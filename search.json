[{"categories":["kubernetes"],"content":"资源清单格式 apiVersion: group/apiversion # 指定当前的组和版本（写的资源清单具体去哪个路径下调代码）。如果没有给定 group 名称，那么默认为 core，可以使用 kubectl api-versions # 获取当前 k8s 版本上所有的 apiVersion 版本信息( 每个版本可能不同 ) kind: Service #资源类别 metadata: #资源元数据 name: pod-demo #资源对象名称； namespace: default #使用名称级别的资源才需要填写； #处于default名称空间下； lables: #标签，筛选操作；一般用于集群内部的筛选功能； app: myapp #标签 annotations: # 主要目的是方便用户阅读查找 spec: # 期望的状态（disired state） containers: #代表mainC； - name: myapp-1 #mainC子对象1名称；列表开头使用 -开头 image: wangyanglinux/myapp:v1 - name: busybox-1 #mainC子对象2名称； image: busybox:1.35.0 command: #此处代表的是ENTRYPOINT； - \"/bin/sh\" - \"-c\" - \"sleep 3600\" status: # 当前状态，本字段有 Kubernetes 自身维护，用户不能去定义 字段格式配置 apiVersion \u003cstring\u003e #表示字符串类型 metadata \u003cObject\u003e #表示需要嵌套多层字段 labels \u003cmap[string]string\u003e #表示由k:v组成的映射 finalizers \u003c[]string\u003e #表示字串列表 ownerReferences \u003c[]Object\u003e #表示对象列表 hostPID \u003cboolean\u003e #布尔类型 priority \u003cinteger\u003e #整型 name \u003cstring\u003e -required- #如果类型后面接 -required-，表示为必填字段 常用资源清单格式定义 Object ：对象，下方是对象的属性 list：类别，下方包含多个数组，每个数组是一个对象 String：字符串 后边直接跟value的值 通用字段 参数名 字段类型 说明 version String 这里是指的是K8S API的版本，目前基本上是v1，可以用kubectl apiversions命令音询 kind String 这里指的是yamI文件定义的资源类型和角色，比如: Pod metadata Object 元数据对象，固定值就写metadata Spec bject 详细定义对象，固定值就写Spec metadate相关字段 参数名 字段类型 说明 metadata Object 元数据对象，固定值就写metadata metadata.name String 元数据对象的名字，这里由我们编写，比如命名Pod的名字 metadata.lables list 标签列表。有key=value组成 pod相关字段 参数名 字段类型 说明 spec.restartPolicy String 定义Pod的重启策略，可选值为Always、OnFailure，默认值为Always。1.Always: Pod一旦终止运行，则无论容器是如何终止的，kubelet服务都将重启它。2.OnFailure: 只有Pod以非零退出码终止时，kubelet才会重启该容器。如果容器正常结束 (退出码为0) ，则kubelet将不会重启它3.Never: Pod终止后，kubelet将退出码报告给Master，不会重启该Pod. spec.nodeSelector Object 定义Node的Label过滤标签，以key:value格式指定 spec.imagePullSecrets Object 定义pull镜像时使用secret名称，以name:secretkey格式指定 spec.hostNetwork Boolean 定义是否使用主机网络模式，默认值为false。设置true表示使用宿主机网络，不使用docker网桥，同时设置了true将无法在同一台宿主机上启动第二个副本。 sepc.NodeName string 定义pod要调度的节点，可以忽略污点，还是要预选、优选。 mainC字段 参数名 字段类型 说明 spec.containers[] list 这里是Spec对象的容器列表定义，是个列表 spec.containers[].name String 这里定义容器的名字 spec.containers[].image String 这里定义要用到的镜像名称 spec.containers[].imagePullPolicy String 定义镜像拉取策略，有Always、Never、lfNotPresent三个值可选 (1) Aways: 意思是每次都尝试重新拉取镜像 (2) Never: 表示仅使用本地镜像 (3) lfNotPresent: 如果本地有镜像就使用本地镜像，没有就拉取在线镜像。上面三个值都没设置的话，默认是Always。 spec.containers[].command[] List 指定容器启动命令，因为是数组可以指定多个，不指定则使用镜像打包时使用的启动命令 spec.containers[].args[] List 指定容器启动命令参数，因为是数组可以指定多个。 spec.containers[].workingDir string 指定容器的工作目录 spec.containers[].volumeMounts[] List 指定容器内部的存储卷配置 spec.containers[].volumeMounts[].name String 指定可以被容器挂载的存储卷的名称 spec.containers[].volumeMounts[].mountPath string 指定可以被容器挂载的存储卷的路径 spec.containers[].volumeMounts[].readOnly string 设置存储卷路径的读写模式，ture 或者false默认为读写模式 spec.containers[].ports[] List 指定容器需要用到的端口列表 spec.containers[].ports[].name String 指定端口名称 spec.containers[].ports[].containerPort String 指定容器需要监听的端口号 spec.containers[].ports[].hostPort String 指定容器所在主机需要监听的端口号，默认跟上面containerPort相同，注意设置了hostPort同一台主机无法启动该容器的相同副本 (因为主机的端口号不能相同，这样会冲突) spec.containers[].ports[].protocol String 指定端口协议，支持TCP和UDP，默认值为TCP spec.containers[].env[] List 指定容器运行前需设置的环境变量列表 spec.containers[].env[].name string 指定环境变量名称 spec.containers[].env[].value String 指定环境变量值 spec.containers[].resources Object 指定资源限制和资源请求的值 (这里开始就是设置容器的资源上限) spec.containers[].resources.limits Object 指定设置容器运行时资源的运行上限 spec.containers[].resources.limits.cpu String 指定CPU的限制，单位为core数，将用于docker run –cpu-shares参数 (这里前面文章Pod资源限制有讲过) spec.containers[].resources.limits.memory String 指定MEM内存的限制，单位为MIB、GiB spec.containers[].resources.requests Object 指定容器启动和调度时的限制设置 spec.containers[].resources.requests.cpu String CPU请求，单位为core数，容器启动时初始化可用数量 spec.containers[].resources.requests.memory String 内存请求，单位为MIB、GiB，容器启动的初始化可用数量 就绪探针 参数名 字段类型 说明 spec.containers.readinessProbe Object 定义容器的就绪探测策略。有三种模式可选:exec：返回码为0为就绪tcpsoket：tcp 对应检测端口响应成功为就绪httpget：返回码 \u003e= 200 \u0026\u0026 \u003c 400 为就绪 spec.containers.readinessProbe.exec list 定义容器的就绪探测策略为exec。 spec.containers.readinessProbe.exec.command List exec所对应的命令 spec.containers.readinessProbe.initialDelaySeconds init 探测开始时间 spec.container","date":"2025-01-07","objectID":"/posts/kubernetes/:0:0","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["golang"],"content":" uber-go/guide 的中文翻译 English Uber Go 语言编码规范 Uber 是一家美国硅谷的科技公司，也是 Go 语言的早期 adopter。其开源了很多 golang 项目，诸如被 Gopher 圈熟知的 zap、jaeger 等。2018 年年末 Uber 将内部的 Go 风格规范 开源到 GitHub，经过一年的积累和更新，该规范已经初具规模，并受到广大 Gopher 的关注。本文是该规范的中文版本。本版本会根据原版实时更新。 版本 当前更新版本：2024-08-10 版本地址：commit:#217 如果您发现任何更新、问题或改进，请随时 fork 和 PR Please feel free to fork and PR if you find any updates, issues or improvement. 目录 uber-go/guide 的中文翻译 English Uber Go 语言编码规范 版本 目录 介绍 指导原则 指向 interface 的指针 Interface 合理性验证 接收器 (receiver) 与接口 零值 Mutex 是有效的 在边界处拷贝 Slices 和 Maps 接收 Slices 和 Maps 返回 slices 或 maps 使用 defer 释放资源 Channel 的 size 要么是 1，要么是无缓冲的 枚举从 1 开始 使用 time 处理时间 使用 time.Time 表达瞬时时间 使用 time.Duration 表达时间段 对外部系统使用 time.Time 和 time.Duration Errors 错误类型 错误包装 错误命名 一次处理错误 处理断言失败 不要使用 panic 使用 go.uber.org/atomic 避免可变全局变量 避免在公共结构中嵌入类型 避免使用内置名称 避免使用 init() 追加时优先指定切片容量 主函数退出方式 (Exit) 一次性退出 在序列化结构中使用字段标记 不要一劳永逸地使用 goroutine 等待 goroutines 退出 不要在 init() 使用 goroutines 性能 优先使用 strconv 而不是 fmt 避免字符串到字节的转换 指定容器容量 指定 Map 容量提示 指定切片容量 规范 避免过长的行 一致性 相似的声明放在一组 import 分组 包名 函数名 导入别名 函数分组与顺序 减少嵌套 不必要的 else 顶层变量声明 对于未导出的顶层常量和变量，使用_作为前缀 结构体中的嵌入 本地变量声明 nil 是一个有效的 slice 缩小变量作用域 避免参数语义不明确 (Avoid Naked Parameters) 使用原始字符串字面值，避免转义 初始化结构体 使用字段名初始化结构 省略结构中的零值字段 对零值结构使用 var 初始化 Struct 引用 初始化 Maps 字符串 string format 命名 Printf 样式的函数 编程模式 表驱动测试 功能选项 Linting Lint Runners Stargazers over time 介绍 样式 (style) 是支配我们代码的惯例。术语样式有点用词不当，因为这些约定涵盖的范围不限于由 gofmt 替我们处理的源文件格式。 本指南的目的是通过详细描述在 Uber 编写 Go 代码的注意事项来管理这种复杂性。这些规则的存在是为了使代码库易于管理，同时仍然允许工程师更有效地使用 Go 语言功能。 该指南最初由 Prashant Varanasi 和 Simon Newton 编写，目的是使一些同事能快速使用 Go。多年来，该指南已根据其他人的反馈进行了修改。 本文档记录了我们在 Uber 遵循的 Go 代码中的惯用约定。其中许多是 Go 的通用准则，而其他扩展准则依赖于下面外部的指南： Effective Go Go Common Mistakes Go Code Review Comments 我们的目标是使代码示例能够准确地用于Go的两个发布版本 releases. 所有代码都应该通过golint和go vet的检查并无错误。我们建议您将编辑器设置为： 保存时运行 goimports 运行 golint 和 go vet 检查错误 您可以在以下 Go 编辑器工具支持页面中找到更为详细的信息： https://go.dev/wiki/IDEsAndTextEditorPlugins 指导原则 指向 interface 的指针 您几乎不需要指向接口类型的指针。您应该将接口作为值进行传递，在这样的传递过程中，实质上传递的底层数据仍然可以是指针。 接口实质上在底层用两个字段表示： 一个指向某些特定类型信息的指针。您可以将其视为\"type\"。 数据指针。如果存储的数据是指针，则直接存储。如果存储的数据是一个值，则存储指向该值的指针。 如果希望接口方法修改基础数据，则必须使用指针传递 (将对象指针赋值给接口变量)。 type F interface { f() } type S1 struct{} func (s S1) f() {} type S2 struct{} func (s *S2) f() {} // f1.f() 无法修改底层数据 // f2.f() 可以修改底层数据，给接口变量 f2 赋值时使用的是对象指针 var f1 F = S1{} var f2 F = \u0026S2{} 永远不要使用指向interface的指针，这个是没有意义的.在go语言中，接口本身就是引用类型，换句话说，接口类型本身就是一个指针。对于我的需求，其实test的参数只要是myinterface就可以了，只需要在传值的时候，传mystruct类型（也只能传mystruct类型） type myinterface interface{ print() } func test(value *myinterface){ //someting to do ... } type mystruct struct { i int } //实现接口 func (this *mystruct) print(){ fmt.Println(this.i) this.i=1 } func main(){ m := \u0026mystruct{0} test(m)//错误 test(*m)//错误 } Interface 合理性验证 在编译时验证接口的符合性。这包括： 将实现特定接口的导出类型作为接口 API 的一部分进行检查 实现同一接口的 (导出和非导出) 类型属于实现类型的集合 任何违反接口合理性检查的场景，都会终止编译，并通知给用户 补充：上面 3 条是编译器对接口的检查机制， 大体意思是错误使用接口会在编译期报错。 所以可以利用这个机制让部分问题在编译期暴露。 BadGood // 如果 Handler 没有实现 http.Handler，会在运行时报错 type Handler struct { // ... } func (h *Handler) ServeHTTP( w http.ResponseWriter, r *http.Request, ) { ... } type Handler struct { // ... } // 用于触发编译期的接口的合理性检查机制 // 如果 Handler 没有实现 http.Handler，会在编译期报错 var _ http.Handler = (*Handler)(nil) func (h *Handler) ServeHTTP( w http.ResponseWriter, r *http.Request, ) { // ... } 如果 *Handler 与 http.Handler 的接口不匹配， 那么语句 var _ http.Handler = (*Handler)(nil) 将无法编译通过。 赋值的右边应该是断言类型的零值。 对于指针类型（如 *Handler）、切片和映射，这是 nil； 对于结构类型，这是空结构。 type LogHandler struct { h http.Handler log *zap.Logger } var _ http.Handler = LogHandler{} func (h LogHandler) ServeHTTP( w http.ResponseWriter, r *http.Request, ) { // ... } 接收器 (receiver) 与接口 使用值接收器的方法既可以通过值调用，也可以通过指针调用。 带指针接收器的方法只能通过指针或 addressable values 调用。 例如， type S struct { data string } func (s S) Read() string { return s.data } func (s *S) Write(str string) { s.data = str } sVals := map[int]S{1: {\"A\"}} // 你通过值只能调用 Read sVals[1].Read() // 这不能编译通过： // sVals[1].Write(\"test\") sPtrs := map[int]*S{1: {\"A\"}} // 通过指针既可以调用 Read，也可以调用 Write 方法 sPtrs[1].Read() sPtrs[1].Write(\"test\") 类似的，即使方法有了值接收器，也同样可","date":"2024-11-22","objectID":"/posts/golang-guide/:0:0","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["python"],"content":" macos 使用 install brew install poetry 初始化 mkdir project-demo cd project-demo poetry init 管理虚拟环境 创建虚拟环境 虚拟环境的命名模式为 项目名-随机数-python版本 poetry env use PYTHONPATH 查看当前虚拟环境 poetry env list 查看当前poetry配置 poetry config --list 允许在项目目录下创建虚拟环境 poetry config virtualenvs.in-project true 如果已经创建了环境需要先移除 poetry env remove PYTHONPATH 创建目录：poetry env use PYTHONPATH 退出与启动环境 已 poetry 开头的命令自动检测当前环境 同样也可以使用poetry shell进入 退出环境：deactivate poetry 指令 添加依赖包 poetry add poetry add requests poetry.lock 与更新顺序 除了更新 pyproject.toml ，此时项目中还会新增一个文件，名为 poetry.lock ，它实际上就相当于 pip 的 requirements.txt ，详细记录了所有安装的模块与版本。 当使用 poetry add 指令时，poetry 会自动依序帮你做完这三件事： 更新 pyproject.toml。 依照 pyproject.toml 的内容，更新 poetry.lock 。 依照 poetry.lock 的内容，更新虚拟环境。 由此可见， poetry.lock 的内容是取决于 pyproject.toml ，但两者并不会自己连动，一定要基于特定指令才会进行同步与更新， poetry add 就是一个典型案例。 poetry lock ：更新 poetry.lock 当你自行修改了 pyproject.toml 内容，比如变更特定模块的版本（这是有可能的，尤其在手动处理版本冲突的时候），此时 poetry.lock 的内容与 pyproject.toml 出现了脱钩，必须让它依照新的 pyproject.toml 内容更新、同步，使用指令： poetry lock 如此一来，才能确保手动修改的内容，也更新到 poetry.lock 中，毕竟虚拟环境如果要重新建立，是基于 poetry.lock 的内容来安装模块，而非 pyproject.toml 。 还是那句话： poetry.lock 相当于 Poetry 的 requirements.txt。 但要特别注意的是， poetry lock 指令，仅会更新 poetry.lock ，不会同时安装模块至虚拟环境 因此，在执行完 poetry lock 指令后，必须再使用 poetry install 来安装模块。否则就会出现 poetry.lock 和虚拟环境不一致的状况。 更多 poetry lock 细节可参考 官方文件，其中特别值得注意的是 --no-update 参数。 新增模块至 dev-dependencies 有些模块，比如 pytest 、 black 等等，只会在开发环境中使用，产品的部署环境并不需要。 Poetry 允许你区分这两者，将上述的模块安装至 dev-dependencies 区块，方便让你轻松建立一份「不包含」 dev-dependencies 开发模块的安装清单。 在此以 Black 为例，安装方式如下： poetry add black --group dev 结果的区别显示在 pyproject.toml 里： python = \"^3.10\" flask = \"^2.3.2\" [tool.poetry.group.dev.dependencies] black = \"^23.7.0\" 可以看到 black 被列在不同区块： tool.poetry.dev-dependencies 。 强烈建议善用 dev-dependencies 善用 --group dev 参数，明确区分开发环境，我认为非常必要。 首先，这些模块常常属于「检测型」工具，相关的依赖模块着实不少！比如 flake8 ，它依赖了 pycodestyle 、 pyflakes 、 mccabe 等等，还有 black 、 pre-commit ，依赖模块数量也都很可观。 Poetry 更新模块 这个就很简单了，使用 poetry update 指令即可： poetry update 上面指令会更新全部可能可以更新的模块，也可以仅指定特定模块，比如： poetry update requests toml 关于 poetry update 的其余参数，请参考文件。 还一件重要的事，那就是关于模块版本的升级限制规则，取决于你在 pyproject.toml 中的设定。 列出全部模块清单 poetry show 树状显示依赖层 poetry show --tree 也可以指定模块显示 poetry show celery --tree 删除模块 poetry remove celery 导出poetry 虚拟环境requirements.txt poetry export -f requirements.txt -o requirements.txt --without-hashes 导出dev的包 poetry export -f requirements.txt -o requirements-dev.txt --without-hashes --dev 添加阿里云源 poetry source add aliyun https://mirrors.aliyun.com/pypi/simple ","date":"2024-10-31","objectID":"/posts/poetry/:0:0","tags":["poetry"],"title":"Poetry: Python虚拟环境管理","uri":"/posts/poetry/"},{"categories":["nodejs"],"content":"问题集锦 /lib64/libstdc++.so.6: version `CXXABI_1.3.9’ not found canvas.node 解决办法（CentOS） npx node-pre-gyp rebuild -C ./node_modules/canvas ","date":"2024-10-29","objectID":"/posts/nodejs/:0:0","tags":["nodejs"],"title":"Nodejs","uri":"/posts/nodejs/"},{"categories":["macos"],"content":"macos 启动过程 launchd开启之后，会依次去完成以下的工作： 根据/System/Library/LaunchDaemons 和/Library/LaunchDaemons路径下的plist文件，加载系统级守护进程； 注册上述守护进程需要的套接字及文件描述符； 根据plist文件中的KeepAlive键值，启动那些需要在系统周期内一直保持的进程； 根据plist文件中的设定，在条件满足时启动进程； 关机时，给所有由launchd开启的进程发送SIGTERM信号。 我们将log信息中的内容与/System/Library/LaunchDaemons路径下的plist进行对照，发现在系统开启之初的bootlog，blued，mDNSResponder等都能再该路径下找到。 LaunchDaemons路径下的plist指定的进程启动是否存在一定的先后顺序呢？ 在launchd依次完成的工作中，可以看到它是先注册套接字和文件描述符，然后才去启动进程，因此plist指定的进程的启动先后顺序并不明确。 launchd配置文件总共有五个路径，在系统开启之初，只加载了/System/Library/LaunchDaemons 和/Library/LaunchDaemons路径下的plist文件，另外三个路径下的plist文件是在用户login之后才进行的。 用户的login是由loginwindow进程完成的，而loginwindow的启动又是由/System/Library/LaunchDaemons路径下的com.apple.loginwindow.plist指定的。 用户登录之后，launchd才会去加载/System/Library/LaunchAgents 和/Library/LaunchAgents以及~/Library/LaunchAgents路径下的plist文件，从而根据plist文件的具体设置去启动相应的进程。 ","date":"2024-10-28","objectID":"/posts/macosboot/:0:0","tags":["macos"],"title":"Macosboot","uri":"/posts/macosboot/"},{"categories":["shell"],"content":"ps命令 查看进程启动时间 ps -eo pid,lstart,etime,cmd |grep $PID shell 判断 -eq # 等于 -ne # 不等于 -gt # 大于 -lt # 小于 -ge # 大于等于 -le # 小于等于 IP地址判断 ((2(5[0-5]|[0-4]\\\\\\\\d))|[0-1]?\\\\\\\\d{1,2})(\\\\\\\\.((2(5[0-5]|[0-4]\\\\\\\\d))|[0-1]?\\\\\\\\d{1,2})){3} 字符串运算 运算符 说明 举例 = 检测两个字符串是否相等，相等返回 true。 [ $a = $b ] 返回 false。 != 检测两个字符串是否不相等，不相等返回 true。 [ $a != $b ] 返回 true。 -z 检测字符串长度是否为0，为0返回 true。 [ -z $a ] 返回 false。 -n 检测字符串长度是否不为 0，不为 0 返回 true。 [ -n “$a” ] 返回 true。 $ 检测字符串是否不为空，不为空返回 true。 [ $a ] 返回 true。 文件测试运算符 操作符 说明 举例 -b file 检测文件是否是块设备文件，如果是，则返回 true。 [ -b $file ] 返回 false。 -c file 检测文件是否是字符设备文件，如果是，则返回 true。 [ -c $file ] 返回 false。 -d file 检测文件是否是目录，如果是，则返回 true。 [ -d $file ] 返回 false。 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。 -g file 检测文件是否设置了 SGID 位，如果是，则返回 true。 [ -g $file ] 返回 false。 -k file 检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。 [ -k $file ] 返回 false。 -p file 检测文件是否是有名管道，如果是，则返回 true。 [ -p $file ] 返回 false。 -u file 检测文件是否设置了 SUID 位，如果是，则返回 true。 [ -u $file ] 返回 false。 -r file 检测文件是否可读，如果是，则返回 true。 [ -r $file ] 返回 true。 -w file 检测文件是否可写，如果是，则返回 true。 [ -w $file ] 返回 true。 -x file 检测文件是否可执行，如果是，则返回 true。 [ -x $file ] 返回 true。 -s file 检测文件是否为空（文件大小是否大于0），不为空返回 true。 [ -s $file ] 返回 true。 -e file 检测文件（包括目录）是否存在，如果是，则返回 true。 [ -e $file ] 返回 true。 其他检查符： -S: 判断某文件是否 socket。 -L: 检测文件是否存在并且是一个符号链接。 逻辑运算 运算符 说明 举例 \u0026\u0026 逻辑的 AND [[ $a -lt 100 \u0026\u0026 $b -gt 100 ]] 返回 false || 逻辑的 OR [[ $a -lt 100 || $b -gt 100 ]] 返回 true 布尔运算符 运算符 说明 举例 ! 非运算，表达式为 true 则返回 false，否则返回 true。 [ ! false ] 返回 true。 -o 或运算，有一个表达式为 true 则返回 true。 [ $a -lt 20 -o $b -gt 100 ] 返回 true。 -a 与运算，两个表达式都为 true 才返回 true。 [ $a -lt 20 -a $b -gt 100 ] 返回 false。 关系运算符 运算符 说明 举例 -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ] 返回 false。 -ne 检测两个数是否不相等，不相等返回 true。 [ $a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。 -ge 检测左边的数是否大于等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ] 返回 true。 算术运算符 运算符 说明 举例 + 加法 expr $a + $b 结果为 30。 - 减法 expr $a - $b 结果为 -10。 * 乘法 expr $a * $b 结果为 200。 / 除法 expr $b / $a 结果为 2。 % 取余 expr $b % $a 结果为 0。 = 赋值 a=$b 把变量 b 的值赋给 a。 == 相等。用于比较两个数字，相同则返回 true。 [ $a == $b ] 返回 false。 != 不相等。用于比较两个数字，不相同则返回 true。 [ $a != $b ] 返回 true。 注意：条件表达式要放在方括号之间，并且要有空格，例如: [$a==$b] 是错误的，必须写成 [ $a == $b ]。 乘号(*)前边必须加反斜杠(\\)才能实现乘法运算； 在 MAC 中 shell 的 expr 语法是：$((表达式))，此处表达式中的 “*” 不需要转义符号 “\\” 。 自增和自减操作符 使用 let 命令 let 命令允许对整数进行算术运算。 #!/bin/bash # 初始化变量 num=5 # 自增 let num++ # 自减 let num-- echo $num 使用 $(( )) 进行算术运算 $(( )) 语法也是进行算术运算的一种方式。 #!/bin/bash # 初始化变量 num=5 # 自增 num=$((num + 1)) # 自减 num=$((num - 1)) echo $num 使用 expr 命令 expr 命令可以用于算术运算，但在现代脚本中不如 let 和 $(( )) 常用。 #!/bin/bash # 初始化变量 num=5 # 自增 num=$(expr $num + 1) # 自减 num=$(expr $num - 1) echo $num 使用 (( )) 进行算术运算 与 $(( )) 类似，(( )) 语法也可以用于算术运算。 #!/bin/bash # 初始化变量 num=5 # 自增 ((num++)) # 自减 ((num--)) echo $num ","date":"2024-10-17","objectID":"/posts/shell/:0:0","tags":["shell"],"title":"Shell","uri":"/posts/shell/"},{"categories":["macos"],"content":"minikube minikube start --image-mirror-country='cn' --driver=hyperkit --registry-mirror=\"\u003chttps://xxx.mirror.aliyuncs.com\u003e\" macos工具集 xldr sourcetree aliyun-cli dash xnip miniconda visualvm maccy obsidian tabby ","date":"2024-10-17","objectID":"/posts/macos/:0:0","tags":["macos"],"title":"Macos","uri":"/posts/macos/"},{"categories":["https"],"content":"ssl # acme.sh # 默认是zerossl，存在认证问题：get authz objec with invalid status, please try again later. # https://github.com/acmesh-official/acme.sh/wiki/Server acme.sh --set-default-ca --server letsencrypt # 申明dns的aksk export DP_Id=\"xxx\";export DP_Key=\"xxx\" # 生成需要的泛域名证书 acme.sh --dnssleep --force --issue -k 2048 --dns dns_dp -d '*.exsample.com' -d exsample.com # 生成nginx 证书 acme.sh --force --install-cert -d *.xxx.net \\ --key-file /usr/local/openresty/nginx/conf/ssl/xxx.net.key \\ --fullchain-file /usr/local/openresty/nginx/conf/ssl/xxx.net.pem \\ --reloadcmd \"nginx -s reload\" # 删除证书 acme.sh --remove -d *.exsample.com # 查看证书信息 acme.sh --info -d *.exsample.com # 查看证书列表 acme.sh --list # 设置自动更新 acme.sh --upgrade --auto-upgrade certbot certbot certonly --manual --preferred-challenges dns ","date":"2024-10-17","objectID":"/posts/letsencrypt/:0:0","tags":["https"],"title":"letsencrypt","uri":"/posts/letsencrypt/"},{"categories":["linux"],"content":"mem centos6.5 -/+ buffers/cache： -buffers/cache 的内存数：95 (等于第1行的 used - buffers - cached) +buffers/cache 的内存数: 32 (等于第1行的 free + buffers + cached) 1. -buffers/cache 反映的是被程序实实在在吃掉的内存， 2. +buffers/cache 反映的是可以挪用的内存总数。 Linux Ctrl C无效 原因：rvm 版本bug 解决方法： 命令查看： 正常： [root@server002 ~]# trap trap -- '' SIGTSTP trap -- '' SIGTTIN trap -- '' SIGTTOU 异常： [root@server002 ~]# trap trap -- '' SIGTSTP trap -- '' SIGTTIN trap -- '' SIGTTOU trap -- '' SIGINT trap -- '' SIGQUIT 现象：终端Ctrl + C完全失效，当执行trap 信号命令时多处两个SIGINT和SIGQUIT两项 升级rvm 版本：rvm get stable（ 1.29.4 版本以上都可以解决） 卸载rvm工具：gem uninstall rvm pip 国内源临时加速 pip install markdown -i \u003chttps://pypi.tuna.tsinghua.edu.cn/simple\u003e 永久配置 # 清华源 pip config set global.index-url \u003chttps://pypi.tuna.tsinghua.edu.cn/simple\u003e # 或： # 阿里源 pip config set global.index-url \u003chttps://mirrors.aliyun.com/pypi/simple/\u003e # 腾讯源 pip config set global.index-url \u003chttp://mirrors.cloud.tencent.com/pypi/simple\u003e goaccess conda • 安装uwsgi： conda install -c conda-forge uwsgi # 取消自动进入base环境 conda config --set auto_activate_base false lvm lvm pvcreate /dev/vdc vgextend VolGroup /dev/vdc lvextend -l +100%FREE /dev/mapper/VolGroup-LogVol00 resize2fs /dev/mapper/VolGroup-LogVol00 根据日期排序删除 ls -ltd FilePath | awk '{if(NR\u003e10){print $0}}' | xargs rm -rf; 磁盘在线扩容 安装工具包： yum -y install cloud-utils-growpart 给指定分区扩容： growpart /dev/vda 1 扩容支文件系统（如果无法resize，确保分区已扩容的情况下重启服务器离线扩容）： resize2fs /dev/vda1 timewait查看 netstat -an | awk '{print $6}' | sort | uniq -c | sort -nr 路由新增删除 route add -net 106.15.100.0/24 gw 183.57.42.65 route del -net 106.15.100.0/24 gw 183.57.42.65 maildrop删除 rsync --delete -rlptD /tmp/empty/ /var/spool/postfix/maildrop/ ssh config ServerAliveInterval 60 ServerAliveCountMax 30 HostkeyAlgorithms +ssh-rsa PubkeyAcceptedAlgorithms +ssh-rsa UserKnownHostsFile=/dev/null StrictHostKeyChecking no UserKnownHostsFile=/dev/null Host * ServerAliveInterval 60 ServerAliveCountMax 30 HostkeyAlgorithms +ssh-rsa PubkeyAcceptedAlgorithms +ssh-rsa StrictHostKeyChecking no Host IPADDRESS HostName IPADDRESS User root IdentityFile ~/.ssh/id_rsa crontab 使用vim编辑 1.对于一些系统，crontab的默认编译器使用起来不是很方便，想换成熟悉的vim，按下面操作即可：编辑.profile文件，增加EDITOR=vim;export EDITOR即可； 2.在命令行直接输入EDITOR=vim;export EDITOR ossutil /opt/ossutil64 cp xxx.sql.gz oss://BUCKET/dir/ -u -c CONFIGFILE 多线程压缩 pigz # 压缩文件 pigz -k filename # -k 保留原文件 pigz -l filename.gz # -l 查看文件压缩内容 # 压缩目录 tar --use-compress-program=\"pigz -k\" -cvf dir1.tar.gz dir1 # 解压文件 pigz -k -d filename.gz # 解压目录 tar --use-compress-program=\"pigz -k \" -xvf dir1.tar.gz requirements 依赖生成: pipreqs --encoding utf8 --force openssl 证书测试 openssl s_client -connect domainName:443 强密码生成 openssl rand -base64 15 系统使用规范(自有服务统一授权为普通用户权限) 统一数据目录：/data 统一日志目录：/var/log 应用统一管理工具：supervisor 三方应用目录：/opt 示例服务标记：应用目录：application 应用备份：appbak 公共脚本：scripts ","date":"2024-10-17","objectID":"/posts/linux/:0:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["supervisor"],"content":" /etc/supervisor.conf [unix_http_server] file=/tmp/supervisor.sock [supervisord] minfds=65535 # supervisord 加大应用的可用链接数 minprocs=65535 user=deploy [supervisorctl] serverurl=unix:///tmp/supervisor.sock supervisor exsample [program:SERVICENAME] ;脚本目录 directory= /data/%(program_name)s/ ;脚本执行命令 command=/usr/bin/uwsgi --ini %(program_name)s.ini --ignore-sigpipe ;supervisor启动的时候是否随着同时启动,默认True autostart=true ;当程序exit的时候，这个program不会自动重启. autorestart=true ;这个选项是子进程启动多少秒之后，此时状态如果是running，则我们认为启动成功了。默认值为1 startsecs=5 ;脚本运行的用户身份 user = USER ;日志输出 stdout_logfile= /var/log/supervisor/%(program_name)s.log ;把stderr重定向到stdout，默认 false redirect_stderr = true ;stdout日志文件大小，默认 50MB stdout_logfile_maxbytes = 20MB ;stdout日志文件备份数 stdout_logfile_backups = 20 ;environment= ","date":"2024-10-15","objectID":"/posts/supervisor/:0:0","tags":["supervisor"],"title":"Supervisor","uri":"/posts/supervisor/"},{"categories":["openvpn"],"content":" port 2305 proto udp dev tun ca ca.crt cert server.crt key server.key dh dh.pem auth SHA512 tls-crypt tc.key topology subnet server 10.8.0.0 255.255.255.0 ifconfig-pool-persist ipp.txt push \"dhcp-option DNS 100.100.2.136\" push \"dhcp-option DNS 100.100.2.138\" # 内网推送 push \"route 172.16.0.0 255.255.0.0\" # 阿里内网推送 push \"route 100.100.0.0 255.255.0.0\" push \"route 100.103.0.0 255.255.0.0\" push \"route 47.106.223.210 255.255.255.255\" keepalive 10 120 cipher AES-256-CBC user nobody group nobody persist-key persist-tun verb 3 crl-verify crl.pem explicit-exit-notify ","date":"2024-10-15","objectID":"/posts/openvpncommunity/:0:0","tags":["openvpn"],"title":"OpenvpnCommunity","uri":"/posts/openvpncommunity/"},{"categories":["nginx"],"content":"trust proxy ip set_real_ip_from 172.16.0.0/16; real_ip_header X-Forwarded-For; real_ip_recursive on; 请求方法限制 if ($request_method !~ ^(GET|HEAD|POST)$ ) { return 501; } try_files location / { try_files $uri $uri/ /index.html; } next.js location / { try_files $uri $uri.html $uri/ /index.html; } 443 force ssl if ($ssl_protocol = \"\") { return 302 https://$host$request_uri; } # 302 if ($server_port !~ 443) { rewrite ^(.*)$ https://$host$1 redirect; } # 301 if ($server_port !~ 443) { rewrite ^(.*)$ https://$host$1 permanent; } 499 proxy_ignore_client_abort on; # 确定在客户端关闭连接时是否应关闭与代理服务器的连接，而不在等待响应 proxy_read_timeout 600; proxy_send_timeout 600; # 如果超时(默认60s)，Nginx 会主动断开连接，记录504 log format log_format main escape=json '{ \"time_local\": \"$time_local\", ' '\"remote_user\": \"$remote_user\", ' '\"remote_addr\": \"$remote_addr\", ' '\"http_referer\": \"$http_referer\", ' '\"request\": \"$request\", ' '\"method\": \"$request_method\", ' '\"url_path\": \"$request_uri\", ' '\"request_body\": \"$request_body\", ' '\"status\": $status, ' '\"level\": \"$level\",' '\"body_bytes_sent\": $body_bytes_sent, ' '\"http_user_agent\": \"$http_user_agent\", ' '\"http_host\": \"$http_host\", ' '\"http_requestid\": \"$http_requestid\", ' '\"http_authorization\": \"$http_authorization\", ' '\"business\": \"ngx_access-$host\", ' '\"http_x_forwarded_for\": \"$http_x_forwarded_for\", ' '\"upstream_addr\": \"$upstream_addr\",' '\"trace_id\": \"$trace_id\",' '\"upstream_response_time\": \"$upstream_response_timer\",' '\"ssl_protocol\": \"$ssl_protocol\",' '\"request_time\": $request_time' ' }'; 跨域 add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods *; add_header Access-Control-Allow-Credentials true; 上传文件 # nginx client_max_body_size 1024m; # php file_uploads on 是否允许通过HTTP上传文件的开关。 默认为ON即是开upload_tmp_dir – 文件上传至服务器上存储临时文件的地方，如果没指定就会用系统默认的临时文件夹 upload_max_filesize 8m 望文生意，即允许上传文件大小的最大值。默认为2M post_max_size 8m 指通过表单POST给PHP的所能接收的最大值，包括表单里的所有值。默认为8M # 针对网络不好配置 max_execution_time 600 每个PHP页面运行的最大时间值(秒)，默认30秒 max_input_time 600 每个PHP页面接收数据所需的最大时间，默认60秒 memory_limit 8m 每个PHP页面所吃掉的最大内存，默认8M proxy location ~ .*\\.(js|css)?$ { expires 12h; proxy_pass http://xxx; } location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)?$ { expires 12h; proxy_pass http://xxx; } exsample http upstream xxx.cn { server 10.x:3000 weight=10 max_fails=3 fail_timeout=3s; server 10.x:3000 weight=10 max_fails=3 fail_timeout=3s; check interval=1000 rise=2 fall=3 timeout=5000 type=http default_down=false; check_http_send \"GET /ping HTTP/1.0\\\\r\\\\n\\\\r\\\\n\"; check_http_expect_alive http_2xx http_3xx; } server { listen 80; server_name xxx.cn; index index.html index.htm; access_log /var/log/nginx/xxx.cn.access.log main; error_log /var/log/nginx/xxx.cn.error.log warn; location ~ ^/NginxStatus/ { stub_status on; access_log on; } location / { proxy_redirect off ; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_connect_timeout 600; proxy_send_timeout 600; proxy_read_timeout 600; proxy_ignore_client_abort on; proxy_buffer_size 1600k; proxy_buffers 4 3200k; proxy_busy_buffers_size 6400k; proxy_temp_file_write_size 6400k; proxy_max_temp_file_size 128m; proxy_next_upstream error timeout invalid_header http_500 http_503 http_404; proxy_pass http://xxx.cn; } } php listen 80; listen [::]:80; listen 443 ssl http2; listen [::]:443 ssl http2; ssl_certificate /usr/local/openresty/nginx/conf/ssl/xxx.com.pem; ssl_certificate_key /usr/local/openresty/nginx/conf/ssl/xxx.com.key; ssl_protocols TLSv1.2 TLSv1.3; ssl_ecdh_curve X25519:prime256v1:secp384r1:secp521r1; ssl_ciphers ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256; ssl_conf_command Ciphersuites TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256; ssl_conf_command Options PrioritizeChaCha; ssl_prefer_server_ci","date":"2024-10-15","objectID":"/posts/nginx/:0:0","tags":["nginx"],"title":"Nginx","uri":"/posts/nginx/"},{"categories":["minio"],"content":"集群版条件 注意 单独无数据磁盘使用 minio节点的时间不能超过3s nginx 配置 upstream xxx.com { least_conn; server 127.0.0.1:9000; } upstream xxx.com-console { least_conn; server 127.0.0.1:9001; } server { listen 80; listen [::]:80; server_name xxx.com; access_log /var/log/nginx/xxx.com.access.log main; error_log /var/log/nginx/xxx.com.error.log warn; # Allow special characters in headers ignore_invalid_headers off; # Allow any size file to be uploaded. # Set to a value such as 1000m; to restrict file size to a specific value client_max_body_size 0; # Disable buffering proxy_buffering off; proxy_request_buffering off; location / { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_connect_timeout 300; # Default is HTTP/1, keepalive is only enabled in HTTP/1.1 proxy_http_version 1.1; proxy_set_header Connection \"\"; chunked_transfer_encoding off; proxy_pass \u003chttp://xxx.com\u003e; # This uses the upstream directive definition to load balance } location /minio { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-NginX-Proxy true; # This is necessary to pass the correct IP to be hashed # real_ip_header X-Real-IP; proxy_connect_timeout 300; # To support websockets in MinIO versions released after January 2023 proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; chunked_transfer_encoding off; proxy_pass \u003chttp://xxx.com-console\u003e; # This uses the upstream directive definition to load balance and assumes a static Console port of 9001 } } minio 配置 useradd minio -s /sbin/nologin /etc/default/minio MINIO_VOLUMES=\"\u003chttp://192.168.1.141/data/minio\u003e \u003chttp://192.168.1.140/data/minio\u003e\" MINIO_OPTS=\"--console-address :9001 --address :9000\" MINIO_ROOT_USER=admin MINIO_ROOT_PASSWORD=xxx # MINIO_SERVER_URL=\"\u003chttps://minio.example.net:9000\u003e\" /usr/lib/systemd/system/minio.service [Unit] Description=MinIO Documentation=https://min.io/docs/minio/linux/index.html Wants=network-online.target After=network-online.target AssertFileIsExecutable=/usr/local/bin/minio [Service] WorkingDirectory=/usr/local User=minio Group=minio ProtectProc=invisible EnvironmentFile=-/etc/default/minio ExecStartPre=/bin/bash -c \"if [ -z \\\\\"${MINIO_VOLUMES}\\\\\" ]; then echo \\\\\"Variable MINIO_VOLUMES not set in /etc/default/minio\\\\\"; exit 1; fi\" ExecStart=/usr/local/bin/minio server $MINIO_OPTS $MINIO_VOLUMES # MinIO RELEASE.2023-05-04T21-44-30Z adds support for Type=notify (\u003chttps://www.freedesktop.org/software/systemd/man/systemd.service.html#Type=\u003e) # This may improve systemctl setups where other services use `After=minio.server` # Uncomment the line to enable the functionality # Type=notify # Let systemd restart this service always Restart=always # Specifies the maximum file descriptor number that can be opened by this process LimitNOFILE=65536 # Specifies the maximum number of threads this process can create TasksMax=infinity # Disable timeout logic and wait until process is stopped TimeoutStopSec=infinity SendSIGKILL=no [Install] WantedBy=multi-user.target # Built for ${project.name}-${project.version} (${project.name}) 开启自启动 # 创建minio目录（一个盘对应一个目录即可） mkdir /data/minio chown -R minio.minio /data/minio systemctl enable minio systemctl start minio ","date":"2024-10-15","objectID":"/posts/minio/:0:0","tags":["minio"],"title":"Minio","uri":"/posts/minio/"},{"categories":["kernal"],"content":"备注: /proc/sys/：目录是Linux内核在启动后生成的伪目录，其目录下的net文件夹中存放了当前系统中开启的所有内核参数,目录树结构与参数的完整名称相关. 如: net.ipv4.tcp_tw_recycle，它对应的文件是/proc/sys/net/ipv4/tcp_tw_recycle文件，文件的内容就是参数值。 允许回收TCP连接，必须为1 Linux从4.12内核版本开始移除了 配置 net.ipv4.tcp_tw_recycle = 0 阿里云 - Linux系统常用内核网络参数介绍与常见问题处理: Sysctl 操作命令 查看当前生效的内核参数 sysctl -a 生效更改的内核参数 sysctl -p 禁用大内存页面 Transparent Huge Pages for Redis/MongoDB ，默认是 always echo \"never\" \u003e /sys/kernel/mm/transparent_hugepage/enabled ulimits 优化设置打开文件的最大数量（文件描述符），按需修改最大数值。 编辑 /etc/security/limits.conf ，添加或替换下面几行代码到文件结尾. root soft nofile 65535 root hard nofile 65535 # root hard nofile 65535 * soft nproc 65535 * hard nproc 65535 * soft nofile 65535 * hard nofile 65535 sysctl.conf 优化 # 脏数据的比例和处理，根据场景不同设置， # 参考 \u003chttps://lonesysadmin.net/2013/12/22/better-linux-disk-caching-performance-vm-dirty_ratio/\u003e # 如果是数据库服务器，希望数据能够尽快安全写入，可降低内存缓存比例 vm.dirty_background_ratio = 5 vm.dirty_ratio = 10 # 如果是业务服务器，对数据安全写入无要求，可加大内存缓存比例 vm.dirty_background_ratio = 50 vm.dirty_ratio = 80 # 设置为1，内核允许分配所有的物理内存,Redis常用 # 0， 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。 # 1， 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。 # 2， 表示内核允许分配超过所有物理内存和交换空间总和的内存 vm.overcommit_memory = 1 fs.file-max = 2097152 # 系统拥有的内存数，ElasticSearch启动必备 vm.max_map_count = 262144 # 数据包转发,0表示禁止 net.ipv4.ip_forward = 0 # 设置为1,tcp链接参数重新配置 net.ipv4.tcp_no_metrics_save = 1 # 处理无源路由 net.ipv4.conf.all.accept_source_route = 0 net.ipv4.conf.default.accept_source_route = 0 # 禁用 sysrq 功能 kernel.sysrq = 0 # 控制 core 文件的文件名中是否添加 pid 作为扩展 kernel.core_uses_pid = 1 # 服务端主动关闭后,客户端释放连接的超时,FIN-WAIT-2状态\u003c30 net.ipv4.tcp_fin_timeout = 10 # 设置为1，防止 SYNC FLOOD 攻击 net.ipv4.tcp_syncookies = 1 # TIME_WAIT socket的最大数目，不宜太大或者太小，nginx反向代理必备 net.ipv4.tcp_max_tw_buckets = 262144 # 允许重用TCP连接,0表示关闭 net.ipv4.tcp_tw_reuse = 1 # 允许TCP保持的空闲keepalive时长,不需要太长 net.ipv4.tcp_keepalive_time = 30 # 链接失效前发送探测包数量 net.ipv4.tcp_keepalive_probes = 3 # 链接无确认时重新发送的频度,default 75s net.ipv4.tcp_keepalive_intvl = 30 # 消息队列存放消息的总字节数 kernel.msgmnb = 65536 # 系统范围内最大多少个消息队列 kernel.msgmni = 2048 # 消息队列的最大消息大小，默认8k，建议64kb kernel.msgmax = 65536 # 每个消息的最大size. kernel.shmmax = 68719476736 # 内核参数定义单个共享内存段的最大值 kernel.shmall = 4294967296 # 交换内存使用 vm.swappiness = 0 # 系统作为TCP客户端连接自动使用的端口(start，end），可发起并发连接数为end-star net.ipv4.ip_local_port_range = 1024 65500 # socket缓冲区发送和接收的默认值 net.core.wmem_default = 8388608 net.core.rmem_default = 8388608 # tcp数据发送和接收值 net.core.wmem_max = 16777216 net.core.rmem_max = 16777216 # TCP 缓冲区内存，连接数达到非常高时候需要配置好 net.ipv4.tcp_rmem = 4096 87380 16777216 net.ipv4.tcp_wmem = 4096 65536 16777216 net.ipv4.tcp_mem = 786432 2097152 3145728 # 打开 SACK 选项,防止伪造sequence net.ipv4.tcp_sack = 1 # 禁用timestamp，重要，高并发下设置为0 net.ipv4.tcp_timestamps = 0 # 激活窗口扩充因子，支持64kb以上数据传输 (2^30)1GB net.ipv4.tcp_window_scaling = 1 # ACCEPT等待队列长度,当内核处理慢时多出的包放入网卡接受队列,反之为允许放入队列的最大数量 net.core.netdev_max_backlog = 262144 # 允许最大并发连接数，重要 net.core.somaxconn = 262144 # SYNC等待队列长度,太大了排队也没用 net.ipv4.tcp_max_syn_backlog = 262144 # 不属于任何进程的socket数目，不宜太大，防止攻击 net.ipv4.tcp_max_orphans = 262144 # 处于SYN_RECV状态时重传SYN+ACK包的次数,5以内 net.ipv4.tcp_synack_retries = 2 # 外向syn握手重试次数，5以内 net.ipv4.tcp_syn_retries = 2 # arp相邻层有效性周期 net.ipv4.neigh.default.gc_stale_time=120 # 数据包反向路由验证,0:关闭 1:严格 2:松散 net.ipv4.conf.default.rp_filter=0 net.ipv4.conf.all.rp_filter=0 net.ipv4.conf.default.arp_announce = 2 net.ipv4.conf.all.arp_announce=2 net.ipv4.conf.lo.arp_announce=2 net.ipv4.conf.all.arp_ignore=1 net.ipv4.conf.lo.arp_ignore=1 net.bridge.bridge-nf-call-ip6tables = 0 net.bridge.bridge-nf-call-iptables = 0 net.bridge.bridge-nf-call-arptables = 0 # 关闭tcp链接传输的慢启动 net.ipv4.tcp_slow_start_after_idle = 0 # Linux实例NAT哈希表满导致ECS实例丢包 # nf_conntrack_buckets * 4 = nf_conntrack_max # net.netfilter.nf_conntrack_buckets = 163837 net.netfilter.nf_conntrack_max = 655350 net.netfilter.nf_conntrack_tcp_timeout_established = 1200 阿里云系统（alibaba cloud linux 3）默认配置 • Alibaba cloud linux 3 default sysctl configure vm.swappiness = 0 kernel.sysrq = 1 net.ipv4.neigh.default.gc_stale_time = 120 # see details in \u003chttps://h","date":"2024-10-15","objectID":"/posts/sysctl/:0:0","tags":["system"],"title":"Sysctl","uri":"/posts/sysctl/"},{"categories":["linux"],"content":"性能观测工具 性能压测工具 性能调优工具 ","date":"2024-10-15","objectID":"/posts/linux_analysis_tools/:0:0","tags":["linux"],"title":"linux_analysis_tools","uri":"/posts/linux_analysis_tools/"},{"categories":["alpine"],"content":" 替换源： # alpine sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories # ubuntu sed -i s@/archive.ubuntu.com/@/mirrors.aliyun.com/@g /etc/apt/sources.list # debian sed -i \"s@\u003chttp://deb.debian.org@http\u003e://mirrors.aliyun.com@g\" /etc/apt/sources.list sed -i \"s@\u003chttp://security.debian.org@http\u003e://mirrors.aliyun.com@g\" /etc/apt/sources.list python： apk add python3 apk add py-pip pip install -U pip \\\\ pip config set global.index-url \u003chttps://mirrors.aliyun.com/pypi/simple/\u003e \\\\ dockerfile COPY * target # 会解压第一层目录 COPY . target # 保留原始目录 ","date":"2024-10-15","objectID":"/posts/alpine/:0:0","tags":["alpine"],"title":"Alpine","uri":"/posts/alpine/"},{"categories":["linux"],"content":" 系统版本：Alibaba Cloud Linux 3.2104 LTS 64位 默认镜像操作 # 关闭默认启动服务 systemctl disable nfs-server systemctl disable rpc-statd systemctl disable systemd-resolved systemctl disable rpcbind systemctl disable nfsdcld systemctl stop nfs-server systemctl stop rpc-statd systemctl stop rpcbind systemctl stop systemd-resolved systemctl stop nfsdcld # 安装软件 dnf install supervisor dnf install nscd # 新增普通用户 useradd xxx 清除dns缓存 service nscd restart # 或者使用以下命令清楚 service nscd restart crontab 59 23 * * * /usr/sbin/logrotate /etc/logrotate.conf logrostate daily #指定转储周期为每天 weekly #指定转储周期为每周； monthly #指定转储周期为每月； rotate count #指定日志文件删除之前转储的次数，0指没有备份，5指保留5个备份； compress #通过gzip压缩转储以后的日志； nocompress #不需要压缩时，用这个参数； delaycompress #延迟压缩，和compress一起使用时，转储的日志文件到下一次转储时才压缩； nodelaycompress #覆盖delaycompress选项，转储同时压缩； copytruncate #用于还在打开中的日志文件，把当前日志备份并截断； nocopytruncate #备份日志文件但是不截断； create mode owner group #转储文件，使用指定的文件模式创建新的日志文件； nocreate #不建立新的日志文件； errors address #专储时的错误信息发送到指定的Email地址； ifempty #即使是空文件也转储，这个是logrotate的缺省选项； notifempty #如果是空文件的话，不转储； mail address #把转储的日志文件发送到指定的E-mail地； nomail #转储时不发送日志文件； olddir directory #转储后的日志文件放入指定的目录，必须和当前日志文件在同一个文件系统； noolddir #转储后的日志文件和当前日志文件放在同一个目录下； prerotate/endscript #在转储以前需要执行的命令可以放入这个对，这两个关键字必须单独成行； postrotate/endscript #在转储以后需要执行的命令可以放入这个对，这两个关键字必须单独成行； tabootext [+] list #让logrotate不转储指定扩展名的文件，缺省的扩展名是：.rpm-orig, .rpmsave,v,和~ ； size size #当日志文件到达指定的大小时才转储，Size可以指定bytes(缺省)以及KB(sizek)或者MB(sizem)； postrotate #日志轮换过后指定指定的脚本，endscript参数表示结束脚本； sharedscripts #共享脚本,下面的postrotate中的脚本只执行一次即可； # 手动执行：/usr/sbin/logrotate -f /etc/logrotate.conf # nginx /var/log/nginx/*.log { daily dateext missingok rotate 52 compress delaycompress notifempty create 640 nginx zabbix sharedscripts postrotate /usr/sbin/nginx -s reload endscript } # 示例：待验证 /var/log/nginx/*log { daily rotate 10 missingok notifempty compress sharedscripts su root postrotate /bin/kill -USR1 $(cat /var/run/nginx.pid 2\u003e/dev/null) 2\u003e/dev/null || : endscript } # httpd /var/log/httpd/*log { missingok notifempty sharedscripts delaycompress postrotate /sbin/service httpd reload \u003e /dev/null 2\u003e/dev/null || true endscript } sshd_config配置 # alibaba linux default configure UseDNS no AddressFamily inet SyslogFacility AUTHPRIV PermitRootLogin yes PasswordAuthentication yes https://help.aliyun.com/zh/ecs/how-to-enable-the-kdump-service-for-linux-instances?spm=a2c4g.750001.0.i42 ","date":"2024-10-15","objectID":"/posts/alibabalinux/:0:0","tags":["alibabalinux"],"title":"Alibabalinux","uri":"/posts/alibabalinux/"},{"categories":["kibana"],"content":" kibana无法新建索引模式，F12 “403”: 权限问题 PUT .kibana/_settings { \"index\": { \"blocks\": { \"read_only_allow_delete\": false } } } kibana磁盘满之后无法写入索引 PUT _settings { \"index\": { \"blocks\": { \"read_only_allow_delete\": \"false\" } } } ","date":"2024-10-15","objectID":"/posts/kibana/:0:0","tags":["kibana"],"title":"Kibana","uri":"/posts/kibana/"},{"categories":["kafka"],"content":" 查看topic bin/kafka-topics.sh --list --bootstrap-server 127.0.0.1:9092 查看某个topic信息 bin/kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --describe TOPICNAME 查看所有消费组 bin/kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group --all-groups 消费消息 bin/kafka-consumer-groups.sh --zookeeper 127.0.0.1:2181 --topic TOPICNAME 查看topic内容 bin/kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --from-beginning --topic TOPICNAME 创建topic bin/kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --partitions 1 --replication-factor 1 --topic TOPICNAME 删除topic bin/kafka-topics.sh --delete --bootstrap-server 127.0.0.1:9092 --topic TOPICNAME bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --list bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --describe --topic TOPICNAME bin/kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --list bin/kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group GROUPNAME bin/kafka-consumer-groups.sh --zookeeper 127.0.0.1:2181 --delete --group GROUPNAME bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic TOPICNAME ","date":"2024-10-15","objectID":"/posts/kafka/:0:0","tags":["kafka,efk"],"title":"Kafka","uri":"/posts/kafka/"},{"categories":["gitlab"],"content":"git lfs 问题 客户端配置：git config --system http.sslverify false 参考连接：https://blog.csdn.net/root_miss/article/details/81450687 gitlab邮箱配置 gitlab_rails['smtp_enable'] = true gitlab_rails['smtp_address'] = \"smtp.exmail.qq.com\" gitlab_rails['smtp_port'] = 25 gitlab_rails['smtp_user_name'] = \"gitlab@xxx.cn\" gitlab_rails['smtp_password'] = \"xxx\" gitlab_rails['smtp_domain'] = \"smtp.exmail.qq.com\" gitlab_rails['smtp_authentication'] = \"login\" gitlab_rails['smtp_ssl'] = false gitlab_rails['smtp_enable_starttls_auto'] = true gitlab_rails['gitlab_email_from'] = \"gitlab@xxx.cn\" user[\"git_user_email\"] = \"gitlab@xxx.cn\" gitlab迁移 gitlab备份 gitlab-rake gitlab:backup:create gitlab 定制相关数据服务 # 停止相关数据连接服务 gitlab-ctl stop unicorn gitlab-ctl stop sidekiq # 从1393513186编号备份中恢复 gitlab-rake gitlab:backup:restore BACKUP=1393513186 # 启动Gitlab gitlab-ctl start submodule add submodule to project git submodule add https://github.com/yyy/xxx.git DESTPATH list submodule git submodule delete submodule git submodule deinit pull submodule: when git clone add parms –recursive git clone https://github.com/xxx.git --recursive if you forget add –recursive git submodule update --init git submodule update --init --recursive update submodule git submodule update --remote change branch git config submodule.xxx.branch dev or git config -f .gitmodules submodule.xxx.branch dev gitconfig 常用配置 [alias] ch = checkou st = status staust = 'gitst' cf = config ck = checkout ft = fetch fh = fetch br = branch brv = branch --v geturl = config --get remote.origin.url bs = bisect lg = log --graph --decorate --oneline --all cfg = config --global cfga = config --global alias. pull = pl pl = pull --rebase cm = commit -c HEAD ps = push lsr = ls-remote --heads udc = reset HEAD~ ftg = fetch --tags am = commit -amend cmd = commit --amend rsh = reset HEAD~ cmi = commit --interactive -c HEAD --reset-author i = --interactive rss = reset --soft rmc = rm --cached cp = cherry-pick cpx = cherry-pick -x bl = blame gk = gitk ltn = ls-tree -r HEAD~ --name-only lt = ls-tree -r HEAD~ --name-only ltng = ls-tree -r HEAD~ --name-only |grep lgd = log -p --full-diff bcm = \"branch -a --contains \" brc = branch -a --contains tagc = tag --contains ","date":"2024-10-14","objectID":"/posts/gitlab/:0:0","tags":["gitlab"],"title":"Gitlab","uri":"/posts/gitlab/"},{"categories":["elasticsearch"],"content":"elasticsearch伸缩容 水平扩容 将现有集群中的一个节点镜像到一个新机器(主要是相关配置 插件都使用已有配置，避免再重新安装插件修改设置等) 更改 elasticsearch.yml 配置 # new add config node.master: false node.data: true # modify config node.name: new_instance_name network.host: real_intranet_address 清空数据目录 方案一：清空数据目录 # default path.data /var/lib/elasticsearch # exec shell rm -rf /var/lib/elasticsearch/*; 方案二：更改数据目录：path.data # new add config path.data: new_stroage_system_path # shell exec chown elasticsearch.elasticsearch /data/application/elasticsearch/ start services /etc/init.d/elasticsearch start 查看集群状态：http://ip:9200/_cat/health?v 查看分片迁移进度：http://ip:9200/#/overview?host=Pd_elasticsearch 查看恢复进度：http://ip:9200/_cat/recovery?v 待平衡完成后 修改索引对应的副本数 curl -XPUT \"\u003chttp://ip:9200/INDEXNAME/_settings\u003e\" -d '{ \"index\" : { \"number_of_replicas\" : 3 } }' http://ip:9200/INDEXNAME/list/_search?pretty\u0026from=0\u0026size=1 缩容操作 服务使用的es集群中应先剔除要下线的节点 恢复成之前的副本数量 curl -XPUT \"\u003chttp://ip:9200/INDEXNAME/_settings\u003e\" -d '{ \"index\" : { \"number_of_replicas\" : 2 } }' 排除es集群要下线的节点 curl -XPUT \"\u003chttp://ip:9200/_cluster/settings\u003e\" -d'{ \"transient\": { \"cluster.routing.allocation.exclude._ip\": \"要下线的ip\" } }' ","date":"2024-10-14","objectID":"/posts/elasticsearch/:0:0","tags":["elasticsearch"],"title":"Elasticsearch","uri":"/posts/elasticsearch/"},{"categories":["postgres"],"content":"导出 pg_dump -h IPADRESS -U USERNAME -t TABLENAME --column-inserts DATABASENAME \u003e BACKUPNAME.sql 表owner批量授权 REASSIGN OWNEDBY old_role [,...] TO new_role 主从配置 主节点配置 # 安装postgre # 切换postgres su - postgres # 登录 psql # 管理员用户配置密码 ALTER USER postgres WITH PASSWORD 'YourPassWord'; # 创建备份账号及权限 CREATE ROLE replica login replication encrypted password 'replica'; # 验证账号是否成功 SELECT usename from pg_user; # 验证权限 SELECT rolname from pg_roles; # 编辑pg_hba.conf,设置replica用户白名单 vim /var/lib/pgsql/9.6/data/pg_hba.conf host all all \u003c从节点的VPC IPv4网段\u003e md5 #允许VPC网段中md5密码认证连接 host replication replica \u003c从节点的VPC IPv4网段\u003e md5 #允许用户从replication数据库进行数据同步 # 编辑postgresql.conf vim /var/lib/pgsql/9.6/data/postgresql.conf # 分别找到以下参数 listen_addresses = '*' #监听的IP地址 wal_level = hot_standby #启用热备模式 synchronous_commit = on #开启同步复制 max_wal_senders = 32 #同步最大的进程数量 wal_sender_timeout = 60s #流复制主机发送数据的超时时间 max_connections = 100 #最大连接数，从库的max_connections必须要大于主库的 # 重启服务 systemctl restart postgresql-9.6.service 从节点配置 # 运行以下命令使用pg_basebackup基础备份工具指定备份目录。 pg_basebackup -D /var/lib/pgsql/9.6/data -h \u003c主节点IP\u003e -p 5432 -U replica -X stream -P # 依次运行以下命令新建并修改recovery.conf配置文件。 cp /usr/pgsql-9.6/share/recovery.conf.sample /var/lib/pgsql/9.6/data/recovery.conf vim /var/lib/pgsql/9.6/data/recovery.conf # 分别找到以下参数，并将参数修改为以下内容： standby_mode = on #声明此节点为从库 primary_conninfo = ‘host=\u003c主节点IP\u003e port=5432 user=replica password=replica’ #对应主库的连接信息 recovery_target_timeline = ‘latest’ #流复制同步到最新的数据 # 运行以下命令打开postgresql.conf文件。 vim /var/lib/pgsql/9.6/data/postgresql.conf max_connections = 1000 # 最大连接数，从节点需设置比主节点大 hot_standby = on # 开启热备 max_standby_streaming_delay = 30s # 数据流备份的最大延迟时间 wal_receiver_status_interval = 1s # 从节点向主节点报告自身状态的最长间隔时间 hot_standby_feedback = on # 如果有错误的数据复制向主进行反馈 # 运行以下命令修改数据目录的属组和属主 chown -R postgres.postgres /var/lib/pgsql/9.6/data 检测验证 # 检测验证需要主从节点之间存在数据交互，例如，从节点备份目录时，进行检测能够得到预期的结果。 pg_basebackup -D /var/lib/pgsql/96/data -h \u003c主节点IP\u003e -p 5432 -U replica -X stream -P # 在主节点中运行以下命令查看sender进程。 ps aux |grep sender # 在从节点中运行以下命令查看receiver进程。 ps aux |grep receiver # 在主节点中进入PostgreSQL交互终端，输入以下SQL语句，在主库中查看从库状态。 select * from pg_stat_replication; ","date":"2024-10-14","objectID":"/posts/postgres/:0:0","tags":["postgres"],"title":"Postgres","uri":"/posts/postgres/"},{"categories":["mysql"],"content":"常用命令 mysql导出 –skip-extended-insert 跳过多行写入 –skip-quote-names 跳过 ` 表名 –complete-insert 带字段的insert 结构导出 mysqldump -uroot -pxxx \\ --default-character-set=utf8 \\ --set-gtid-purged=off \\ --compact \\ --no-data \\ --databases xxx \\ --tables xxx \u003e $(date +%Y%m%d%H%M%S)_struct.sql 数据导出 mysqldump -uroot -pxxx \\ --default-character-set=utf8 \\ --set-gtid-purged=off \\ --compact \\ --no-create-info \\ --skip-quote-names \\ --complete-insert \\ --databases xxx \\ --tables xxx \u003e $(date +%Y%m%d%H%M%S)_data.sql 数据加条件导出 mysqldump -uroot -pxxx \\ --default-character-set=utf8 \\ --set-gtid-purged=off \\ --compact \\ --no-create-info \\ --skip-quote-names \\ --complete-insert \\ --databases xxx \\ --tables xxx \\ --where=\"sqlxxx\"\u003e $(date +%Y%m%d%H%M%S)_data.sql 整库备份 # 建表语句+数据 mysqldump -u USER -p -h HOST -B DATABASENAME --single-transaction --default-character-set=utf8 --set-gtid-purged=off \u003e DATABASENAME_$(date +%Y%m%d%H%M%S).sql binlog日志查看 mysqlbinlog --base64-output=decode-rows -v -v mysql-bin.021530 \u003e021530.sql 慢进程查看 select id,user,host,db,command,time,state,info from information_schema.PROCESSLIST order by time desc; Slave 链接 master 配置 CHANGE MASTER TO MASTER_HOST='IPADDRESS',MASTER_USER='UserName',MASTER_PASSWORD='PassWord',master_log_file='BinLogFile',master_log_pos=POSITION; 从库扩容备份操作 1. 备份到目标机器: innobackupex --defaults-file=/etc/my.cnf --no-timestamp --user=root --password=\"PassWord\" --compress --parallel=4 --compress-threads=4 --stream=xbstream /tmp/backup | ssh root@IPADDRESS \"xbstream -x -C /DSTDIR\" 2. 从库扩容操作: 目标机器解压 innobackupex --parallel=8 --decompress ./ 目标机器初始化 innobackupex --use-memory=51200M --apply-log ./ 目标机器恢复 innobackupex --defaults-file=/etc/my.cnf --copy-back ./2017-08-23_21-23-46/ 清理备份文件 find /var/lib/mysql -name \"*.qp\" | xargs rm chown -R mysql.mysql /var/lib/mysql mysql 从库繁忙配置： innodb_flush_log_at_trx_commit = 2 sync_binlog=1 set global innodb_flush_log_at_trx_commit=0; set global sync_binlog=0; mysql8.0密码更改原生： set global validate_password.policy=0; set global validate_password.length=1; ALTER user 'root'@'localhost' IDENTIFIED BY 'PASSWORD'; ALTER USER 'UserName'@'%' IDENTIFIED WITH mysql_native_password BY 'PassWord'; mysql slave 权限配置： CREATE USER 'rpl'@'172.16.1.%' IDENTIFIED BY 'xxx'; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'rpl'@'172.16.1.%'; information_schema 表空间优化 碎片大小 = 数据总大小 - 实际表空间文件大小 数据总大小 = Data_length + Index_length = 101842944 实际表空间文件大小 = rows_Avg_row_length = 101177624 碎片大小 = (101842944 - 101177624) / 1024 /1024 = 0.63MB 整理碎片 alter table table_name engine = innodb pt-online-schema-change optimize table 命令整理: show table status from DBNAME like ‘%TABLENAME%’ \\G 查看; pt-online-schema-change-shell #!/bin/bash source /etc/profile pt-online-schema-change \\ --defaults-file=/etc/my.cnf \\ -uroot -h localhost --password=PASSWORD \\ --alter=\"ENGINE=InnoDB\" \\ D=DBNAME,t=TABLENAME \\ 1--no-check-replication-filters --alter-foreign-keys-method=auto \\ 1--recursion-method=none --print \\ 1--charset=utf8 --max-load=\"Threads_running=100\" \\ 1--critical-load=\"Threads_running=200\" --execute 查看所有数据库的容量 SELECT table_schema as '数据库', sum(table_rows) as '记录数', sum(truncate(data_length/1024/1024, 2)) as '数据容量(MB)', sum(truncate(index_length/1024/1024, 2)) as '索引容量(MB)', sum(truncate(DATA_FREE/1024/1024, 2)) as '碎片占用(MB)' from information_schema.tables group by table_schema order by sum(data_length) desc, sum(index_length) desc; 查看指定库的大小 SELECT table_schema as '数据库', sum(table_rows) as '记录数', sum(truncate(data_length/1024/1024, 2)) as '数据容量(MB)', sum(truncate(index_length/1024/1024, 2)) as '索引容量(MB)', sum(truncate(DATA_FREE/1024/1024, 2)) as '碎片占用(MB)' from information_schema.tables where table_schema='DBNAME' order by data_length desc, index_length desc; 查看指定库所有表的大小 SELECT table_schema as '数据库', table_name as '表名', table_rows as '记录数', truncate(data_length/1024/1024, 2) as '数据容量(MB)', truncate(index_length/1024/1024, 2) as '索引容量(MB)', truncate(DATA_FREE/1024/1024, 2) as '碎片占用(MB)' from information_schema.tables where table_schema='DBNAM","date":"2024-10-12","objectID":"/posts/mysql/:0:0","tags":["mysql"],"title":"Mysql","uri":"/posts/mysql/"},{"categories":["apisix"],"content":"Nginx proxy_pass + / 问题: location /api { proxy_pass http://api_proxy/; } # 访问: http://api.xxx.com/api/admin; # 转发效果：http://api_proxy/admin; 由于Apisix 使用的是radixtree 的写法, 导致只支持匹配规则(Full match,Prefix matching) , 并且不会去掉匹配的路径, 这个时候, 为了去掉上面的 /api , 需要使用到插件：proxy-rewrite Apisix-Router：https://apisix.apache.org/zh/docs/apisix/terminology/router Proxy-rewrite：https://apisix.apache.org/zh/docs/apisix/plugins/proxy-rewrite ngx_http_rewirte_module：https://nginx.org/en/docs/http/ngx_http_rewrite_module.html ngx_http_proxy_module：https://nginx.org/en/docs/http/ngx_http_proxy_module.html ngx_stream_proxy_module：http://nginx.org/en/docs/stream/ngx_stream_proxy_module.html { \"uri\": \"/api*\", \"name\": \"api\", \"id\": \"489259072256738721\", \"upstream\": { \"type\": \"roundrobin\", \"pass_host\": \"pass\", \"nodes\": { \"10.1.1.1:3030\": 10 }, \"timeout\": { \"send\": 6, \"connect\": 6, \"read\": 6 }, \"scheme\": \"http\", \"keepalive_pool\": { \"idle_timeout\": 60, \"requests\": 1000, \"size\": 320 } }, \"plugins\": { \"proxy-rewrite\": { \"regex_uri\": [ \"^/api(.*)$\", \"$1\" ] } }, \"status\": 1, \"host\": \"api.xxx.com\" } ","date":"2024-10-12","objectID":"/posts/apisix/:0:0","tags":["apisix"],"title":"Apisix","uri":"/posts/apisix/"},{"categories":["macos"],"content":"安装lrsz brew install lrzsz iterm2-send-zmodem.sh #!/bin/bash osascript -e 'tell application \"iTerm2\" to version' \u003e /dev/null 2\u003e\u00261 \u0026\u0026 NAME=iTerm2 || NAME=iTerm if [[ $NAME = \"iTerm\" ]]; then FILE=$(osascript -e 'tell application \"iTerm\" to activate' -e 'tell application \"iTerm\" to set thefile to choose file with prompt \"Choose a file to send\"' -e \"do shell script (\\\"echo \\\"\u0026(quoted form of POSIX path of thefile as Unicode text)\u0026\\\"\\\")\") else FILE=$(osascript -e 'tell application \"iTerm2\" to activate' -e 'tell application \"iTerm2\" to set thefile to choose file with prompt \"Choose a file to send\"' -e \"do shell script (\\\"echo \\\"\u0026(quoted form of POSIX path of thefile as Unicode text)\u0026\\\"\\\")\") fi if [[ $FILE = \"\" ]]; then echo Cancelled. # Send ZModem cancel echo -e \\\\x18\\\\x18\\\\x18\\\\x18\\\\x18 sleep 1 echo echo \\# Cancelled transfer else /usr/local/bin/sz \"$FILE\" --escape --binary --bufsize 4096 sleep 1 echo echo \\# Received \"$FILE\" fi iterm2-recv-zmodem.sh #!/bin/bash osascript -e 'tell application \"iTerm2\" to version' \u003e /dev/null 2\u003e\u00261 \u0026\u0026 NAME=iTerm2 || NAME=iTerm if [[ $NAME = \"iTerm\" ]]; then FILE=$(osascript -e 'tell application \"iTerm\" to activate' -e 'tell application \"iTerm\" to set thefile to choose folder with prompt \"Choose a folder to place received files in\"' -e \"do shell script (\\\"echo \\\"\u0026(quoted form of POSIX path of thefile as Unicode text)\u0026\\\"\\\")\") else FILE=$(osascript -e 'tell application \"iTerm2\" to activate' -e 'tell application \"iTerm2\" to set thefile to choose folder with prompt \"Choose a folder to place received files in\"' -e \"do shell script (\\\"echo \\\"\u0026(quoted form of POSIX path of thefile as Unicode text)\u0026\\\"\\\")\") fi if [[ $FILE = \"\" ]]; then echo Cancelled. # Send ZModem cancel echo -e \\\\x18\\\\x18\\\\x18\\\\x18\\\\x18 sleep 1 echo echo \\# Cancelled transfer else cd \"$FILE\" /usr/local/bin/rz --rename --escape --binary --bufsize 4096 sleep 1 echo echo echo \\# Sent \\-\\\u003e $FILE fi iterm2 triggers配置 Regular expression: rz waiting to receive.\\*\\*B0100 Action: Run Silent Coprocess Parameters: /usr/local/bin/iterm2-send-zmodem.sh Instant: checked Regular expression: \\*\\*B00000000000000 Action: Run Silent Coprocess Parameters: /usr/local/bin/iterm2-recv-zmodem.sh Instant: checked ","date":"2024-10-12","objectID":"/posts/lrzsz/:0:0","tags":["macos"],"title":"Lrzsz","uri":"/posts/lrzsz/"},{"categories":["tomcat"],"content":"版本号隐藏 进入到tomcat 目录 mv webapps/ROOT webapps/ROOT mkdir webapps/ROOT$(date +%Y%m%d) 编辑conf/server.xml配置文件中的配置项中添加如下配置： \u003cValve className=\"org.apache.catalina.valves.ErrorReportValve\" showReport=\"false\" showServerInfo=\"false\" /\u003e 修改后再次访问，返回404 ","date":"2024-10-12","objectID":"/posts/tomcat/:0:0","tags":["tomcat"],"title":"Tomcat","uri":"/posts/tomcat/"},{"categories":["java"],"content":"java home 配置 vim /etc/profile export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.312.b07-10.p01.ky10.aarch64/jre/ export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar Java • Jcmd 开启java 进程remote 端口 jcmd 20364 ManagementAgent.start jmxremote.port=9999 jmxremote.ssl=false jmxremote.authenticate=false -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9999 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=10.1.219.21 • Java dump堆栈信息 jmap -dump:format=b,file=VipQuickRoutePlatAsyn.dat 29473 ","date":"2024-10-12","objectID":"/posts/java/:0:0","tags":["java"],"title":"Java","uri":"/posts/java/"},{"categories":["golang"],"content":"build_packages go打包命令 # 常规打包方法 go build # 使用 “-dflags” 缩小大小 go build -ldflags '-w -s' # 使用upx打包为最小程序 upx ...二进制文件 示例 CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o target/NAME_`date +%Y_%m_%d` ${MAINSRCPATH} CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -ldflags '-w -s' -o pkg/PACKAGENAME multi_platfrom_build ● Mac 打包Linux windows $ CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build test.go $ CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build test.go ● Linux打包Mac windows $ CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build test.go $ CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build test.go ● windows编译Linux Mac $ SET CGO_ENABLED=0SET GOOS=darwin3 SET GOARCH=amd64 go build test.go $ SET CGO_ENABLED=0 SET GOOS=linux SET GOARCH=amd64 go build test.go 参数说明 GOOS：目标可执行程序运行操作系统，支持 darwin，freebsd，linux，windows GOARCH：目标可执行程序操作系统构架，包括 386，amd64，arm go 代理配置 go env -w GOPROXY=https://goproxy.cn,direct fmt 使用 General %v // 以默认的方式打印变量的值 %T // 打印变量的类型 Integer %+d // 带符号的整型，fmt.Printf(\"%+d\", 255)输出+255 %q // 打印单引号 %o // 不带零的八进制 %#o // 带零的八进制 %x // 小写的十六进制 %X // 大写的十六进制 %#x // 带0x的十六进制 %U // 打印Unicode字符 %#U // 打印带字符的Unicode %b // 打印整型的二进制 Integer width %5d // 表示该整型最大长度是5，下面这段代码 %-5d // 则相反，打印结果会自动左对齐 %05d // 会在数字前面补零。 Float %f(=%.6f) // 6位小数点 %e(=%.6e) // 6位小数点（科学计数法） %g // 用最少的数字来表示 %.3g // 最多3位数字来表示 %.3f // 最多3位小数来表示 String %s //正常输出字符串 %q //字符串带双引号，字符串中的引号带转义符 %#q //字符串带反引号，如果字符串内有反引号，就用双引号代替 %x //将字符串转换为小写的16进制格式 %X //将字符串转换为大写的16进制格式 %x //带空格的16进制格式 String Width (以5做例子） %5s // 最小宽度为5 %-5s // 最小宽度为5（左对齐） %.5s // 最大宽度为5 %5.7s // 最小宽度为5，最大宽度为7 %-5.7s // 最小宽度为5，最大宽度为7（左对齐） %5.3s // 如果宽度大于3，则截断 %05s // 如果宽度小于5，就会在字符串前面补零 Struct %v // 正常打印。比如：{sam {12345 67890}} %+v // 带字段名称。比如：{name:sam phone:{mobile:12345 office:67890} %#v // 用Go的语法打印。 // 比如main.People{name:\"sam\", phone:main.Phone{mobile:\"12345\", office:\"67890\"}} Boolean %t // 打印true或false Pointer %p // 带0x的指针 %#p // 不带0x的指针 ","date":"2024-10-12","objectID":"/posts/golang/:0:0","tags":["golang"],"title":"Golang","uri":"/posts/golang/"}]