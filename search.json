[{"categories":["kubernetes"],"content":"资源清单格式 apiVersion: group/apiversion # 指定当前的组和版本（写的资源清单具体去哪个路径下调代码）。如果没有给定 group 名称，那么默认为 core，可以使用 kubectl api-versions # 获取当前 k8s 版本上所有的 apiVersion 版本信息( 每个版本可能不同 ) kind: Service #资源类别 metadata: #资源元数据 name: pod-demo #资源对象名称； namespace: default #使用名称级别的资源才需要填写； #处于default名称空间下； lables: #标签，筛选操作；一般用于集群内部的筛选功能； app: myapp #标签 annotations: # 主要目的是方便用户阅读查找 spec: # 期望的状态（disired state） containers: #代表mainC； - name: myapp-1 #mainC子对象1名称；列表开头使用 -开头 image: wangyanglinux/myapp:v1 - name: busybox-1 #mainC子对象2名称； image: busybox:1.35.0 command: #此处代表的是ENTRYPOINT； - \"/bin/sh\" - \"-c\" - \"sleep 3600\" status: # 当前状态，本字段有 Kubernetes 自身维护，用户不能去定义 ","date":"2025-01-07","objectID":"/posts/kubernetes/:1:0","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"字段格式配置 apiVersion \u003cstring\u003e #表示字符串类型 metadata \u003cObject\u003e #表示需要嵌套多层字段 labels \u003cmap[string]string\u003e #表示由k:v组成的映射 finalizers \u003c[]string\u003e #表示字串列表 ownerReferences \u003c[]Object\u003e #表示对象列表 hostPID \u003cboolean\u003e #布尔类型 priority \u003cinteger\u003e #整型 name \u003cstring\u003e -required- #如果类型后面接 -required-，表示为必填字段 ","date":"2025-01-07","objectID":"/posts/kubernetes/:2:0","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"常用资源清单格式定义 Object ：对象，下方是对象的属性 list：类别，下方包含多个数组，每个数组是一个对象 String：字符串 后边直接跟value的值 ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:0","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"通用字段 参数名 字段类型 说明 version String 这里是指的是K8S API的版本，目前基本上是v1，可以用kubectl apiversions命令音询 kind String 这里指的是yamI文件定义的资源类型和角色，比如: Pod metadata Object 元数据对象，固定值就写metadata Spec bject 详细定义对象，固定值就写Spec ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:1","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"metadate相关字段 参数名 字段类型 说明 metadata Object 元数据对象，固定值就写metadata metadata.name String 元数据对象的名字，这里由我们编写，比如命名Pod的名字 metadata.lables list 标签列表。有key=value组成 ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:2","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"pod相关字段 参数名 字段类型 说明 spec.restartPolicy String 定义Pod的重启策略，可选值为Always、OnFailure，默认值为Always。1.Always: Pod一旦终止运行，则无论容器是如何终止的，kubelet服务都将重启它。2.OnFailure: 只有Pod以非零退出码终止时，kubelet才会重启该容器。如果容器正常结束 (退出码为0) ，则kubelet将不会重启它3.Never: Pod终止后，kubelet将退出码报告给Master，不会重启该Pod. spec.nodeSelector Object 定义Node的Label过滤标签，以key:value格式指定 spec.imagePullSecrets Object 定义pull镜像时使用secret名称，以name:secretkey格式指定 spec.hostNetwork Boolean 定义是否使用主机网络模式，默认值为false。设置true表示使用宿主机网络，不使用docker网桥，同时设置了true将无法在同一台宿主机上启动第二个副本。 sepc.NodeName string 定义pod要调度的节点，可以忽略污点，还是要预选、优选。 mainC字段 参数名 字段类型 说明 spec.containers[] list 这里是Spec对象的容器列表定义，是个列表 spec.containers[].name String 这里定义容器的名字 spec.containers[].image String 这里定义要用到的镜像名称 spec.containers[].imagePullPolicy String 定义镜像拉取策略，有Always、Never、lfNotPresent三个值可选 (1) Aways: 意思是每次都尝试重新拉取镜像 (2) Never: 表示仅使用本地镜像 (3) lfNotPresent: 如果本地有镜像就使用本地镜像，没有就拉取在线镜像。上面三个值都没设置的话，默认是Always。 spec.containers[].command[] List 指定容器启动命令，因为是数组可以指定多个，不指定则使用镜像打包时使用的启动命令 spec.containers[].args[] List 指定容器启动命令参数，因为是数组可以指定多个。 spec.containers[].workingDir string 指定容器的工作目录 spec.containers[].volumeMounts[] List 指定容器内部的存储卷配置 spec.containers[].volumeMounts[].name String 指定可以被容器挂载的存储卷的名称 spec.containers[].volumeMounts[].mountPath string 指定可以被容器挂载的存储卷的路径 spec.containers[].volumeMounts[].readOnly string 设置存储卷路径的读写模式，ture 或者false默认为读写模式 spec.containers[].ports[] List 指定容器需要用到的端口列表 spec.containers[].ports[].name String 指定端口名称 spec.containers[].ports[].containerPort String 指定容器需要监听的端口号 spec.containers[].ports[].hostPort String 指定容器所在主机需要监听的端口号，默认跟上面containerPort相同，注意设置了hostPort同一台主机无法启动该容器的相同副本 (因为主机的端口号不能相同，这样会冲突) spec.containers[].ports[].protocol String 指定端口协议，支持TCP和UDP，默认值为TCP spec.containers[].env[] List 指定容器运行前需设置的环境变量列表 spec.containers[].env[].name string 指定环境变量名称 spec.containers[].env[].value String 指定环境变量值 spec.containers[].resources Object 指定资源限制和资源请求的值 (这里开始就是设置容器的资源上限) spec.containers[].resources.limits Object 指定设置容器运行时资源的运行上限 spec.containers[].resources.limits.cpu String 指定CPU的限制，单位为core数，将用于docker run –cpu-shares参数 (这里前面文章Pod资源限制有讲过) spec.containers[].resources.limits.memory String 指定MEM内存的限制，单位为MIB、GiB spec.containers[].resources.requests Object 指定容器启动和调度时的限制设置 spec.containers[].resources.requests.cpu String CPU请求，单位为core数，容器启动时初始化可用数量 spec.containers[].resources.requests.memory String 内存请求，单位为MIB、GiB，容器启动的初始化可用数量 就绪探针 参数名 字段类型 说明 spec.containers.readinessProbe Object 定义容器的就绪探测策略。有三种模式可选:exec：返回码为0为就绪tcpsoket：tcp 对应检测端口响应成功为就绪httpget：返回码 \u003e= 200 \u0026\u0026 \u003c 400 为就绪 spec.containers.readinessProbe.exec list 定义容器的就绪探测策略为exec。 spec.containers.readinessProbe.exec.command List exec所对应的命令 spec.containers.readinessProbe.initialDelaySeconds init 探测开始时间 spec.containers.readinessProbe.periodSeconds init 探测间隔时间。s为单位 存活探针 参数名 字段类型 说明 spec.containers.livenessProbe object 定义容器的就绪探测策略。有三种模式可选:exec：返回码为0为就绪tcpsoket：tcp 对应检测端口响应成功为就绪httpget：返回码 \u003e= 200 \u0026\u0026 \u003c 400 为就绪 spec.containers.livenessProbe.httpGet object 定义容器的就绪探测策略为httpGet。 spec.containers.livenessProbe.httpGet.port init 探测的端口 spec.containers.livenessProbe.httpGet.path string 探测的文件。根为网页根路径 spec.containers.livenessProbe.initialDelaySeconds init 探测开始时间 spec.containers.livenessProbe.periodSeconds init 探测间隔时间。s为单位 spec.containers.livenessProbe.timeoutSeconds init 探测超时时间，超时后就是探测失败 钩子字段 参数名 字段类型 说明 spec.containers.lifecycle object 定义钩子 spec.containers.lifecycle.postStart object 定义启动后的钩子 spec.containers.lifecycle.preStop object 定义退出前钩子 spec.containers.lifecycle.postStart.exec object 定义启动后的钩子动作为命令 spec.containers.lifecycle.postStart.exec.command list 定义启动后的钩子详细动作 initC字段 与容器字段通过，只不过把containers换成initcontainers 参数名 字段类型 说明 spec.initcontainers[] list 这里是Spec对象的容器列表定义，是个列表，定义initC容器 spec.initcontainers[].name String 这里定义容器的名字 spec.initcontainers[].image String 这里定义要用到的镜像名称 spec.initcontainers[].command[] List 指定容器启动命令，因为是数组可以指定多个，不指定则使用镜像打包时使用的启动命令 ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:3","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"控制器通用字段 参数名 字段类型 说明 spec.replicas init 副本数（pod数量） spec.template object pod模板，内容就是pod中的字段内容 spec.selector object 标签匹配（用来区分是谁的pod），将适合的pod加入到该该控制器下 内容是：标签：值 spec.minReadySeconds init 用定义新建的 Pod 经过多少秒后才被视为可用，默认为0。 spec.backoffLimit init 失败次数达到指定次数之后进入懒启动状态（重建间隔时间长） 标签选择—标签选择器 处理RC其他都支持 参数名 字段类型 说明 spec.selector object 标签匹配（用来区分是谁的pod），将适合的pod加入到该该控制器下 spec.selector.matchLabels[] list 集合式的标签匹配（用来区分是谁的pod），将适合的pod加入到该该控制器下内容是：标签：值（RS支持） spec.selector.matchExpressions[] object 支持运算符匹配进行标签选择（用来区分是谁的pod），将适合的pod加入到该该控制器下内容是：key： xxxxoperator: 运算符vlaues：- xxxx spec.selector.matchExpressions[].key string 标签选择器的key字段 spec.selector.matchExpressions.operator string 标签选择的运算符，有In、NotIn、Exists、DoesNotExist 四个值可选In ：label 的值在某个列表中（根据value的值进行选择）NotIn ：label 的值不在某个列表中Exists ：某个 label 存在（根据key进行选择）DoesNotExist：某个 label 不存在 spec.selector.matchExpressions[].values list 标签选择器下的value字段 ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:4","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"RC 控制器 参数名 字段类型 说明 spec.selector list 标签匹配（用来区分是谁的pod），将适合的pod加入到该该控制器下 内容是：标签：值 RC （ReplicationController ）主要的作用就是用来确保容器应用的副本数始终保持在用户定义的副本数 。即如果有容器异常退出，会自动创建新的Pod来替代；而如果异常多出来的容器也会自动回收（回收最晚创建的） 根据标签确认是否输入控制器 不支持集合式的标签匹配 ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:5","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"RS控制器 参数名 字段类型 说明 spec.minReadySeconds init 用定义新建的 Pod 经过多少秒后才被视为可用，默认为0。 spec.selector.matchLabels[] list 集合式的标签匹配（用来区分是谁的pod），将适合的pod加入到该该控制器下内容是：标签：值（RS支持） spec.selector.matchExpressions[] object 支持运算符匹配进行标签选择（用来区分是谁的pod），将适合的pod加入到该该控制器下内容是：key： xxxxoperator: 运算符vlaues：xxxx spec.selector.matchExpressions[].key string 标签选择器的key字段 spec.selector.matchExpressions.operator string 标签选择的运算符，有In、NotIn、Exists、DoesNotExist 四个值可选In ：label 的值在某个列表中（根据value的值进行选择）NotIn ：label 的值不在某个列表中Exists ：某个 label 存在（根据key进行选择）DoesNotExist：某个 label 不存在 spec.selector.matchExpressions[].values list 标签选择器下的value字段 ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:6","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"deployment控制器 参数名 字段类型 说明 spec.minReadySeconds init 用定义新建的 Pod 经过多少秒后才被视为可用，默认为0。 spec.selector list 默认标签选择器。默认是matchLabels子集形式进行匹配 spec.selector.matchLabels[] list 集合式的标签匹配（用来区分是谁的pod），将适合的pod加入到该该控制器下内容是：标签：值 spec.selector.matchExpressions[] object 支持运算符匹配进行标签选择（用来区分是谁的pod），将适合的pod加入到该该控制器下内容是：key： xxxxoperator: 运算符vlaues：xxxx spec.selector.matchExpressions[].key string 标签选择器的key字段 spec.selector.matchExpressions.operator string 标签选择的运算符，有In、NotIn、Exists、DoesNotExist 四个值可选In ：label 的值在某个列表中（根据value的值进行选择）NotIn ：label 的值不在某个列表中Exists ：某个 label 存在（根据key进行选择）DoesNotExist：某个 label 不存在spec.selector.matchExpressions[].values list 标签选择器下的value字段sepc.revisionHistoryLimit init 设置保留的滚动更新历史版本数量，默认值为2147483647,表示保存所有历史版本spec.strategy.type string 部署类型，可以选择 的值为ecreate (字母开头大写) 或 RollingUpdate , 默认为 RollingUpdate 。 Deployment.spec.strategy.Recreate 滚动更新方式为重建 Deployment.spec.strategy.rollingUpdate 映射 滚动更新方式为滚动更新 Deployment.spec.strategy.rollingUpdate.maxSurge init 设置更新时pod最多多几个（或者指定百分比） Deployment.spec.strategy.rollingUpdate.maxUnavailable init 设置更新时pod最多几个不可用（或者指定百分比） Deployment.spec.revisonHistoryLimit init 指定 deployment 最多保留多少 镜像版本修改的历史记录。默认的会保留所有的 revision；如果将该项设置为0，Deployment 就不允许回退了 ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:7","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"job控制器 参数名 字段类型 说明 spec.template – 格式同Pod相同 spec.template.spec.restartPolicy String 仅支持Never或OnFailure，需要修改定义Pod的重启策略，可选值为Always、OnFailure，默认值为Always。1.Always: Pod一旦终止运行，则无论容器是如何终止的，kubelet服务都将重启它。2.OnFailure: 只有Pod以非零退出码终止时，kubelet才会重启该容器。如果容器正常结束 (退出码为0) ，则kubelet将不会重启它3.Never: Pod终止后，kubelet将退出码报告给Master，不会重启该Pod. spec.completions init 标志Job结束需要成功运行的Pod个数，默认为1 spec.parallelism init 标志并行运行的Pod的个数，默认为1 spec.activeDeadlineSeconds init 标志失败Pod的重试最大时间，超过这个时间不会继续重试。秒为单位 ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:8","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"CronJob控制器 参数名 字段类型 说明 .spec.schedule string 调度，必需字段，指定任务运行周期，格式同 Cron。如：“*/1 * * * *” spec.completions init 标志Job结束需要成功运行的Pod个数，默认为1 spec.parallelism init 标志并行运行的Pod的个数，默认为1 spec.concurrencyPolicy string -并发策略，该字段也是可选的。它指定了如何处理被 Cron Job 创建的 Job 的并发执行。只允许指定下面策略中的一种：Allow（默认）：允许并发运行 JobForbid：禁止并发运行，如果前一个还没有完成，则直接跳过下一个Replace：取消当前正在运行的 Job，用一个新的来替换 spec.suspend string 挂起，该字段也是可选的。有true、false两个值可以选择。如果设置为 true，后续所有执行都会被挂起。它对已经开始执行的 Job 不起作用。默认值为 false spec.successfulJobsHistoryLimit init 历史限制。是可选的字段。它们指定了可以保留多少完成的 Job。默认为3 spec.failedJobsHistoryLimit init 历史限制。是可选的字段。它们指定了可以保留多少失败的 Job。默认为0 spec.activeDeadlineSeconds init 标志失败Pod的重试最大时间，超过这个时间不会继续重试。该字段是可选的。如果因为任何原因而错过了被调度的时间，那么错过执行时间的 Job 将被认为是失败。秒为单位 spec.jobTemplate object 的。如果没有指定，则没有期限Job 模板，必需字段，指定需要运行的任务，格式同 JobjobTemplate.spec.template – 格式同Pod相同jobTemplate.spec.template.spec.restartPolicy String 仅支持Never或OnFailure，需要修改定义Pod的重启策略，可选值为Always、OnFailure，默认值为Always。1.Always: Pod一旦终止运行，则无论容器是如何终止的，kubelet服务都将重启它。2.OnFailure: 只有Pod以非零退出码终止时，kubelet才会重启该容器。如果容器正常结束 (退出码为0) ，则kubelet将不会重启它3.Never: Pod终止后，kubelet将退出码报告给Master，不会重启该Pod. ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:9","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"service 参数名 字段类型 是否必选 取值说明 .apiVersion string Required v1 .kind string Required Service .metadata object Required 元数据 .metadata.name string Required Service名称，需符合RFC 1035规范 .metadata.namespace string Required 命名空间，不指定系统时将使用名为default的命名空间 .metadata.labels [] list 自定义标签属性列表 .metadata.annotation[] list 自定义注解属性列表 .spec object Required 期望描述 .spec.selector[] list Required Label Selector配置，将选择具有指定Label标签的Pod作为管理范围 .spec.type string Requited Service的类型，指定Service的防问方式，默认值为ClusterIP。取值可有：ClusterIP、NodePort、LoadBalancer。 .spec.clusterIP string 虚拟服务的IP地址，当type=ClusterIP时，如果不指定，则系统自动分配，也可以手工分配；当type=LoadBalancer时，需要指定 .spec.sessionAffinity string 会话保持字段是否支持Session,可选值为ClientIP,默认值为None。ClientIP:表示将同一个客户端（根据客户端的IP地址决定）的访问请求都转发到同一个后端Pod .spec.ports[] list Service端口列表 .spec.ports[].name string 端口名称 .spec.ports[].protocol string 端口协议，支持TCP和UDP，默认值为TCP .spec.ports[].port int 服务监听的端口号 .spec.ports[].targetPort int 需要转发到后端Pod的端口号 .spec.ports[].nodePort int 当spec.type=NodePort时，指定映射到宿主机的端口号 .status object 当spec.type=LoadBalancer时，设置外部负载均衡器的地址 .status.loadBalancer object 外部负载均衡器 .status.loadBalancer.ingress object 外部负载均衡器 .status.loadBalancer.ingress.ip string 外部负载均衡器的IP地址 .status.loadBalancer.ingress.hostname string 外部负载均衡器的主机名 ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:10","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"Endpoint 作用：连接外部服务值本地svc 原理：只有配置了 selector 的 service 才会自动创建一个同名的 endpoints，没有配置 selector 的 service 不会产生 endpoints 资源对象 参数名 字段类型 说明 metadata.name string 必需字段，必须与要匹配的svc名字完全一致，并且在同一名字空间中 svc.subsets object #配置外部集群信息（一级字段） subsets.address list 外部地址 subsets.ports list 外部端口 apiVersion: v1 kind: Service metadata: name: nginx spec: ports: - protocol: TCP port: 6666 targetPort: 80 --- apiVersion: v1 kind: Endpoints metadata: name: nginx #名字必须与svc名字完全一致，并且在同一名字空间中 subsets: #配置外部集群信息 - addresses: #外部地址 - ip: 192.168.110.102 # - ip: xxxxxx 跟踪多个 ip (多个 pod 或者容器或者应用)，可以使用以下方式 ports: - port: 80 #外部端口 ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:11","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"ingress Ingress（入口，准入）是Kubernetes提供的接口，Kubernetes使用Ingress策略定义和Ingress Controller 实现了基于Ingress策略定义的服务路由功能，用于对Kubernetes集群外部的客户端提供服务。 Ingress 专门对接用于七层负载的 参数名 字段类型 说明 Ingress.spec.rules list 规则设置 spec.rules.host string 代理到的域名 spec.rules.http object 基于http协议 spec.rules.http.path list 访问的网址路径 spec.rules.http.path.paths string 访问的网址路径是哪个 spec.rules.http.path.paths.backend object 代理设置 spec.rules.http.path.paths.backend.serviceName string 代理到哪个svc spec.rules.http.path.paths.backend.servicePort string 代理的端口 ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:12","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"configmap 创建方式：使用命令创建，在命令中 下方是如何使用： 在资源清单中添加环境变量 字段 字段类型 描述 pod.spec.containers.env list 要在容器中设置的环境变量列表。 无法更新。 EnvVar 表示容器中存在的环境变量。 pod.spec.containers.env.name string 环境变量的Key值，必须设置。 pod.spec.containers.env.value string 设置环境变量的Value，可以使用 $(VAR_NAME) 的方式对容器中的环境变量进行引用。 $(VAR_NAME) 表示对 $ 进行转义，会将$(VAR_NAME) 以值的方式设置为环境变量的值而不是将其展开。 通过ConfigMap逐个添加env（变量名容器内二次定义） key=容器定义。value=configmap中的key的value 字段 字段类型 描述 pod.spec.containers.env list 要在容器中设置的环境变量列表。 无法更新。 EnvVar 表示容器中存在的环境变量。 pod.spec.containers.env.valueFrom object 环境变量值的源。如果值不为空，则无法使用。 pod.spec.containers.env.valueFrom.configMapKeyRef object 选择configMap中的一个Key值的字段。 pod.spec.contaienrs.env.valueFrom.configMapKeyRef.name string 指定configMap的名字 pod.spec.containers.env.valueFrom.configMapKeyRef.key string 指定configMap引用的key值，会将对应的value赋予环境变量的value值。 pod.spec.contianers.env.valueFrom.configMapKeyRef.optional boolean 指定configMap和key值是否必需预先定义好逐个添加env（没学，不用看） 通过ConfigMap批量添加env（变量名无法二次定义） key=configmap中的key。value=configmap中的key的value 字段 字段类型 描述 pod.spec.contianers.envFrom list 用于在容器中填充 环境变量的源列表 ，格式必须为C_IDENTIFIER(C语言标识符格式标准) 。如果Key值无效则报告为事件，如果key重复，则以最后的为准，环境变量注入 无法被更新 。 pod.spec.containers.envFrom.configMapRef Object 选择ConfigMap，注入环境变量 pod.spec.containers.envFrom.configMapRef.name string ConfigMap的名称 pod.spec.containers.optional boolean （没学，不用看）指定configMap是否需要被预先定义好 通过数据卷插件使用configmap 将文件填入数据卷。key就是文件名，value就是文件内容 字段 字段类型 描述 pod.sepc.containers.volumeMounts list 挂载一个卷 pod.sepc.containers.volumeMounts.name string 挂载的卷名 pod.sepc.containers.volumeMounts.mountPath srting 挂载到哪个目录下 pod.sepc.volumes list 定义卷 pod.sepc.volumes.name string 卷名 pod.sepc.volumes.name.configMap object 卷来源是configmap pod.sepc.volumes.name.configMap.name string configmap的名字 configmap的热更新（修改 pod annotations 的方式） 更新 ConfigMap 目前并不会触发相关 Pod 的滚动更新，可以通过修改 pod annotations 的方式强制触发滚动更新 这个例子里我们在 .spec.template.metadata.annotations 中添加 version/config，每次通过修改 version/config的值 来触发滚动更新 $ kubectl patch deployment nginx-test --patch '{\"spec\": {\"template\": {\"metadata\": {\"annotations\": {\"version/config\": \"20190411\" }}}}}' # 在其中添加此字段即可滚动更新，修改也可以触发滚动更新 使用该 ConfigMap 挂载的 Env 不会同步更新 使用该 ConfigMap 挂载的 Volume 中的数据需要一段时间（实测大概10秒）才能同步更新 ⚠️ 注意：apps/v1版本的api接口，默认滚动幅度为25% ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:13","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"secret service Account 用来访问 Kubernetes API，由 Kubernetes 自动创建，并且会自动挂载到 Pod 的 /run/secrets/kubernetes.io/serviceaccount 目录中。专门用于集群安全中pod的认证。 Opaque Secret 类似于 configmap，但是 value 字段是编码的value 数据必须是原数据经过 base64 编码以后的结果，secret 在使用的时候，value 会被自动解码 字段 字段类型 描述 secret.type string secret类型。有三种类型、service Account、opaque 、dockerconfigjson。本处写opaque secret.data list 数据段。格式：key=value；value必须是过 base64 编码以后的结果 kubernetes.io/dockerconfigjson 使用 Kuberctl 命令创建 docker 仓库认证的 secret，命令中有写到。资源清单不在做描述 ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:14","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"volume emptyDir（空目录） 当 Pod 被分配给节点时，首先创建 emptyDir 卷，并且只要该 Pod 在该节点上运行，该卷就会存在。正如卷的名字所述，它最初是空的。Pod 中的容器可以读取和写入 emptyDir 卷中的相同文件，尽管该卷可以挂载到每个容器中的相同或不同路径上。当出于任何原因从节点中删除 Pod 时，emptyDir 中的数据将被永久删除 用法：pod的暂存空间。（存放initC执行结果、容器运行产生元数据-mfsmaster的元数据日志） ⚠️注意：emptyDir跟pod生命周期一致。容器崩溃不会从节点中移除 pod，因此 emptyDir 卷中的数据在容器崩溃时是安全的 字段 字段类型 描述 pod.spec.volumes list 定义卷 pod.spec.volumes.name string 卷名 pod.spec.volumes.emptyDir string 卷类型是emptydir。value值为{ }emptyDir: {} pod.sepc.containers.volumeMounts list 挂载一个卷 pod.sepc.containers.volumeMounts.name string 挂载的卷名 pod.sepc.containers.volumeMounts.mountPath srting 挂载到哪个目录下 hostPath hostPath卷将主机节点的文件系统中的文件或目录挂载到集群中，可对主机文件/目录进行判断，判断是否存在，存在是否合理，并做出动作 字段 字段类型 描述 pod.sepc.containers.volumeMounts list 挂载一个卷 pod.sepc.containers.volumeMounts.name string 挂载的卷名 pod.sepc.containers.volumeMounts.mountPath string 挂载到哪个目录下 pod.spec.volumes list 定义卷 pod.spec.volumes.name string 卷名 pod.spec.volumes.hostPath object 卷类型为hostpath pod.spec.volumes.hostPath.path string 卷的物理机路径（主机上的目录位置） pod.spec.volumes.hostPath.type string key值填hostPath卷的类型。有八个值可选，下方详解。 hostPath卷类型的vlaue值 值 行为 空字符串（默认）用于向后兼容，这意味着在挂载 hostPath 卷之前不会执行任何检查。（不检查直接使用） DirectoryOrCreate 如果在给定的路径上没有任何东西存在，那么将根据需要在那里创建一个空目录，权限设置为 0755，与 Kubelet 具有相同的组和所有权**（就是节点所在的Kubelet创建的）。（如果目录不存在则创建一个空目录，存在的是个文件则报错）** Directory 给定的路径下必须存在目录，不存在则报错 FileOrCreate 如果在给定的路径上没有任何东西存在，那么会根据需要创建一个空文件，权限设置为 0644，与 Kubelet 具有相同的组和所有权。（如果文件不存在则创建空文件，存在的是个目录则报错） File 给定的路径下必须存在文件，否则报错。 Socket 给定的路径下必须存在 UNIX 套接字，否则报错。 CharDevice 给定的路径下必须存在字符设备，否则报错。 BlockDevice 给定的路径下必须存在块设备，否则报错。 ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:15","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"PVC持久化卷 PV 类别是：PersistentVolume PV 也是集群中的资源。 PV 是 Volume 之类的卷插件，但具有独立于使用 PV 的 Pod 的生命周期。可被PVC调用提供给pod 字段 字段类型 描述 spec.capacity object pv容量 spec.capacity.storage string pv的大小。5Gi表示5GB spec.volumeMode string 卷模式。写Filesystem即可 spec.accessModes string 访问模式（读写策略）。三个值可选 ReadWriteOnce——该卷可以被单个节点以读/写模式挂载ReadOnlyMany——该卷可以被多个节点以只读模式挂载ReadWriteMany——该卷可以被多个节点以读/写模式挂载 spec.persistentVolumeReclaimPolicy string 卷的回收策略，三个值可选Retain（保留）——手动回收（基本都用这个）Recycle（回收）——基本擦除（rm -rf /thevolume/*）Delete（删除）——关联的存储资产，用于动态pv。此策略会将卷直接删除—-节省成本 sepc.storageClassName string 定义存储类的类名（是自定义的，严格匹配） sepc.nfs object 通过nfs提供底层数据存储 sepc.nfs.path string nfs共享的路径 sepc.nfs.server string nfs的地址 Retain（保留）——手动回收（基本都用这个） Recycle（回收）——基本擦除（rm -rf /thevolume/*） Delete（删除）——关联的存储资产（例如 AWS EBS、GCE PD、Azure Disk 和 OpenStack Cinder 卷）将被删除—-节省成本 PVC pvc是用户存储的请求。它与Pod相似。Pod消耗节点资源，PVC消耗PV资源。Pod可以请求特定级别的资源（CPU和内存）。声明可以请求特定的大小和访问模式（例如，可以以读/写一次或只读多次模式挂载） 声明需要在StatefulSet控制器中进行声明 StatefulSet是为了 解决有状态服务的问题 （对应 Deployments 和 ReplicaSets 是为无状态服务而设计），需要配合无头服务Service使用 其特性包括： 稳定的存储：即 Pod 重新调度后还是能访问到相同的持久化数据，基于 PVC 来实现。 PV卷的名称为：PodName+PV模板Name。 稳定的网络标识：即 Pod 重新调度后其 PodName 和 HostName（域名）不变，基于 Headless Service（即没有 Cluster IP 的 Service ）来实现。 有序扩容：有序扩展，即 Pod 是有顺序的，在部署或者扩展的时候要依据定义的顺序依次依次进行 即从 0 到 N-1，在 下一个 Pod 运行之前所有之前的 Pod 必须都是 Running 和 Ready 状态 ，基于 init containers 来实现。 只有当第一个pod就绪以后才会创建第二个pod 有序的回收：有序删除（即从 N-1 到 0） Service具有以下特点： 没有ClusterIP地址 kube-proxy不会创建负载均衡转发规则 Service是否有DNS域名解析取决于还Headless Service是否设置了Label Selector apiVersion: v1 kind: Service metadata: name: nginx labels: app: nginx spec: ports: - port: 80 name: web clusterIP: None #无头svc selector: app: nginx --- apiVersion: apps/v1 kind: StatefulSet metadata: name: web spec: selector: matchLabels: app: nginx serviceName: \"nginx\" #必须填写无头服务svc的名字 replicas: 3 template: metadata: labels: app: nginx spec: containers: - name: nginx image: wangyanglinux/myapp:v1 ports: - containerPort: 80 name: web volumeMounts: #卷绑定 - name: www mountPath: /usr/share/nginx/html volumeClaimTemplates: #pvc的卷声明模板（一个pod对应一个pvc，跟随pod一起创建） - metadata: name: www spec: accessModes: [ \"ReadWriteOnce\" ] #访问策略 storageClassName: \"nfs\" #使用存储类 resources: requests: storage: 1Gi #请求资源是1G 回收策略可不写 ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:16","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"调度器 节点亲和性 匹配逻辑 匹配的是节点的标签。只要node符合该标签即为匹配成功 字段 字段类型 描述 pod.spec.schedulername string 指定使用调度器（自定义调度器的使用） pod.spec.affinity object pod的亲和性设置 pod.spec.affinity.nodeAffinity object 节点亲和性设置（硬亲和跟软亲和可在一起） pod.spec.affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution object 节点硬亲和 硬亲和.nodeSelectorTerms list 节点标签选择器 硬亲和.nodeSelectorTerms.matchExpressions 匹配运算符。下面有多个选项的话，满足任何一个条件就可以了 硬亲和.nodeSelectorTerms.matchExpressions.matchExpressions list 匹配运算符 硬亲和.nodeSelectorTerms.matchExpressions.matchExpressions.key string 匹配节点标签的key 硬亲和.nodeSelectorTerms.matchExpressions.matchExpressions.operator string 使用哪个运算符In：label 的值在某个列表中NotIn：label 的值不在某个列表中Gt：label 的值大于某个值Lt：label 的值小于某个值Exists：某个 label 存在（key是否存在）DoesNotExist：某个 label 不存在（key是否不存在） 硬亲和.nodeSelectorTerms.matchExpressions.matchExpressions.values list 列表内写匹配的node标签值 pod.spec.affinity.nodeAffinity.preferredDuringSchedulingIgnoredDuringExecution object 节点软亲和 软亲和.weight string 软亲和权重范围在 1-100 之间（多个软亲和若产生冲突，选择权重高的） 软亲和.preference object 节点选择器条目，与权重（weight）相关 软亲和.preference.matchExpressions list 节点选择器条目，与权重（weight）相关 软亲和.preference.matchExpressions list 匹配运算符有多个选项的话，则必须同时满足这些条件才能正常调度 软亲和.preference.matchExpressions.matchExpressions.key string 匹配节点标签的key 软亲和.preference.matchExpressions…matchExpressions.operator string 使用哪个运算符In：label 的值在某个列表中NotIn：label 的值不在某个列表中Gt：label 的值大于某个值Lt：label 的值小于某个值Exists：某个 label 存在（key是否存在）DoesNotExist：某个 label 不存在（key是否不存在） 软亲和.preference.matchExpressions.matchExpressions.values list 列表内写匹配的node标签值 pod亲和性 匹配逻辑 pod亲和性匹配的是拓扑域，亲和的是拓扑域，反亲和的也是拓扑域。决定跟不跟pod在同一个拓扑域 首先在整个集群中寻找标签符合匹配条件的pod 找到该pod后，根据设置的拓扑域的key匹配其拓扑域的value 只要在设置的拓扑域的value与符合标签的pod的拓扑域的value一致，就可以建立pod 根据拓扑域匹配新的pod该建立在哪里，只要与上面符合条件的pod在同拓扑域即可。 拓扑域：在同一层次就属于同一拓扑域。例如：同一主机、同一机房、同一地区等等 pod亲和性不支持Gt、Lt运算符。 字段 字段类型 描述 pod.spec.affinity object pod的亲和性设置 pod.spec.affinity.podAffinity object pod亲和性设置 pod.spec.affinity.podAntiAffinity object pod反亲和性设置 pod亲和性.requiredDuringSchedulingIgnoredDuringExecution list pod硬亲和策略 pod亲和性.preferredDuringSchedulingIgnoredDuringExecution list pod软亲和策略 下方字段通过node亲和性一致 ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:17","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"亲和性相关运算符 键值运算关系 In：label 的值在某个列表中 NotIn：label 的值不在某个列表中 Gt：label 的值大于某个值–pod不支持 Lt：label 的值小于某个值–pod不支持 Exists：某个 label 存在（key是否存在） DoesNotExist：某个 label 不存在（key是否不存在 调度策略 匹配标签 操作符 拓扑域支持 调度目标 nodeAffinity 主机 In, NotIn, Exists, DoesNotExist, Gt, Lt 否 指定主机 podAffinity POD In, NotIn, Exists, DoesNotExist 是 POD与指定POD同一拓扑域 podAnitAffinity POD In, NotIn, Exists, DoesNotExist 是 POD与指定POD不在同一拓扑域 节点亲和性的前提条件是： 在指定拓扑域内，有目标Pod（设置为flag的Pod）。 如果是硬限制，则目标Pod的标签与matchExpressions中的条件（一个或多个）必须完全匹配。 如果是软限制，则目标Pod的标签，不是必须的，如果相匹配，还要考虑weight（1~100）关系。 固定节点调度 字段 字段类型 描述 Pod.spec.nodeName string 固定节点调度，后边跟节点名，可以跳过污点 Pod.spec.nodeSelector string 匹配节点标签进行调度，不会跳过污点。 类似于节点硬亲和，只会在符合匹配的节点上建立。节点不让建立则pending（等待调度） ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:18","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"污点与容忍 污点 # 设置污点 $ kubectl taint node 节点名 key1=value:NoSchedule # 节点说明中，查找 Taints 字段 $ kubectl describe node 节点名 # 去除污点 $ kubectl taint node 节点名 key=value:NoSchedule- #加个 - 号 容忍字段 字段 字段类型 描述 pod.spec.tolerations list 容忍设置 pod.spec.tolerations.key string 污点的key pod.spec.tolerations.operator string 污点运算符 “Equal” #运算符是等于 pod.spec.tolerations.value srting 污点的value pod.spec.tolerations.effect string 污点的effect（效果） ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:19","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"RBAC Role and ClusterRole 在 RBAC API 中，Role 表示一组规则权限，权限只会增加(累加权限)，不存在一个资源一开始就有很多权限而通过 RBAC 对其进行减少的操作；Role 可以定义在一个 namespace 中，如果想要跨 namespace 则可以创建 ClusterRole Role资源清单 kind: Role apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: namespace: default #必须写，不写就会有个默认值是default name: pod-reader rules: - apiGroups: [ \"\" ] # \"\" indicates the core API group #对哪个接口组版本的资源进行操作，不写就代表核心组：v1 resources: [ \"pods\" ] #可进行操作的资源对象 verbs: [ \"get\", \"watch\", \"list\" ] #对上方资源的操作，一般写all即可，不同资源有不同操作，在开发者手册中有。get：获取这个pod。watch：监控。lsit：列出，加起来就是查看pod的信息 ClusterRole资源清单 ClusterRole 具有与 Role 相同的权限角色控制能力，不同的是 ClusterRole 是集群级别的，ClusterRole 可以用于: 集群级别的资源控制( 例如 node 访问权限 ) 非资源型 endpoints( 例如 /health 访问 ) 所有命名空间资源控制(例如 pods ) kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: # \"namespace\" omitted since ClusterRoles are not namespaced不能写名字空间 name: secret-reader rules: - apiGroups: [ \"\" ] resources: [ \"secrets\" ] verbs: [ \"get\", \"watch\", \"list\" ] ⚠️ 集群角色不能写名字空间 RoleBinding and ClusterRoleBinding RoleBinding and ClusterRoleBinding是什么？ RoloBinding可以将角色中定义的权限授予用户或用户组，RoleBinding 包含一组权限列表(subjects) 权限列表中包含有不同形式的待授予权限资源类型(users, groups, or service accounts)；RoloBinding同样包含对被Bind的Role 引用；RoleBinding 适用于某个命名空间内授权，而 ClusterRoleBinding 适用于集群范围内的授权 RoleBinding绑定Role 角色通过角色绑定，绑定给用户（user/group/sa） 例如：将 default 命名空间的 pod-reader Role 授予 jane 用户，此后 jane 用户在 default 命名空间中将具有 pod-reader 的权限 kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: read-pods namespace: default #角色所在的名字空间 subjects: #绑定给说 - kind: User #绑定给用户 name: jane #jane用户 apiGroup: rbac.authorization.k8s.io #接口组版本 roleRef: #角色来源 kind: Role #来源于角色 name: pod-reader #来源哪个角色用户 apiGroup: rbac.authorization.k8s.io RoleBinding绑定ClusterRole 集群角色通过集群角色绑定，绑定给用户（user/group/sa） 同样可以引用ClusterRole来对当前namespace内用户、用户组或ServiceAccount进行授权，这种操作允许集群管理员在整个集群内定义一些通用的ClusterRole，然后在不同的namespace中使用 RoleBinding来引用 例如：以下 RoleBinding 引用了一个 ClusterRole，这个 ClusterRole 具有整个集群内对 secrets 的访问权限；但是其授权用户dave只能访问 development 空间中的 secrets(因为 RoleBinding 定义在 development 命名空间) # This role binding allows \"dave\" to read secrets in the \"development\" namespace. #这个角色绑定允许“dave”读取“dev”命名空间中的信息。 kind: RoleBinding #资源类型 apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: read-secrets namespace: dev # 这只授予“dev”名称空间内的权限。必写 subjects: - kind: User name: dave apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole #角色来源于集群角色 name: secret-reader apiGroup: rbac.authorization.k8s.io ClusterRoleBinding绑定ClusterRole 集群角色通过角色绑定，绑定给用户（user/group/sa）。将集群角色权限限制在角色名字空间下 使用ClusterRoleBinding可以对整个集群中的所有命名空间资源权限进行授权；以下ClusterRoleBinding样例展示了授权manager组内所有用户在全部命名空间中对secrets进行访问 # This cluster role binding allows anyone in the \"manager\" group to read secrets in any namespace. #此集群角色绑定允许“manager”组中的任何人读取任何名称空间中的秘密。 kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: read-secrets-global subjects: - kind: Group name: manager apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: secret-reader apiGroup: rbac.authorization.k8s.io Resources（子资源） Kubernetes 集群内一些资源一般以其名称字符串来表示，这些字符串一般会在 API 的 URL 地址中出现；同时某些资源也会包含子资源，例如 logs 资源就属于 pods 的子资源，API 中 URL 样例如下 GET /api/v1/namespaces/{namespace}/pods/{name}/log /api/v1/namespaces/default/pods/pod-demo/log 例如：如果要在 RBAC 授权模型中控制这些子资源的访问权限，可以通过 / 分隔符来实现，以下是一个定义 pods 资资源 logs 访问权限的 Role 定义样例 kind: Role apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: namespace: default name: pod-and-pod-logs-reader rules: - apiGroups: [ \"\" ] resources: [ \"pods\", \"pods/log\" ] #这里添加了两个权限。pods权限，pods/log权限。pods权限包含pods/log权限，这里写pods/log就是给看看写的格式。 verbs: [ \"get\", \"list\" ] to Subjects 权利附着点：user、group、sa 权利附着点命名方式 RoleBinding 和 ClusterRoleBinding 可以将 Role 绑定到 Subjects；Subjects 可以是 groups、users 或者 service accounts Subjects 中 Users 使用字符串表示， 它可以是一个普通的名字字符串，如 “alice”； 也可以是 email 格式的邮箱地址，如 “xxx@163.com”； 甚至是一组字符串形式的数字 ID 。 但是 Users 的前缀 system: 是系统保留的，集群管理员应该确保普通用户不会使用这个前缀格式 Groups 书写格式与 Users 相同，都为一个字符串，并且没有特定的格式要求；同样 system: 前缀为系统保留 ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:20","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["kubernetes"],"content":"资源限制 参数 含义 spec.container[].resources.requests.cpu 容器初始要求的CPU数量（Pod运行可能不需要要求的CPU，但必须分配，不能被其他Pod使用）。 spec.container[].resources.limits.cpu 容器所能使用的最大CPU数量（单位：500m=0.5）。 spec.container[].resources.requests.memory 容器初始要求的内存数量(可以不用，必须分配，不能被其他Pod使用) spec.container[].resources.requests.memory 容器能使用的最大内存数量（单位：Ki,Mi,Gi,Ti,Pi,Ei） 字段 描述 .kind LimitRange （指定资源限制对象类型）,注意,需要在metadata中指定命名空间。 .spec.limits[].default 设置默认的CPU和memory .spec.limits[].defaultRequest 设置默认的请求值 .spec.limits[].max 设置Pod可以请求的（在Pod中设置的）最大资源限制 .spec.limits[].min 设置Pod可以请求的（在Pod中设置的）最小资源限制 量（单位：500m=0.5）。 .spec.container[].resources.requests.memory 容器初始要求的内存数量(可以不用，必须分配，不能被其他Pod使用)容器能使用的最大内存数量（单位：Ki,Mi,Gi,Ti,Pi,Ei） .spec.limits[].maxLimitRequestRatio 设置默认超售值，Pod可以使用可以超过的的最大资源限制。 ","date":"2025-01-07","objectID":"/posts/kubernetes/:3:21","tags":["k8s"],"title":"Kubernetes","uri":"/posts/kubernetes/"},{"categories":["golang"],"content":"uber-go/guide 的中文翻译 ","date":"2024-11-22","objectID":"/posts/golang-guide/:1:0","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"English ","date":"2024-11-22","objectID":"/posts/golang-guide/:2:0","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"Uber Go 语言编码规范 Uber 是一家美国硅谷的科技公司，也是 Go 语言的早期 adopter。其开源了很多 golang 项目，诸如被 Gopher 圈熟知的 zap、jaeger 等。2018 年年末 Uber 将内部的 Go 风格规范 开源到 GitHub，经过一年的积累和更新，该规范已经初具规模，并受到广大 Gopher 的关注。本文是该规范的中文版本。本版本会根据原版实时更新。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:3:0","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"版本 当前更新版本：2024-08-10 版本地址：commit:#217 如果您发现任何更新、问题或改进，请随时 fork 和 PR Please feel free to fork and PR if you find any updates, issues or improvement. ","date":"2024-11-22","objectID":"/posts/golang-guide/:4:0","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"目录 uber-go/guide 的中文翻译 English Uber Go 语言编码规范 版本 目录 介绍 指导原则 指向 interface 的指针 Interface 合理性验证 接收器 (receiver) 与接口 零值 Mutex 是有效的 在边界处拷贝 Slices 和 Maps 接收 Slices 和 Maps 返回 slices 或 maps 使用 defer 释放资源 Channel 的 size 要么是 1，要么是无缓冲的 枚举从 1 开始 使用 time 处理时间 使用 time.Time 表达瞬时时间 使用 time.Duration 表达时间段 对外部系统使用 time.Time 和 time.Duration Errors 错误类型 错误包装 错误命名 一次处理错误 处理断言失败 不要使用 panic 使用 go.uber.org/atomic 避免可变全局变量 避免在公共结构中嵌入类型 避免使用内置名称 避免使用 init() 追加时优先指定切片容量 主函数退出方式 (Exit) 一次性退出 在序列化结构中使用字段标记 不要一劳永逸地使用 goroutine 等待 goroutines 退出 不要在 init() 使用 goroutines 性能 优先使用 strconv 而不是 fmt 避免字符串到字节的转换 指定容器容量 指定 Map 容量提示 指定切片容量 规范 避免过长的行 一致性 相似的声明放在一组 import 分组 包名 函数名 导入别名 函数分组与顺序 减少嵌套 不必要的 else 顶层变量声明 对于未导出的顶层常量和变量，使用_作为前缀 结构体中的嵌入 本地变量声明 nil 是一个有效的 slice 缩小变量作用域 避免参数语义不明确 (Avoid Naked Parameters) 使用原始字符串字面值，避免转义 初始化结构体 使用字段名初始化结构 省略结构中的零值字段 对零值结构使用 var 初始化 Struct 引用 初始化 Maps 字符串 string format 命名 Printf 样式的函数 编程模式 表驱动测试 功能选项 Linting Lint Runners Stargazers over time ","date":"2024-11-22","objectID":"/posts/golang-guide/:5:0","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"介绍 样式 (style) 是支配我们代码的惯例。术语样式有点用词不当，因为这些约定涵盖的范围不限于由 gofmt 替我们处理的源文件格式。 本指南的目的是通过详细描述在 Uber 编写 Go 代码的注意事项来管理这种复杂性。这些规则的存在是为了使代码库易于管理，同时仍然允许工程师更有效地使用 Go 语言功能。 该指南最初由 Prashant Varanasi 和 Simon Newton 编写，目的是使一些同事能快速使用 Go。多年来，该指南已根据其他人的反馈进行了修改。 本文档记录了我们在 Uber 遵循的 Go 代码中的惯用约定。其中许多是 Go 的通用准则，而其他扩展准则依赖于下面外部的指南： Effective Go Go Common Mistakes Go Code Review Comments 我们的目标是使代码示例能够准确地用于Go的两个发布版本 releases. 所有代码都应该通过golint和go vet的检查并无错误。我们建议您将编辑器设置为： 保存时运行 goimports 运行 golint 和 go vet 检查错误 您可以在以下 Go 编辑器工具支持页面中找到更为详细的信息： https://go.dev/wiki/IDEsAndTextEditorPlugins ","date":"2024-11-22","objectID":"/posts/golang-guide/:6:0","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"指导原则 ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:0","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"指向 interface 的指针 您几乎不需要指向接口类型的指针。您应该将接口作为值进行传递，在这样的传递过程中，实质上传递的底层数据仍然可以是指针。 接口实质上在底层用两个字段表示： 一个指向某些特定类型信息的指针。您可以将其视为\"type\"。 数据指针。如果存储的数据是指针，则直接存储。如果存储的数据是一个值，则存储指向该值的指针。 如果希望接口方法修改基础数据，则必须使用指针传递 (将对象指针赋值给接口变量)。 type F interface { f() } type S1 struct{} func (s S1) f() {} type S2 struct{} func (s *S2) f() {} // f1.f() 无法修改底层数据 // f2.f() 可以修改底层数据，给接口变量 f2 赋值时使用的是对象指针 var f1 F = S1{} var f2 F = \u0026S2{} 永远不要使用指向interface的指针，这个是没有意义的.在go语言中，接口本身就是引用类型，换句话说，接口类型本身就是一个指针。对于我的需求，其实test的参数只要是myinterface就可以了，只需要在传值的时候，传mystruct类型（也只能传mystruct类型） type myinterface interface{ print() } func test(value *myinterface){ //someting to do ... } type mystruct struct { i int } //实现接口 func (this *mystruct) print(){ fmt.Println(this.i) this.i=1 } func main(){ m := \u0026mystruct{0} test(m)//错误 test(*m)//错误 } ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:1","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"Interface 合理性验证 在编译时验证接口的符合性。这包括： 将实现特定接口的导出类型作为接口 API 的一部分进行检查 实现同一接口的 (导出和非导出) 类型属于实现类型的集合 任何违反接口合理性检查的场景，都会终止编译，并通知给用户 补充：上面 3 条是编译器对接口的检查机制， 大体意思是错误使用接口会在编译期报错。 所以可以利用这个机制让部分问题在编译期暴露。 BadGood // 如果 Handler 没有实现 http.Handler，会在运行时报错 type Handler struct { // ... } func (h *Handler) ServeHTTP( w http.ResponseWriter, r *http.Request, ) { ... } type Handler struct { // ... } // 用于触发编译期的接口的合理性检查机制 // 如果 Handler 没有实现 http.Handler，会在编译期报错 var _ http.Handler = (*Handler)(nil) func (h *Handler) ServeHTTP( w http.ResponseWriter, r *http.Request, ) { // ... } 如果 *Handler 与 http.Handler 的接口不匹配， 那么语句 var _ http.Handler = (*Handler)(nil) 将无法编译通过。 赋值的右边应该是断言类型的零值。 对于指针类型（如 *Handler）、切片和映射，这是 nil； 对于结构类型，这是空结构。 type LogHandler struct { h http.Handler log *zap.Logger } var _ http.Handler = LogHandler{} func (h LogHandler) ServeHTTP( w http.ResponseWriter, r *http.Request, ) { // ... } ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:2","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"接收器 (receiver) 与接口 使用值接收器的方法既可以通过值调用，也可以通过指针调用。 带指针接收器的方法只能通过指针或 addressable values 调用。 例如， type S struct { data string } func (s S) Read() string { return s.data } func (s *S) Write(str string) { s.data = str } sVals := map[int]S{1: {\"A\"}} // 你通过值只能调用 Read sVals[1].Read() // 这不能编译通过： // sVals[1].Write(\"test\") sPtrs := map[int]*S{1: {\"A\"}} // 通过指针既可以调用 Read，也可以调用 Write 方法 sPtrs[1].Read() sPtrs[1].Write(\"test\") 类似的，即使方法有了值接收器，也同样可以用指针接收器来满足接口。 type F interface { f() } type S1 struct{} func (s S1) f() {} type S2 struct{} func (s *S2) f() {} s1Val := S1{} s1Ptr := \u0026S1{} s2Val := S2{} s2Ptr := \u0026S2{} var i F i = s1Val i = s1Ptr i = s2Ptr // 下面代码无法通过编译。因为 s2Val 是一个值，而 S2 的 f 方法中没有使用值接收器 // i = s2Val Effective Go 中有一段关于 pointers vs. values 的精彩讲解。 补充： 一个类型可以有值接收器方法集和指针接收器方法集 值接收器方法集是指针接收器方法集的子集，反之不是 规则 值对象只可以使用值接收器方法集 指针对象可以使用 值接收器方法集 + 指针接收器方法集 接口的匹配 (或者叫实现) 类型实现了接口的所有方法，叫匹配 具体的讲，要么是类型的值方法集匹配接口，要么是指针方法集匹配接口 具体的匹配分两种： 值方法集和接口匹配 给接口变量赋值的不管是值还是指针对象，都 ok，因为都包含值方法集 指针方法集和接口匹配 只能将指针对象赋值给接口变量，因为只有指针方法集和接口匹配 如果将值对象赋值给接口变量，会在编译期报错 (会触发接口合理性检查机制) 为啥 i = s2Val 会报错，因为值方法集和接口不匹配。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:3","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"零值 Mutex 是有效的 零值 sync.Mutex 和 sync.RWMutex 是有效的。所以指向 mutex 的指针基本是不必要的。 BadGood mu := new(sync.Mutex) mu.Lock() var mu sync.Mutex mu.Lock() 如果你使用结构体指针，mutex 应该作为结构体的非指针字段。即使该结构体不被导出，也不要直接把 mutex 嵌入到结构体中。 BadGood type SMap struct { sync.Mutex data map[string]string } func NewSMap() *SMap { return \u0026SMap{ data: make(map[string]string), } } func (m *SMap) Get(k string) string { m.Lock() defer m.Unlock() return m.data[k] } type SMap struct { mu sync.Mutex data map[string]string } func NewSMap() *SMap { return \u0026SMap{ data: make(map[string]string), } } func (m *SMap) Get(k string) string { m.mu.Lock() defer m.mu.Unlock() return m.data[k] } Mutex 字段， Lock 和 Unlock 方法是 SMap 导出的 API 中不刻意说明的一部分。 mutex 及其方法是 SMap 的实现细节，对其调用者不可见。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:4","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"在边界处拷贝 Slices 和 Maps slices 和 maps 包含了指向底层数据的指针，因此在需要复制它们时要特别注意。 接收 Slices 和 Maps 请记住，当 map 或 slice 作为函数参数传入时，如果您存储了对它们的引用，则用户可以对其进行修改。 Bad Good func (d *Driver) SetTrips(trips []Trip) { d.trips = trips } trips := ... d1.SetTrips(trips) // 你是要修改 d1.trips 吗？ trips[0] = ... func (d *Driver) SetTrips(trips []Trip) { d.trips = make([]Trip, len(trips)) copy(d.trips, trips) } trips := ... d1.SetTrips(trips) // 这里我们修改 trips[0]，但不会影响到 d1.trips trips[0] = ... 返回 slices 或 maps 同样，请注意用户对暴露内部状态的 map 或 slice 的修改。 BadGood type Stats struct { mu sync.Mutex counters map[string]int } // Snapshot 返回当前状态。 func (s *Stats) Snapshot() map[string]int { s.mu.Lock() defer s.mu.Unlock() return s.counters } // snapshot 不再受互斥锁保护 // 因此对 snapshot 的任何访问都将受到数据竞争的影响 // 影响 stats.counters snapshot := stats.Snapshot() type Stats struct { mu sync.Mutex counters map[string]int } func (s *Stats) Snapshot() map[string]int { s.mu.Lock() defer s.mu.Unlock() result := make(map[string]int, len(s.counters)) for k, v := range s.counters { result[k] = v } return result } // snapshot 现在是一个拷贝 snapshot := stats.Snapshot() ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:5","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"使用 defer 释放资源 使用 defer 释放资源，诸如文件和锁。 BadGood p.Lock() if p.count \u003c 10 { p.Unlock() return p.count } p.count++ newCount := p.count p.Unlock() return newCount // 当有多个 return 分支时，很容易遗忘 unlock p.Lock() defer p.Unlock() if p.count \u003c 10 { return p.count } p.count++ return p.count // 更可读 Defer 的开销非常小，只有在您可以证明函数执行时间处于纳秒级的程度时，才应避免这样做。使用 defer 提升可读性是值得的，因为使用它们的成本微不足道。尤其适用于那些不仅仅是简单内存访问的较大的方法，在这些方法中其他计算的资源消耗远超过 defer。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:6","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"Channel 的 size 要么是 1，要么是无缓冲的 channel 通常 size 应为 1 或是无缓冲的。默认情况下，channel 是无缓冲的，其 size 为零。任何其他尺寸都必须经过严格的审查。我们需要考虑如何确定大小，考虑是什么阻止了 channel 在高负载下和阻塞写时的写入，以及当这种情况发生时系统逻辑有哪些变化。(翻译解释：按照原文意思是需要界定通道边界，竞态条件，以及逻辑上下文梳理) BadGood // 应该足以满足任何情况！ c := make(chan int, 64) // 大小：1 c := make(chan int, 1) // 或者 // 无缓冲 channel，大小为 0 c := make(chan int) ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:7","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"枚举从 1 开始 在 Go 中引入枚举的标准方法是声明一个自定义类型和一个使用了 iota 的 const 组。由于变量的默认值为 0，因此通常应以非零值开头枚举。 BadGood type Operation int const ( Add Operation = iota Subtract Multiply ) // Add=0, Subtract=1, Multiply=2 type Operation int const ( Add Operation = iota + 1 Subtract Multiply ) // Add=1, Subtract=2, Multiply=3 在某些情况下，使用零值是有意义的（枚举从零开始），例如，当零值是理想的默认行为时。 type LogOutput int const ( LogToStdout LogOutput = iota LogToFile LogToRemote ) // LogToStdout=0, LogToFile=1, LogToRemote=2 ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:8","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"使用 time 处理时间 时间处理很复杂。关于时间的错误假设通常包括以下几点。 一天有 24 小时 一小时有 60 分钟 一周有七天 一年 365 天 还有更多 例如，1 表示在一个时间点上加上 24 小时并不总是产生一个新的日历日。 因此，在处理时间时始终使用 \"time\" 包，因为它有助于以更安全、更准确的方式处理这些不正确的假设。 使用 time.Time 表达瞬时时间 在处理时间的瞬间时使用 time.Time，在比较、添加或减去时间时使用 time.Time 中的方法。 BadGood func isActive(now, start, stop int) bool { return start \u003c= now \u0026\u0026 now \u003c stop } func isActive(now, start, stop time.Time) bool { return (start.Before(now) || start.Equal(now)) \u0026\u0026 now.Before(stop) } 使用 time.Duration 表达时间段 在处理时间段时使用 time.Duration . BadGood func poll(delay int) { for { // ... time.Sleep(time.Duration(delay) * time.Millisecond) } } poll(10) // 是几秒钟还是几毫秒？ func poll(delay time.Duration) { for { // ... time.Sleep(delay) } } poll(10*time.Second) 回到第一个例子，在一个时间瞬间加上 24 小时，我们用于添加时间的方法取决于意图。如果我们想要下一个日历日 (当前天的下一天) 的同一个时间点，我们应该使用 Time.AddDate。但是，如果我们想保证某一时刻比前一时刻晚 24 小时，我们应该使用 Time.Add。 newDay := t.AddDate(0 /* years */, 0 /* months */, 1 /* days */) maybeNewDay := t.Add(24 * time.Hour) 对外部系统使用 time.Time 和 time.Duration 尽可能在与外部系统的交互中使用 time.Duration 和 time.Time 例如 : Command-line 标志: flag 通过 time.ParseDuration 支持 time.Duration JSON: encoding/json 通过其 UnmarshalJSON method 方法支持将 time.Time 编码为 RFC 3339 字符串 SQL: database/sql 支持将 DATETIME 或 TIMESTAMP 列转换为 time.Time，如果底层驱动程序支持则返回 YAML: gopkg.in/yaml.v2 支持将 time.Time 作为 RFC 3339 字符串，并通过 time.ParseDuration 支持 time.Duration。 当不能在这些交互中使用 time.Duration 时，请使用 int 或 float64，并在字段名称中包含单位。 例如，由于 encoding/json 不支持 time.Duration，因此该单位包含在字段的名称中。 BadGood // {\"interval\": 2} type Config struct { Interval int `json:\"interval\"` } // {\"intervalMillis\": 2000} type Config struct { IntervalMillis int `json:\"intervalMillis\"` } 当在这些交互中不能使用 time.Time 时，除非达成一致，否则使用 string 和 RFC 3339 中定义的格式时间戳。默认情况下，Time.UnmarshalText 使用此格式，并可通过 time.RFC3339 在 Time.Format 和 time.Parse 中使用。 尽管这在实践中并不成问题，但请记住，\"time\" 包不支持解析闰秒时间戳（8728），也不在计算中考虑闰秒（15190）。如果您比较两个时间瞬间，则差异将不包括这两个瞬间之间可能发生的闰秒。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:9","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"Errors 错误类型 声明错误的选项很少。 在选择最适合您的用例的选项之前，请考虑以下事项。 调用者是否需要匹配错误以便他们可以处理它？ 如果是，我们必须通过声明顶级错误变量或自定义类型来支持 errors.Is 或 errors.As 函数。 错误消息是否为静态字符串，还是需要上下文信息的动态字符串？ 如果是静态字符串，我们可以使用 errors.New，但对于后者，我们必须使用 fmt.Errorf 或自定义错误类型。 我们是否正在传递由下游函数返回的新错误？ 如果是这样，请参阅错误包装部分。 错误匹配？ 错误消息 指导 No static errors.New No dynamic fmt.Errorf Yes static top-level var with errors.New Yes dynamic custom error type 例如， 使用 errors.New 表示带有静态字符串的错误。 如果调用者需要匹配并处理此错误，则将此错误导出为变量以支持将其与 errors.Is 匹配。 无错误匹配错误匹配 // package foo func Open() error { return errors.New(\"could not open\") } // package bar if err := foo.Open(); err != nil { // Can't handle the error. panic(\"unknown error\") } // package foo var ErrCouldNotOpen = errors.New(\"could not open\") func Open() error { return ErrCouldNotOpen } // package bar if err := foo.Open(); err != nil { if errors.Is(err, foo.ErrCouldNotOpen) { // handle the error } else { panic(\"unknown error\") } } 对于动态字符串的错误， 如果调用者不需要匹配它，则使用 fmt.Errorf， 如果调用者确实需要匹配它，则自定义 error。 无错误匹配错误匹配 // package foo func Open(file string) error { return fmt.Errorf(\"file %q not found\", file) } // package bar if err := foo.Open(\"testfile.txt\"); err != nil { // Can't handle the error. panic(\"unknown error\") } // package foo type NotFoundError struct { File string } func (e *NotFoundError) Error() string { return fmt.Sprintf(\"file %q not found\", e.File) } func Open(file string) error { return \u0026NotFoundError{File: file} } // package bar if err := foo.Open(\"testfile.txt\"); err != nil { var notFound *NotFoundError if errors.As(err, \u0026notFound) { // handle the error } else { panic(\"unknown error\") } } 请注意，如果您从包中导出错误变量或类型， 它们将成为包的公共 API 的一部分。 错误包装 如果调用其他方法时出现错误, 通常有三种处理方式可以选择： 将原始错误原样返回 使用 fmt.Errorf 搭配 %w 将错误添加进上下文后返回 使用 fmt.Errorf 搭配 %v 将错误添加进上下文后返回 如果没有要添加的其他上下文，则按原样返回原始错误。 这将保留原始错误类型和消息。 这非常适合底层错误消息有足够的信息来追踪它来自哪里的错误。 否则，尽可能在错误消息中添加上下文 这样就不会出现诸如“连接被拒绝”之类的模糊错误， 您会收到更多有用的错误，例如“调用服务 foo：连接被拒绝”。 使用 fmt.Errorf 为你的错误添加上下文， 根据调用者是否应该能够匹配和提取根本原因，在 %w 或 %v 动词之间进行选择。 如果调用者应该可以访问底层错误，请使用 %w。 对于大多数包装错误，这是一个很好的默认值， 但请注意，调用者可能会开始依赖此行为。因此，对于包装错误是已知var或类型的情况，请将其作为函数契约的一部分进行记录和测试。 使用 %v 来混淆底层错误。 调用者将无法匹配它，但如果需要，您可以在将来切换到 %w。 在为返回的错误添加上下文时，通过避免使用\"failed to\"之类的短语来保持上下文简洁，当错误通过堆栈向上渗透时，它会一层一层被堆积起来： BadGood s, err := store.New() if err != nil { return fmt.Errorf( \"failed to create new store: %w\", err) } s, err := store.New() if err != nil { return fmt.Errorf( \"new store: %w\", err) } failed to x: failed to y: failed to create new store: the error x: y: new store: the error 然而，一旦错误被发送到另一个系统，应该清楚消息是一个错误（例如err 标签或日志中的\"Failed\"前缀）。 另见 不要只检查错误，优雅地处理它们。 错误命名 对于存储为全局变量的错误值， 根据是否导出，使用前缀 Err 或 err。 请看指南 对于未导出的顶层常量和变量，使用_作为前缀。 var ( // 导出以下两个错误，以便此包的用户可以将它们与 errors.Is 进行匹配。 ErrBrokenLink = errors.New(\"link is broken\") ErrCouldNotOpen = errors.New(\"could not open\") // 这个错误没有被导出，因为我们不想让它成为我们公共 API 的一部分。 我们可能仍然在带有错误的包内使用它。 errNotFound = errors.New(\"not found\") ) 对于自定义错误类型，请改用后缀 Error。 // 同样，这个错误被导出，以便这个包的用户可以将它与 errors.As 匹配。 type NotFoundError struct { File string } func (e *NotFoundError) Error() string { return fmt.Sprintf(\"file %q not found\", e.File) } // 并且这个错误没有被导出，因为我们不想让它成为公共 API 的一部分。 我们仍然可以在带有 errors.As 的包中使用它。 type resolveError struct { Path string } func (e *resolveError) Error() string { return fmt.Sprintf(\"resolve %q\", e.Path) } 一次处理错误 当调用方从被调用方接收到错误时，它可以根据对错误的了解，以各种不同的方式进行处理。 其中包括但不限于： 如果被调用者约定定义了特定的错误，则将错误与errors.Is或errors.As匹配，并以不同的方式处理分支 如果错误是可恢复的，则记录错误并正常降级 如果该错误表示特定于域的故障条件，则返回定义明确的错误 返回错误，无论是 wrapped 还是逐字逐句 无论调用方如何处理错误，它通常都应该只处理每个错误一次。例如，调用方不应该记录错误然后返回，因为its调用方也可能处理错误。 例如，考虑以下情况： DescriptionCode Bad: 记录错误并将其返回 堆栈中的调用程序可能会对该错误采取类似的操作。这样做会在应用程序日志中造成大量噪音，但收效甚微。 u, err := getUser(id) if err != nil { // BAD: See description log.Printf(\"Could not get user %q: %v\", id, err) return err } Good: 将错误换行并返回 堆栈中更靠上的调用程序将处理该错误。使用%w可确保它们可以将错误与errors.Is或errors.As相匹配 （如果相关）。 u, err := getUser(id) if err != nil { return fmt.Errorf(\"get user %q: %w\", id, err) } Good: 记录错误并正常降级 如果操作不是绝对必要的，我们可以通过从中恢复来提供降级但不间断的体验。 if err := emitMetrics(); err != nil { // Failure to write metrics should not // break the applica","date":"2024-11-22","objectID":"/posts/golang-guide/:7:10","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"处理断言失败 类型断言 将会在检测到不正确的类型时，以单一返回值形式返回 panic。 因此，请始终使用“逗号 ok”习语。 BadGood t := i.(string) t, ok := i.(string) if !ok { // 优雅地处理错误 } ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:11","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"不要使用 panic 在生产环境中运行的代码必须避免出现 panic。panic 是 级联失败 的主要根源 。如果发生错误，该函数必须返回错误，并允许调用方决定如何处理它。 BadGood func run(args []string) { if len(args) == 0 { panic(\"an argument is required\") } // ... } func main() { run(os.Args[1:]) } func run(args []string) error { if len(args) == 0 { return errors.New(\"an argument is required\") } // ... return nil } func main() { if err := run(os.Args[1:]); err != nil { fmt.Fprintln(os.Stderr, err) os.Exit(1) } } panic/recover 不是错误处理策略。仅当发生不可恢复的事情（例如：nil 引用）时，程序才必须 panic。程序初始化是一个例外：程序启动时应使程序中止的不良情况可能会引起 panic。 var _statusTemplate = template.Must(template.New(\"name\").Parse(\"_statusHTML\")) 即使在测试代码中，也优先使用t.Fatal或者t.FailNow而不是 panic 来确保失败被标记。 BadGood // func TestFoo(t *testing.T) f, err := os.CreateTemp(\"\", \"test\") if err != nil { panic(\"failed to set up test\") } // func TestFoo(t *testing.T) f, err := os.CreateTemp(\"\", \"test\") if err != nil { t.Fatal(\"failed to set up test\") } ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:12","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"使用 go.uber.org/atomic 使用 sync/atomic 包的原子操作对原始类型 (int32, int64等）进行操作，因为很容易忘记使用原子操作来读取或修改变量。 go.uber.org/atomic 通过隐藏基础类型为这些操作增加了类型安全性。此外，它包括一个方便的atomic.Bool类型。 BadGood type foo struct { running int32 // atomic } func (f* foo) start() { if atomic.SwapInt32(\u0026f.running, 1) == 1 { // already running… return } // start the Foo } func (f *foo) isRunning() bool { return f.running == 1 // race! } type foo struct { running atomic.Bool } func (f *foo) start() { if f.running.Swap(true) { // already running… return } // start the Foo } func (f *foo) isRunning() bool { return f.running.Load() } ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:13","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"避免可变全局变量 使用选择依赖注入方式避免改变全局变量。 既适用于函数指针又适用于其他值类型 BadGood // sign.go var _timeNow = time.Now func sign(msg string) string { now := _timeNow() return signWithTime(msg, now) } // sign.go type signer struct { now func() time.Time } func newSigner() *signer { return \u0026signer{ now: time.Now, } } func (s *signer) Sign(msg string) string { now := s.now() return signWithTime(msg, now) } // sign_test.go func TestSign(t *testing.T) { oldTimeNow := _timeNow _timeNow = func() time.Time { return someFixedTime } defer func() { _timeNow = oldTimeNow }() assert.Equal(t, want, sign(give)) } // sign_test.go func TestSigner(t *testing.T) { s := newSigner() s.now = func() time.Time { return someFixedTime } assert.Equal(t, want, s.Sign(give)) } ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:14","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"避免在公共结构中嵌入类型 这些嵌入的类型泄漏实现细节、禁止类型演化和模糊的文档。 假设您使用共享的 AbstractList 实现了多种列表类型，请避免在具体的列表实现中嵌入 AbstractList。 相反，只需手动将方法写入具体的列表，该列表将委托给抽象列表。 type AbstractList struct {} // 添加将实体添加到列表中。 func (l *AbstractList) Add(e Entity) { // ... } // 移除从列表中移除实体。 func (l *AbstractList) Remove(e Entity) { // ... } BadGood // ConcreteList 是一个实体列表。 type ConcreteList struct { *AbstractList } // ConcreteList 是一个实体列表。 type ConcreteList struct { list *AbstractList } // 添加将实体添加到列表中。 func (l *ConcreteList) Add(e Entity) { l.list.Add(e) } // 移除从列表中移除实体。 func (l *ConcreteList) Remove(e Entity) { l.list.Remove(e) } Go 允许 类型嵌入 作为继承和组合之间的折衷。外部类型获取嵌入类型的方法的隐式副本。默认情况下，这些方法委托给嵌入实例的同一方法。 结构还获得与类型同名的字段。 所以，如果嵌入的类型是 public，那么字段是 public。为了保持向后兼容性，外部类型的每个未来版本都必须保留嵌入类型。 很少需要嵌入类型。 这是一种方便，可以帮助您避免编写冗长的委托方法。 即使嵌入兼容的抽象列表 interface，而不是结构体，这将为开发人员提供更大的灵活性来改变未来，但仍然泄露了具体列表使用抽象实现的细节。 BadGood // AbstractList 是各种实体列表的通用实现。 type AbstractList interface { Add(Entity) Remove(Entity) } // ConcreteList 是一个实体列表。 type ConcreteList struct { AbstractList } // ConcreteList 是一个实体列表。 type ConcreteList struct { list AbstractList } // 添加将实体添加到列表中。 func (l *ConcreteList) Add(e Entity) { l.list.Add(e) } // 移除从列表中移除实体。 func (l *ConcreteList) Remove(e Entity) { l.list.Remove(e) } 无论是使用嵌入结构还是嵌入接口，都会限制类型的演化。 向嵌入接口添加方法是一个破坏性的改变。 从嵌入结构体删除方法是一个破坏性改变。 删除嵌入类型是一个破坏性的改变。 即使使用满足相同接口的类型替换嵌入类型，也是一个破坏性的改变。 尽管编写这些委托方法是乏味的，但是额外的工作隐藏了实现细节，留下了更多的更改机会，还消除了在文档中发现完整列表接口的间接性操作。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:15","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"避免使用内置名称 Go 语言规范 概述了几个内置的， 不应在 Go 项目中使用的 预先声明的标识符。 根据上下文的不同，将这些标识符作为名称重复使用， 将在当前作用域（或任何嵌套作用域）中隐藏原始标识符，或者混淆代码。 在最好的情况下，编译器会报错；在最坏的情况下，这样的代码可能会引入潜在的、难以恢复的错误。 BadGood var error string // `error` 作用域隐式覆盖 // or func handleErrorMessage(error string) { // `error` 作用域隐式覆盖 } var errorMessage string // `error` 指向内置的非覆盖 // or func handleErrorMessage(msg string) { // `error` 指向内置的非覆盖 } type Foo struct { // 虽然这些字段在技术上不构成阴影，但`error`或`string`字符串的重映射现在是不明确的。 error error string string } func (f Foo) Error() error { // `error` 和 `f.error` 在视觉上是相似的 return f.error } func (f Foo) String() string { // `string` and `f.string` 在视觉上是相似的 return f.string } type Foo struct { // `error` and `string` 现在是明确的。 err error str string } func (f Foo) Error() error { return f.err } func (f Foo) String() string { return f.str } 注意，编译器在使用预先分隔的标识符时不会生成错误， 但是诸如go vet之类的工具会正确地指出这些和其他情况下的隐式问题。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:16","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"避免使用 init() 尽可能避免使用init()。当init()是不可避免或可取的，代码应先尝试： 无论程序环境或调用如何，都要完全确定。 避免依赖于其他init()函数的顺序或副作用。虽然init()顺序是明确的，但代码可以更改， 因此init()函数之间的关系可能会使代码变得脆弱和容易出错。 避免访问或操作全局或环境状态，如机器信息、环境变量、工作目录、程序参数/输入等。 避免I/O，包括文件系统、网络和系统调用。 不能满足这些要求的代码可能属于要作为main()调用的一部分（或程序生命周期中的其他地方）， 或者作为main()本身的一部分写入。特别是，打算由其他程序使用的库应该特别注意完全确定性， 而不是执行“init magic” BadGood type Foo struct { // ... } var _defaultFoo Foo func init() { _defaultFoo = Foo{ // ... } } var _defaultFoo = Foo{ // ... } // or，为了更好的可测试性： var _defaultFoo = defaultFoo() func defaultFoo() Foo { return Foo{ // ... } } type Config struct { // ... } var _config Config func init() { // Bad: 基于当前目录 cwd, _ := os.Getwd() // Bad: I/O raw, _ := os.ReadFile( path.Join(cwd, \"config\", \"config.yaml\"), ) yaml.Unmarshal(raw, \u0026_config) } type Config struct { // ... } func loadConfig() Config { cwd, err := os.Getwd() // handle err raw, err := os.ReadFile( path.Join(cwd, \"config\", \"config.yaml\"), ) // handle err var config Config yaml.Unmarshal(raw, \u0026config) return config } 考虑到上述情况，在某些情况下，init()可能更可取或是必要的，可能包括： 不能表示为单个赋值的复杂表达式。 可插入的钩子，如database/sql、编码类型注册表等。 对 Google Cloud Functions 和其他形式的确定性预计算的优化。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:17","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"追加时优先指定切片容量 追加时优先指定切片容量 在尽可能的情况下，在初始化要追加的切片时为make()提供一个容量值。 BadGood for n := 0; n \u003c b.N; n++ { data := make([]int, 0) for k := 0; k \u003c size; k++{ data = append(data, k) } } for n := 0; n \u003c b.N; n++ { data := make([]int, 0, size) for k := 0; k \u003c size; k++{ data = append(data, k) } } BenchmarkBad-4 100000000 2.48s BenchmarkGood-4 100000000 0.21s ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:18","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"主函数退出方式 (Exit) Go 程序使用 os.Exit 或者 log.Fatal* 立即退出 (使用panic不是退出程序的好方法，请 不要使用 panic。) 仅在main() 中调用其中一个 os.Exit 或者 log.Fatal*。所有其他函数应将错误返回到信号失败中。 BadGood func main() { body := readFile(path) fmt.Println(body) } func readFile(path string) string { f, err := os.Open(path) if err != nil { log.Fatal(err) } b, err := os.ReadAll(f) if err != nil { log.Fatal(err) } return string(b) } func main() { body, err := readFile(path) if err != nil { log.Fatal(err) } fmt.Println(body) } func readFile(path string) (string, error) { f, err := os.Open(path) if err != nil { return \"\", err } b, err := os.ReadAll(f) if err != nil { return \"\", err } return string(b), nil } 原则上：退出的具有多种功能的程序存在一些问题： 不明显的控制流：任何函数都可以退出程序，因此很难对控制流进行推理。 难以测试：退出程序的函数也将退出调用它的测试。这使得函数很难测试，并引入了跳过 go test 尚未运行的其他测试的风险。 跳过清理：当函数退出程序时，会跳过已经进入defer队列里的函数调用。这增加了跳过重要清理任务的风险。 一次性退出 如果可能的话，你的main（）函数中 最多一次 调用 os.Exit或者log.Fatal。如果有多个错误场景停止程序执行，请将该逻辑放在单独的函数下并从中返回错误。 这会缩短 main() 函数，并将所有关键业务逻辑放入一个单独的、可测试的函数中。 BadGood package main func main() { args := os.Args[1:] if len(args) != 1 { log.Fatal(\"missing file\") } name := args[0] f, err := os.Open(name) if err != nil { log.Fatal(err) } defer f.Close() // 如果我们调用 log.Fatal 在这条线之后 // f.Close 将会被执行。 b, err := os.ReadAll(f) if err != nil { log.Fatal(err) } // ... } package main func main() { if err := run(); err != nil { log.Fatal(err) } } func run() error { args := os.Args[1:] if len(args) != 1 { return errors.New(\"missing file\") } name := args[0] f, err := os.Open(name) if err != nil { return err } defer f.Close() b, err := os.ReadAll(f) if err != nil { return err } // ... } 上面的示例使用log.Fatal，但该指南也适用于os.Exit或任何调用os.Exit的库代码。 func main() { if err := run(); err != nil { fmt.Fprintln(os.Stderr, err) os.Exit(1) } } 您可以根据需要更改run()的签名。例如，如果您的程序必须使用特定的失败退出代码退出，run()可能会返回退出代码而不是错误。这也允许单元测试直接验证此行为。 func main() { os.Exit(run(args)) } func run() (exitCode int) { // ... } 请注意，这些示例中使用的run()函数并不是强制性的。 run()函数的名称、签名和设置具有灵活性。除其他外，您可以： 接受未分析的命令行参数 (e.g., run(os.Args[1:])) 解析main()中的命令行参数并将其传递到run 使用自定义错误类型将退出代码传回main（） 将业务逻辑置于不同的抽象层 package main 本指南只要求在main()中有一个位置负责实际的退出流程。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:19","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"在序列化结构中使用字段标记 任何序列化到JSON、YAML、， 或其他支持基于标记的字段命名的格式应使用相关标记进行注释。 BadGood type Stock struct { Price int Name string } bytes, err := json.Marshal(Stock{ Price: 137, Name: \"UBER\", }) type Stock struct { Price int `json:\"price\"` Name string `json:\"name\"` // Safe to rename Name to Symbol. } bytes, err := json.Marshal(Stock{ Price: 137, Name: \"UBER\", }) 理论上： 结构的序列化形式是不同系统之间的契约。 对序列化表单结构（包括字段名）的更改会破坏此约定。在标记中指定字段名使约定明确， 它还可以通过重构或重命名字段来防止意外违反约定。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:20","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"不要一劳永逸地使用 goroutine Goroutines 是轻量级的，但它们不是免费的： 至少，它们会为堆栈和 CPU 的调度消耗内存。 虽然这些成本对于 Goroutines 的使用来说很小，但当它们在没有受控生命周期的情况下大量生成时会导致严重的性能问题。 具有非托管生命周期的 Goroutines 也可能导致其他问题，例如防止未使用的对象被垃圾回收并保留不再使用的资源。 因此，不要在代码中泄漏 goroutine。 使用 go.uber.org/goleak 来测试可能产生 goroutine 的包内的 goroutine 泄漏。 一般来说，每个 goroutine: 必须有一个可预测的停止运行时间； 或者 必须有一种方法可以向 goroutine 发出信号它应该停止 在这两种情况下，都必须有一种方式代码来阻塞并等待 goroutine 完成。 For example: BadGood go func() { for { flush() time.Sleep(delay) } }() var ( stop = make(chan struct{}) // 告诉 goroutine 停止 done = make(chan struct{}) // 告诉我们 goroutine 退出了 ) go func() { defer close(done) ticker := time.NewTicker(delay) defer ticker.Stop() for { select { case \u003c-tick.C: flush() case \u003c-stop: return } } }() // 其它... close(stop) // 指示 goroutine 停止 \u003c-done // and wait for it to exit 没有办法阻止这个 goroutine。这将一直运行到应用程序退出。 这个 goroutine 可以用 close(stop), 我们可以等待它退出 \u003c-done. 等待 goroutines 退出 给定一个由系统生成的 goroutine， 必须有一种方案能等待 goroutine 的退出。 有两种常用的方法可以做到这一点： 使用 sync.WaitGroup. 如果您要等待多个 goroutine，请执行此操作 var wg sync.WaitGroup for i := 0; i \u003c N; i++ { wg.Add(1) go func() { defer wg.Done() // ... }() } // To wait for all to finish: wg.Wait() 添加另一个 chan struct{}，goroutine 完成后会关闭它。 如果只有一个 goroutine，请执行此操作。 done := make(chan struct{}) go func() { defer close(done) // ... }() // To wait for the goroutine to finish: \u003c-done 不要在 init() 使用 goroutines init() 函数不应该产生 goroutines。 另请参阅 避免使用 init()。 如果一个包需要一个后台 goroutine， 它必须公开一个负责管理 goroutine 生命周期的对象。 该对象必须提供一个方法（Close、Stop、Shutdown 等）来指示后台 goroutine 停止并等待它的退出。 BadGood func init() { go doWork() } func doWork() { for { // ... } } type Worker struct{ /* ... */ } func NewWorker(...) *Worker { w := \u0026Worker{ stop: make(chan struct{}), done: make(chan struct{}), // ... } go w.doWork() } func (w *Worker) doWork() { defer close(w.done) for { // ... case \u003c-w.stop: return } } // Shutdown 告诉 worker 停止 // 并等待它完成。 func (w *Worker) Shutdown() { close(w.stop) \u003c-w.done } 当用户导出这个包时，无条件地生成一个后台 goroutine。 用户无法控制 goroutine 或停止它的方法。 仅当用户请求时才生成工作人员。 提供一种关闭工作器的方法，以便用户可以释放工作器使用的资源。 请注意，如果工作人员管理多个 goroutine，则应使用WaitGroup。 请参阅 等待 goroutines 退出。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:7:21","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"性能 性能方面的特定准则只适用于高频场景。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:8:0","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"优先使用 strconv 而不是 fmt 将原语转换为字符串或从字符串转换时，strconv速度比fmt快。 BadGood for i := 0; i \u003c b.N; i++ { s := fmt.Sprint(rand.Int()) } for i := 0; i \u003c b.N; i++ { s := strconv.Itoa(rand.Int()) } BenchmarkFmtSprint-4 143 ns/op 2 allocs/op BenchmarkStrconv-4 64.2 ns/op 1 allocs/op ","date":"2024-11-22","objectID":"/posts/golang-guide/:8:1","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"避免字符串到字节的转换 不要反复从固定字符串创建字节 slice。相反，请执行一次转换并捕获结果。 BadGood for i := 0; i \u003c b.N; i++ { w.Write([]byte(\"Hello world\")) } data := []byte(\"Hello world\") for i := 0; i \u003c b.N; i++ { w.Write(data) } BenchmarkBad-4 50000000 22.2 ns/op BenchmarkGood-4 500000000 3.25 ns/op ","date":"2024-11-22","objectID":"/posts/golang-guide/:8:2","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"指定容器容量 尽可能指定容器容量，以便为容器预先分配内存。这将在添加元素时最小化后续分配（通过复制和调整容器大小）。 指定 Map 容量提示 在尽可能的情况下，在使用 make() 初始化的时候提供容量信息 make(map[T1]T2, hint) 向make()提供容量提示会在初始化时尝试调整 map 的大小，这将减少在将元素添加到 map 时为 map 重新分配内存。 注意，与 slices 不同。map 容量提示并不保证完全的、预先的分配，而是用于估计所需的 hashmap bucket 的数量。 因此，在将元素添加到 map 时，甚至在指定 map 容量时，仍可能发生分配。 BadGood m := make(map[string]os.FileInfo) files, _ := os.ReadDir(\"./files\") for _, f := range files { m[f.Name()] = f } files, _ := os.ReadDir(\"./files\") m := make(map[string]os.FileInfo, len(files)) for _, f := range files { m[f.Name()] = f } m 是在没有大小提示的情况下创建的； 在运行时可能会有更多分配。 m 是有大小提示创建的；在运行时可能会有更少的分配。 指定切片容量 在尽可能的情况下，在使用make()初始化切片时提供容量信息，特别是在追加切片时。 make([]T, length, capacity) 与 maps 不同，slice capacity 不是一个提示：编译器将为提供给make()的 slice 的容量分配足够的内存， 这意味着后续的append()操作将导致零分配（直到 slice 的长度与容量匹配，在此之后，任何 append 都可能调整大小以容纳其他元素）。 BadGood for n := 0; n \u003c b.N; n++ { data := make([]int, 0) for k := 0; k \u003c size; k++{ data = append(data, k) } } for n := 0; n \u003c b.N; n++ { data := make([]int, 0, size) for k := 0; k \u003c size; k++{ data = append(data, k) } } BenchmarkBad-4 100000000 2.48s BenchmarkGood-4 100000000 0.21s ","date":"2024-11-22","objectID":"/posts/golang-guide/:8:3","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"规范 ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:0","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"避免过长的行 避免使用需要读者水平滚动或过度转动头部的代码行。 我们建议将行长度限制为 99 characters (99 个字符). 作者应该在达到这个限制之前换行， 但这不是硬性限制。 允许代码超过此限制。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:1","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"一致性 本文中概述的一些标准都是客观性的评估，是根据场景、上下文、或者主观性的判断； 但是最重要的是，保持一致. 一致性的代码更容易维护、是更合理的、需要更少的学习成本、并且随着新的约定出现或者出现错误后更容易迁移、更新、修复 bug 相反，在一个代码库中包含多个完全不同或冲突的代码风格会导致维护成本开销、不确定性和认知偏差。所有这些都会直接导致速度降低、代码审查痛苦、而且增加 bug 数量。 将这些标准应用于代码库时，建议在 package（或更大）级别进行更改，子包级别的应用程序通过将多个样式引入到同一代码中，违反了上述关注点。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:2","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"相似的声明放在一组 Go 语言支持将相似的声明放在一个组内。 BadGood import \"a\" import \"b\" import ( \"a\" \"b\" ) 这同样适用于常量、变量和类型声明： BadGood const a = 1 const b = 2 var a = 1 var b = 2 type Area float64 type Volume float64 const ( a = 1 b = 2 ) var ( a = 1 b = 2 ) type ( Area float64 Volume float64 ) 仅将相关的声明放在一组。不要将不相关的声明放在一组。 BadGood type Operation int const ( Add Operation = iota + 1 Subtract Multiply EnvVar = \"MY_ENV\" ) type Operation int const ( Add Operation = iota + 1 Subtract Multiply ) const EnvVar = \"MY_ENV\" 分组使用的位置没有限制，例如：你可以在函数内部使用它们： BadGood func f() string { red := color.New(0xff0000) green := color.New(0x00ff00) blue := color.New(0x0000ff) ... } func f() string { var ( red = color.New(0xff0000) green = color.New(0x00ff00) blue = color.New(0x0000ff) ) ... } 例外：如果变量声明与其他变量相邻，则应将变量声明（尤其是函数内部的声明）分组在一起。对一起声明的变量执行此操作，即使它们不相关。 BadGood func (c *client) request() { caller := c.name format := \"json\" timeout := 5*time.Second var err error // ... } func (c *client) request() { var ( caller = c.name format = \"json\" timeout = 5*time.Second err error ) // ... } ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:3","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"import 分组 导入应该分为两组： 标准库 其他库 默认情况下，这是 goimports 应用的分组。 BadGood import ( \"fmt\" \"os\" \"go.uber.org/atomic\" \"golang.org/x/sync/errgroup\" ) import ( \"fmt\" \"os\" \"go.uber.org/atomic\" \"golang.org/x/sync/errgroup\" ) ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:4","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"包名 当命名包时，请按下面规则选择一个名称： 全部小写。没有大写或下划线。 大多数使用命名导入的情况下，不需要重命名。 简短而简洁。请记住，在每个使用的地方都完整标识了该名称。 不用复数。例如net/url，而不是net/urls。 不要用“common”，“util”，“shared”或“lib”。这些是不好的，信息量不足的名称。 另请参阅 Go 包命名规则 和 Go 包样式指南. ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:5","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"函数名 我们遵循 Go 社区关于使用 MixedCaps 作为函数名 的约定。有一个例外，为了对相关的测试用例进行分组，函数名可能包含下划线，如：TestMyFunction_WhatIsBeingTested. ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:6","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"导入别名 如果程序包名称与导入路径的最后一个元素不匹配，则必须使用导入别名。 import ( \"net/http\" client \"example.com/client-go\" trace \"example.com/trace/v2\" ) 在所有其他情况下，除非导入之间有直接冲突，否则应避免导入别名。 BadGood import ( \"fmt\" \"os\" nettrace \"golang.net/x/trace\" ) import ( \"fmt\" \"os\" \"runtime/trace\" nettrace \"golang.net/x/trace\" ) ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:7","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"函数分组与顺序 函数应按粗略的调用顺序排序。 同一文件中的函数应按接收者分组。 因此，导出的函数应先出现在文件中，放在struct, const, var定义的后面。 在定义类型之后，但在接收者的其余方法之前，可能会出现一个 newXYZ()/NewXYZ() 由于函数是按接收者分组的，因此普通工具函数应在文件末尾出现。 BadGood func (s *something) Cost() { return calcCost(s.weights) } type something struct{ ... } func calcCost(n []int) int {...} func (s *something) Stop() {...} func newSomething() *something { return \u0026something{} } type something struct{ ... } func newSomething() *something { return \u0026something{} } func (s *something) Cost() { return calcCost(s.weights) } func (s *something) Stop() {...} func calcCost(n []int) int {...} ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:8","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"减少嵌套 代码应通过尽可能先处理错误情况/特殊情况并尽早返回或继续循环来减少嵌套。减少嵌套多个级别的代码的代码量。 BadGood for _, v := range data { if v.F1 == 1 { v = process(v) if err := v.Call(); err == nil { v.Send() } else { return err } } else { log.Printf(\"Invalid v: %v\", v) } } for _, v := range data { if v.F1 != 1 { log.Printf(\"Invalid v: %v\", v) continue } v = process(v) if err := v.Call(); err != nil { return err } v.Send() } ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:9","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"不必要的 else 如果在 if 的两个分支中都设置了变量，则可以将其替换为单个 if。 BadGood var a int if b { a = 100 } else { a = 10 } a := 10 if b { a = 100 } ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:10","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"顶层变量声明 在顶层，使用标准var关键字。请勿指定类型，除非它与表达式的类型不同。 BadGood var _s string = F() func F() string { return \"A\" } var _s = F() // 由于 F 已经明确了返回一个字符串类型，因此我们没有必要显式指定_s 的类型 // 还是那种类型 func F() string { return \"A\" } 如果表达式的类型与所需的类型不完全匹配，请指定类型。 type myError struct{} func (myError) Error() string { return \"error\" } func F() myError { return myError{} } var _e error = F() // F 返回一个 myError 类型的实例，但是我们要 error 类型 ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:11","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"对于未导出的顶层常量和变量，使用_作为前缀 在未导出的顶级vars和consts， 前面加上前缀_，以使它们在使用时明确表示它们是全局符号。 基本依据：顶级变量和常量具有包范围作用域。使用通用名称可能很容易在其他文件中意外使用错误的值。 BadGood // foo.go const ( defaultPort = 8080 defaultUser = \"user\" ) // bar.go func Bar() { defaultPort := 9090 ... fmt.Println(\"Default port\", defaultPort) // We will not see a compile error if the first line of // Bar() is deleted. } // foo.go const ( _defaultPort = 8080 _defaultUser = \"user\" ) 例外：未导出的错误值可以使用不带下划线的前缀 err。 参见错误命名。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:12","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"结构体中的嵌入 嵌入式类型（例如 mutex）应位于结构体内的字段列表的顶部，并且必须有一个空行将嵌入式字段与常规字段分隔开。 BadGood type Client struct { version int http.Client } type Client struct { http.Client version int } 内嵌应该提供切实的好处，比如以语义上合适的方式添加或增强功能。 它应该在对用户没有任何不利影响的情况下使用。（另请参见：避免在公共结构中嵌入类型）。 例外：即使在未导出类型中，Mutex 也不应该作为内嵌字段。另请参见：零值 Mutex 是有效的。 嵌入 不应该: 纯粹是为了美观或方便。 使外部类型更难构造或使用。 影响外部类型的零值。如果外部类型有一个有用的零值，则在嵌入内部类型之后应该仍然有一个有用的零值。 作为嵌入内部类型的副作用，从外部类型公开不相关的函数或字段。 公开未导出的类型。 影响外部类型的复制形式。 更改外部类型的 API 或类型语义。 嵌入内部类型的非规范形式。 公开外部类型的实现详细信息。 允许用户观察或控制类型内部。 通过包装的方式改变内部函数的一般行为，这种包装方式会给用户带来一些意料之外情况。 简单地说，有意识地和有目的地嵌入。一种很好的测试体验是， “是否所有这些导出的内部方法/字段都将直接添加到外部类型” 如果答案是some或no，不要嵌入内部类型 - 而是使用字段。 BadGood type A struct { // Bad: A.Lock() and A.Unlock() 现在可用 // 不提供任何功能性好处，并允许用户控制有关 A 的内部细节。 sync.Mutex } type countingWriteCloser struct { // Good: Write() 在外层提供用于特定目的， // 并且委托工作到内部类型的 Write() 中。 io.WriteCloser count int } func (w *countingWriteCloser) Write(bs []byte) (int, error) { w.count += len(bs) return w.WriteCloser.Write(bs) } type Book struct { // Bad: 指针更改零值的有用性 io.ReadWriter // other fields } // later var b Book b.Read(...) // panic: nil pointer b.String() // panic: nil pointer b.Write(...) // panic: nil pointer type Book struct { // Good: 有用的零值 bytes.Buffer // other fields } // later var b Book b.Read(...) // ok b.String() // ok b.Write(...) // ok type Client struct { sync.Mutex sync.WaitGroup bytes.Buffer url.URL } type Client struct { mtx sync.Mutex wg sync.WaitGroup buf bytes.Buffer url url.URL } ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:13","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"本地变量声明 如果将变量明确设置为某个值，则应使用短变量声明形式 (:=)。 BadGood var s = \"foo\" s := \"foo\" 但是，在某些情况下，var 使用关键字时默认值会更清晰。例如，声明空切片。 BadGood func f(list []int) { filtered := []int{} for _, v := range list { if v \u003e 10 { filtered = append(filtered, v) } } } func f(list []int) { var filtered []int for _, v := range list { if v \u003e 10 { filtered = append(filtered, v) } } } ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:14","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"nil 是一个有效的 slice nil 是一个有效的长度为 0 的 slice，这意味着， 您不应明确返回长度为零的切片。应该返回nil 来代替。 BadGood if x == \"\" { return []int{} } if x == \"\" { return nil } 要检查切片是否为空，请始终使用len(s) == 0。而非 nil。 BadGood func isEmpty(s []string) bool { return s == nil } func isEmpty(s []string) bool { return len(s) == 0 } 零值切片（用var声明的切片）可立即使用，无需调用make()创建。 BadGood nums := []int{} // or, nums := make([]int) if add1 { nums = append(nums, 1) } if add2 { nums = append(nums, 2) } var nums []int if add1 { nums = append(nums, 1) } if add2 { nums = append(nums, 2) } 记住，虽然 nil 切片是有效的切片，但它不等于长度为 0 的切片（一个为 nil，另一个不是），并且在不同的情况下（例如序列化），这两个切片的处理方式可能不同。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:15","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"缩小变量作用域 如果有可能，尽量缩小变量作用范围。除非它与 减少嵌套的规则冲突。 BadGood err := os.WriteFile(name, data, 0644) if err != nil { return err } if err := os.WriteFile(name, data, 0644); err != nil { return err } 如果需要在 if 之外使用函数调用的结果，则不应尝试缩小范围。 BadGood if data, err := os.ReadFile(name); err == nil { err = cfg.Decode(data) if err != nil { return err } fmt.Println(cfg) return nil } else { return err } data, err := os.ReadFile(name) if err != nil { return err } if err := cfg.Decode(data); err != nil { return err } fmt.Println(cfg) return nil ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:16","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"避免参数语义不明确 (Avoid Naked Parameters) 函数调用中的意义不明确的参数可能会损害可读性。当参数名称的含义不明显时，请为参数添加 C 样式注释 (/* ... */) BadGood // func printInfo(name string, isLocal, done bool) printInfo(\"foo\", true, true) // func printInfo(name string, isLocal, done bool) printInfo(\"foo\", true /* isLocal */, true /* done */) 对于上面的示例代码，还有一种更好的处理方式是将上面的 bool 类型换成自定义类型。将来，该参数可以支持不仅仅局限于两个状态（true/false）。 type Region int const ( UnknownRegion Region = iota Local ) type Status int const ( StatusReady Status= iota + 1 StatusDone // Maybe we will have a StatusInProgress in the future. ) func printInfo(name string, region Region, status Status) ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:17","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"使用原始字符串字面值，避免转义 Go 支持使用 原始字符串字面值，也就是 \" ` \" 来表示原生字符串，在需要转义的场景下，我们应该尽量使用这种方案来替换。 可以跨越多行并包含引号。使用这些字符串可以避免更难阅读的手工转义的字符串。 BadGood wantError := \"unknown name:\\\"test\\\"\" wantError := `unknown error:\"test\"` ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:18","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"初始化结构体 使用字段名初始化结构 初始化结构时，几乎应该始终指定字段名。目前由 go vet 强制执行。 BadGood k := User{\"John\", \"Doe\", true} k := User{ FirstName: \"John\", LastName: \"Doe\", Admin: true, } 例外：当有 3 个或更少的字段时，测试表中的字段名may可以省略。 tests := []struct{ op Operation want string }{ {Add, \"add\"}, {Subtract, \"subtract\"}, } 省略结构中的零值字段 初始化具有字段名的结构时，除非提供有意义的上下文，否则忽略值为零的字段。 也就是，让我们自动将这些设置为零值 BadGood user := User{ FirstName: \"John\", LastName: \"Doe\", MiddleName: \"\", Admin: false, } user := User{ FirstName: \"John\", LastName: \"Doe\", } 这有助于通过省略该上下文中的默认值来减少阅读的障碍。只指定有意义的值。 在字段名提供有意义上下文的地方包含零值。例如，表驱动测试 中的测试用例可以受益于字段的名称，即使它们是零值的。 tests := []struct{ give string want int }{ {give: \"0\", want: 0}, // ... } 对零值结构使用 var 如果在声明中省略了结构的所有字段，请使用 var 声明结构。 BadGood user := User{} var user User 这将零值结构与那些具有类似于为 初始化 Maps 创建的，区别于非零值字段的结构区分开来， 我们倾向于声明一个空切片 初始化 Struct 引用 在初始化结构引用时，请使用\u0026T{}代替new(T)，以使其与结构体初始化一致。 BadGood sval := T{Name: \"foo\"} // inconsistent sptr := new(T) sptr.Name = \"bar\" sval := T{Name: \"foo\"} sptr := \u0026T{Name: \"bar\"} ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:19","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"初始化 Maps 对于空 map 请使用 make(..) 初始化， 并且 map 是通过编程方式填充的。 这使得 map 初始化在表现上不同于声明，并且它还可以方便地在 make 后添加大小提示。 BadGood var ( // m1 读写安全; // m2 在写入时会 panic m1 = map[T1]T2{} m2 map[T1]T2 ) var ( // m1 读写安全; // m2 在写入时会 panic m1 = make(map[T1]T2) m2 map[T1]T2 ) 声明和初始化看起来非常相似的。 声明和初始化看起来差别非常大。 在尽可能的情况下，请在初始化时提供 map 容量大小，详细请看 指定 Map 容量提示。 另外，如果 map 包含固定的元素列表，则使用 map literals(map 初始化列表) 初始化映射。 BadGood m := make(map[T1]T2, 3) m[k1] = v1 m[k2] = v2 m[k3] = v3 m := map[T1]T2{ k1: v1, k2: v2, k3: v3, } 基本准则是：在初始化时使用 map 初始化列表 来添加一组固定的元素。否则使用 make (如果可以，请尽量指定 map 容量)。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:20","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"字符串 string format 如果你在函数外声明Printf-style 函数的格式字符串，请将其设置为const常量。 这有助于go vet对格式字符串执行静态分析。 BadGood msg := \"unexpected values %v, %v\\n\" fmt.Printf(msg, 1, 2) const msg = \"unexpected values %v, %v\\n\" fmt.Printf(msg, 1, 2) ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:21","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"命名 Printf 样式的函数 声明Printf-style 函数时，请确保go vet可以检测到它并检查格式字符串。 这意味着您应尽可能使用预定义的Printf-style 函数名称。go vet将默认检查这些。有关更多信息，请参见 Printf 系列。 如果不能使用预定义的名称，请以 f 结束选择的名称：Wrapf，而不是Wrap。go vet可以要求检查特定的 Printf 样式名称，但名称必须以f结尾。 go vet -printfuncs=wrapf,statusf 另请参阅 go vet: Printf family check. ","date":"2024-11-22","objectID":"/posts/golang-guide/:9:22","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"编程模式 ","date":"2024-11-22","objectID":"/posts/golang-guide/:10:0","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"表驱动测试 当测试逻辑是重复的时候，通过 subtests 使用 table 驱动的方式编写 case 代码看上去会更简洁。 BadGood // func TestSplitHostPort(t *testing.T) host, port, err := net.SplitHostPort(\"192.0.2.0:8000\") require.NoError(t, err) assert.Equal(t, \"192.0.2.0\", host) assert.Equal(t, \"8000\", port) host, port, err = net.SplitHostPort(\"192.0.2.0:http\") require.NoError(t, err) assert.Equal(t, \"192.0.2.0\", host) assert.Equal(t, \"http\", port) host, port, err = net.SplitHostPort(\":8000\") require.NoError(t, err) assert.Equal(t, \"\", host) assert.Equal(t, \"8000\", port) host, port, err = net.SplitHostPort(\"1:8\") require.NoError(t, err) assert.Equal(t, \"1\", host) assert.Equal(t, \"8\", port) // func TestSplitHostPort(t *testing.T) tests := []struct{ give string wantHost string wantPort string }{ { give: \"192.0.2.0:8000\", wantHost: \"192.0.2.0\", wantPort: \"8000\", }, { give: \"192.0.2.0:http\", wantHost: \"192.0.2.0\", wantPort: \"http\", }, { give: \":8000\", wantHost: \"\", wantPort: \"8000\", }, { give: \"1:8\", wantHost: \"1\", wantPort: \"8\", }, } for _, tt := range tests { t.Run(tt.give, func(t *testing.T) { host, port, err := net.SplitHostPort(tt.give) require.NoError(t, err) assert.Equal(t, tt.wantHost, host) assert.Equal(t, tt.wantPort, port) }) } 很明显，使用 test table 的方式在代码逻辑扩展的时候，比如新增 test case，都会显得更加的清晰。 我们遵循这样的约定：将结构体切片称为tests。 每个测试用例称为tt。此外，我们鼓励使用give和want前缀说明每个测试用例的输入和输出值。 tests := []struct{ give string wantHost string wantPort string }{ // ... } for _, tt := range tests { // ... } 并行测试，比如一些专门的循环（例如，生成goroutine或捕获引用作为循环体的一部分的那些循环） 必须注意在循环的范围内显式地分配循环变量，以确保它们保持预期的值。 tests := []struct{ give string // ... }{ // ... } for _, tt := range tests { tt := tt // for t.Parallel t.Run(tt.give, func(t *testing.T) { t.Parallel() // ... }) } 在上面的例子中，由于下面使用了t.Parallel()，我们必须声明一个作用域为循环迭代的tt变量。 如果我们不这样做，大多数或所有测试都会收到一个意外的tt值，或者一个在运行时发生变化的值。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:10:1","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"功能选项 功能选项是一种模式，您可以在其中声明一个不透明 Option 类型，该类型在某些内部结构中记录信息。您接受这些选项的可变编号，并根据内部结构上的选项记录的全部信息采取行动。 将此模式用于您需要扩展的构造函数和其他公共 API 中的可选参数，尤其是在这些功能上已经具有三个或更多参数的情况下。 BadGood // package db func Open( addr string, cache bool, logger *zap.Logger ) (*Connection, error) { // ... } // package db type Option interface { // ... } func WithCache(c bool) Option { // ... } func WithLogger(log *zap.Logger) Option { // ... } // Open creates a connection. func Open( addr string, opts ...Option, ) (*Connection, error) { // ... } 必须始终提供缓存和记录器参数，即使用户希望使用默认值。 db.Open(addr, db.DefaultCache, zap.NewNop()) db.Open(addr, db.DefaultCache, log) db.Open(addr, false /* cache */, zap.NewNop()) db.Open(addr, false /* cache */, log) 只有在需要时才提供选项。 db.Open(addr) db.Open(addr, db.WithLogger(log)) db.Open(addr, db.WithCache(false)) db.Open( addr, db.WithCache(false), db.WithLogger(log), ) 我们建议实现此模式的方法是使用一个 Option 接口，该接口保存一个未导出的方法，在一个未导出的 options 结构上记录选项。 type options struct { cache bool logger *zap.Logger } type Option interface { apply(*options) } type cacheOption bool func (c cacheOption) apply(opts *options) { opts.cache = bool(c) } func WithCache(c bool) Option { return cacheOption(c) } type loggerOption struct { Log *zap.Logger } func (l loggerOption) apply(opts *options) { opts.logger = l.Log } func WithLogger(log *zap.Logger) Option { return loggerOption{Log: log} } // Open creates a connection. func Open( addr string, opts ...Option, ) (*Connection, error) { options := options{ cache: defaultCache, logger: zap.NewNop(), } for _, o := range opts { o.apply(\u0026options) } // ... } 注意：还有一种使用闭包实现这个模式的方法，但是我们相信上面的模式为作者提供了更多的灵活性，并且更容易对用户进行调试和测试。特别是，我们的这种方式允许在测试和模拟中比较选项，这在闭包实现中几乎是不可能的。此外，它还允许选项实现其他接口，包括 fmt.Stringer，允许用户读取选项的字符串表示形式。 还可以参考下面资料： Self-referential functions and the design of options Functional options for friendly APIs ","date":"2024-11-22","objectID":"/posts/golang-guide/:10:2","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"Linting 比任何 “blessed” linter 集更重要的是，lint 在一个代码库中始终保持一致。 我们建议至少使用以下 linters，因为我认为它们有助于发现最常见的问题，并在不需要规定的情况下为代码质量建立一个高标准： errcheck 以确保错误得到处理 goimports 格式化代码和管理 imports golint 指出常见的文体错误 govet 分析代码中的常见错误 staticcheck 各种静态分析检查 ","date":"2024-11-22","objectID":"/posts/golang-guide/:11:0","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"Lint Runners 我们推荐 golangci-lint 作为 go-to lint 的运行程序，这主要是因为它在较大的代码库中的性能以及能够同时配置和使用许多规范。这个 repo 有一个示例配置文件 .golangci.yml 和推荐的 linter 设置。 golangci-lint 有 various-linters 可供使用。建议将上述 linters 作为基本 set，我们鼓励团队添加对他们的项目有意义的任何附加 linters。 ","date":"2024-11-22","objectID":"/posts/golang-guide/:11:1","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["golang"],"content":"Stargazers over time ","date":"2024-11-22","objectID":"/posts/golang-guide/:12:0","tags":["golang"],"title":"Golang-Guide","uri":"/posts/golang-guide/"},{"categories":["python"],"content":" macos 使用 ","date":"2024-10-31","objectID":"/posts/poetry/:0:0","tags":["poetry"],"title":"Poetry: Python虚拟环境管理","uri":"/posts/poetry/"},{"categories":["python"],"content":"install brew install poetry ","date":"2024-10-31","objectID":"/posts/poetry/:1:0","tags":["poetry"],"title":"Poetry: Python虚拟环境管理","uri":"/posts/poetry/"},{"categories":["python"],"content":"初始化 mkdir project-demo cd project-demo poetry init ","date":"2024-10-31","objectID":"/posts/poetry/:2:0","tags":["poetry"],"title":"Poetry: Python虚拟环境管理","uri":"/posts/poetry/"},{"categories":["python"],"content":"管理虚拟环境 创建虚拟环境 虚拟环境的命名模式为 项目名-随机数-python版本 poetry env use PYTHONPATH 查看当前虚拟环境 poetry env list 查看当前poetry配置 poetry config --list 允许在项目目录下创建虚拟环境 poetry config virtualenvs.in-project true 如果已经创建了环境需要先移除 poetry env remove PYTHONPATH 创建目录：poetry env use PYTHONPATH 退出与启动环境 已 poetry 开头的命令自动检测当前环境 同样也可以使用poetry shell进入 退出环境：deactivate ","date":"2024-10-31","objectID":"/posts/poetry/:3:0","tags":["poetry"],"title":"Poetry: Python虚拟环境管理","uri":"/posts/poetry/"},{"categories":["python"],"content":"poetry 指令 ","date":"2024-10-31","objectID":"/posts/poetry/:4:0","tags":["poetry"],"title":"Poetry: Python虚拟环境管理","uri":"/posts/poetry/"},{"categories":["python"],"content":"添加依赖包 poetry add poetry add requests ","date":"2024-10-31","objectID":"/posts/poetry/:4:1","tags":["poetry"],"title":"Poetry: Python虚拟环境管理","uri":"/posts/poetry/"},{"categories":["python"],"content":"poetry.lock 与更新顺序 除了更新 pyproject.toml ，此时项目中还会新增一个文件，名为 poetry.lock ，它实际上就相当于 pip 的 requirements.txt ，详细记录了所有安装的模块与版本。 当使用 poetry add 指令时，poetry 会自动依序帮你做完这三件事： 更新 pyproject.toml。 依照 pyproject.toml 的内容，更新 poetry.lock 。 依照 poetry.lock 的内容，更新虚拟环境。 由此可见， poetry.lock 的内容是取决于 pyproject.toml ，但两者并不会自己连动，一定要基于特定指令才会进行同步与更新， poetry add 就是一个典型案例。 ","date":"2024-10-31","objectID":"/posts/poetry/:5:0","tags":["poetry"],"title":"Poetry: Python虚拟环境管理","uri":"/posts/poetry/"},{"categories":["python"],"content":"poetry lock ：更新 poetry.lock 当你自行修改了 pyproject.toml 内容，比如变更特定模块的版本（这是有可能的，尤其在手动处理版本冲突的时候），此时 poetry.lock 的内容与 pyproject.toml 出现了脱钩，必须让它依照新的 pyproject.toml 内容更新、同步，使用指令： poetry lock 如此一来，才能确保手动修改的内容，也更新到 poetry.lock 中，毕竟虚拟环境如果要重新建立，是基于 poetry.lock 的内容来安装模块，而非 pyproject.toml 。 还是那句话： poetry.lock 相当于 Poetry 的 requirements.txt。 但要特别注意的是， poetry lock 指令，仅会更新 poetry.lock ，不会同时安装模块至虚拟环境 因此，在执行完 poetry lock 指令后，必须再使用 poetry install 来安装模块。否则就会出现 poetry.lock 和虚拟环境不一致的状况。 更多 poetry lock 细节可参考 官方文件，其中特别值得注意的是 --no-update 参数。 ","date":"2024-10-31","objectID":"/posts/poetry/:6:0","tags":["poetry"],"title":"Poetry: Python虚拟环境管理","uri":"/posts/poetry/"},{"categories":["python"],"content":"新增模块至 dev-dependencies 有些模块，比如 pytest 、 black 等等，只会在开发环境中使用，产品的部署环境并不需要。 Poetry 允许你区分这两者，将上述的模块安装至 dev-dependencies 区块，方便让你轻松建立一份「不包含」 dev-dependencies 开发模块的安装清单。 在此以 Black 为例，安装方式如下： poetry add black --group dev 结果的区别显示在 pyproject.toml 里： python = \"^3.10\" flask = \"^2.3.2\" [tool.poetry.group.dev.dependencies] black = \"^23.7.0\" 可以看到 black 被列在不同区块： tool.poetry.dev-dependencies 。 强烈建议善用 dev-dependencies 善用 --group dev 参数，明确区分开发环境，我认为非常必要。 首先，这些模块常常属于「检测型」工具，相关的依赖模块着实不少！比如 flake8 ，它依赖了 pycodestyle 、 pyflakes 、 mccabe 等等，还有 black 、 pre-commit ，依赖模块数量也都很可观。 ","date":"2024-10-31","objectID":"/posts/poetry/:7:0","tags":["poetry"],"title":"Poetry: Python虚拟环境管理","uri":"/posts/poetry/"},{"categories":["python"],"content":"Poetry 更新模块 这个就很简单了，使用 poetry update 指令即可： poetry update 上面指令会更新全部可能可以更新的模块，也可以仅指定特定模块，比如： poetry update requests toml 关于 poetry update 的其余参数，请参考文件。 还一件重要的事，那就是关于模块版本的升级限制规则，取决于你在 pyproject.toml 中的设定。 ","date":"2024-10-31","objectID":"/posts/poetry/:8:0","tags":["poetry"],"title":"Poetry: Python虚拟环境管理","uri":"/posts/poetry/"},{"categories":["python"],"content":"列出全部模块清单 poetry show 树状显示依赖层 poetry show --tree 也可以指定模块显示 poetry show celery --tree ","date":"2024-10-31","objectID":"/posts/poetry/:9:0","tags":["poetry"],"title":"Poetry: Python虚拟环境管理","uri":"/posts/poetry/"},{"categories":["python"],"content":"删除模块 poetry remove celery ","date":"2024-10-31","objectID":"/posts/poetry/:10:0","tags":["poetry"],"title":"Poetry: Python虚拟环境管理","uri":"/posts/poetry/"},{"categories":["python"],"content":"导出poetry 虚拟环境requirements.txt poetry export -f requirements.txt -o requirements.txt --without-hashes 导出dev的包 poetry export -f requirements.txt -o requirements-dev.txt --without-hashes --dev ","date":"2024-10-31","objectID":"/posts/poetry/:11:0","tags":["poetry"],"title":"Poetry: Python虚拟环境管理","uri":"/posts/poetry/"},{"categories":["python"],"content":"添加阿里云源 poetry source add aliyun https://mirrors.aliyun.com/pypi/simple ","date":"2024-10-31","objectID":"/posts/poetry/:12:0","tags":["poetry"],"title":"Poetry: Python虚拟环境管理","uri":"/posts/poetry/"},{"categories":["nodejs"],"content":"问题集锦 ","date":"2024-10-29","objectID":"/posts/nodejs/:1:0","tags":["nodejs"],"title":"Nodejs","uri":"/posts/nodejs/"},{"categories":["nodejs"],"content":"/lib64/libstdc++.so.6: version `CXXABI_1.3.9’ not found canvas.node 解决办法（CentOS） npx node-pre-gyp rebuild -C ./node_modules/canvas ","date":"2024-10-29","objectID":"/posts/nodejs/:1:1","tags":["nodejs"],"title":"Nodejs","uri":"/posts/nodejs/"},{"categories":["macos"],"content":"macos 启动过程 ","date":"2024-10-28","objectID":"/posts/macosboot/:1:0","tags":["macos"],"title":"Macosboot","uri":"/posts/macosboot/"},{"categories":["macos"],"content":"launchd开启之后，会依次去完成以下的工作： 根据/System/Library/LaunchDaemons 和/Library/LaunchDaemons路径下的plist文件，加载系统级守护进程； 注册上述守护进程需要的套接字及文件描述符； 根据plist文件中的KeepAlive键值，启动那些需要在系统周期内一直保持的进程； 根据plist文件中的设定，在条件满足时启动进程； 关机时，给所有由launchd开启的进程发送SIGTERM信号。 我们将log信息中的内容与/System/Library/LaunchDaemons路径下的plist进行对照，发现在系统开启之初的bootlog，blued，mDNSResponder等都能再该路径下找到。 ","date":"2024-10-28","objectID":"/posts/macosboot/:2:0","tags":["macos"],"title":"Macosboot","uri":"/posts/macosboot/"},{"categories":["macos"],"content":"LaunchDaemons路径下的plist指定的进程启动是否存在一定的先后顺序呢？ 在launchd依次完成的工作中，可以看到它是先注册套接字和文件描述符，然后才去启动进程，因此plist指定的进程的启动先后顺序并不明确。 launchd配置文件总共有五个路径，在系统开启之初，只加载了/System/Library/LaunchDaemons 和/Library/LaunchDaemons路径下的plist文件，另外三个路径下的plist文件是在用户login之后才进行的。 用户的login是由loginwindow进程完成的，而loginwindow的启动又是由/System/Library/LaunchDaemons路径下的com.apple.loginwindow.plist指定的。 用户登录之后，launchd才会去加载/System/Library/LaunchAgents 和/Library/LaunchAgents以及~/Library/LaunchAgents路径下的plist文件，从而根据plist文件的具体设置去启动相应的进程。 ","date":"2024-10-28","objectID":"/posts/macosboot/:2:1","tags":["macos"],"title":"Macosboot","uri":"/posts/macosboot/"},{"categories":["shell"],"content":"ps命令 ","date":"2024-10-17","objectID":"/posts/shell/:1:0","tags":["shell"],"title":"Shell","uri":"/posts/shell/"},{"categories":["shell"],"content":"查看进程启动时间 ps -eo pid,lstart,etime,cmd |grep $PID ","date":"2024-10-17","objectID":"/posts/shell/:1:1","tags":["shell"],"title":"Shell","uri":"/posts/shell/"},{"categories":["shell"],"content":"shell 判断 -eq # 等于 -ne # 不等于 -gt # 大于 -lt # 小于 -ge # 大于等于 -le # 小于等于 ","date":"2024-10-17","objectID":"/posts/shell/:2:0","tags":["shell"],"title":"Shell","uri":"/posts/shell/"},{"categories":["shell"],"content":"IP地址判断 ((2(5[0-5]|[0-4]\\\\\\\\d))|[0-1]?\\\\\\\\d{1,2})(\\\\\\\\.((2(5[0-5]|[0-4]\\\\\\\\d))|[0-1]?\\\\\\\\d{1,2})){3} ","date":"2024-10-17","objectID":"/posts/shell/:3:0","tags":["shell"],"title":"Shell","uri":"/posts/shell/"},{"categories":["shell"],"content":"字符串运算 运算符 说明 举例 = 检测两个字符串是否相等，相等返回 true。 [ $a = $b ] 返回 false。 != 检测两个字符串是否不相等，不相等返回 true。 [ $a != $b ] 返回 true。 -z 检测字符串长度是否为0，为0返回 true。 [ -z $a ] 返回 false。 -n 检测字符串长度是否不为 0，不为 0 返回 true。 [ -n “$a” ] 返回 true。 $ 检测字符串是否不为空，不为空返回 true。 [ $a ] 返回 true。 ","date":"2024-10-17","objectID":"/posts/shell/:4:0","tags":["shell"],"title":"Shell","uri":"/posts/shell/"},{"categories":["shell"],"content":"文件测试运算符 操作符 说明 举例 -b file 检测文件是否是块设备文件，如果是，则返回 true。 [ -b $file ] 返回 false。 -c file 检测文件是否是字符设备文件，如果是，则返回 true。 [ -c $file ] 返回 false。 -d file 检测文件是否是目录，如果是，则返回 true。 [ -d $file ] 返回 false。 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。 -g file 检测文件是否设置了 SGID 位，如果是，则返回 true。 [ -g $file ] 返回 false。 -k file 检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。 [ -k $file ] 返回 false。 -p file 检测文件是否是有名管道，如果是，则返回 true。 [ -p $file ] 返回 false。 -u file 检测文件是否设置了 SUID 位，如果是，则返回 true。 [ -u $file ] 返回 false。 -r file 检测文件是否可读，如果是，则返回 true。 [ -r $file ] 返回 true。 -w file 检测文件是否可写，如果是，则返回 true。 [ -w $file ] 返回 true。 -x file 检测文件是否可执行，如果是，则返回 true。 [ -x $file ] 返回 true。 -s file 检测文件是否为空（文件大小是否大于0），不为空返回 true。 [ -s $file ] 返回 true。 -e file 检测文件（包括目录）是否存在，如果是，则返回 true。 [ -e $file ] 返回 true。 其他检查符： -S: 判断某文件是否 socket。 -L: 检测文件是否存在并且是一个符号链接。 ","date":"2024-10-17","objectID":"/posts/shell/:5:0","tags":["shell"],"title":"Shell","uri":"/posts/shell/"},{"categories":["shell"],"content":"逻辑运算 运算符 说明 举例 \u0026\u0026 逻辑的 AND [[ $a -lt 100 \u0026\u0026 $b -gt 100 ]] 返回 false || 逻辑的 OR [[ $a -lt 100 || $b -gt 100 ]] 返回 true ","date":"2024-10-17","objectID":"/posts/shell/:6:0","tags":["shell"],"title":"Shell","uri":"/posts/shell/"},{"categories":["shell"],"content":"布尔运算符 运算符 说明 举例 ! 非运算，表达式为 true 则返回 false，否则返回 true。 [ ! false ] 返回 true。 -o 或运算，有一个表达式为 true 则返回 true。 [ $a -lt 20 -o $b -gt 100 ] 返回 true。 -a 与运算，两个表达式都为 true 才返回 true。 [ $a -lt 20 -a $b -gt 100 ] 返回 false。 ","date":"2024-10-17","objectID":"/posts/shell/:7:0","tags":["shell"],"title":"Shell","uri":"/posts/shell/"},{"categories":["shell"],"content":"关系运算符 运算符 说明 举例 -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ] 返回 false。 -ne 检测两个数是否不相等，不相等返回 true。 [ $a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。 -ge 检测左边的数是否大于等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ] 返回 true。 ","date":"2024-10-17","objectID":"/posts/shell/:8:0","tags":["shell"],"title":"Shell","uri":"/posts/shell/"},{"categories":["shell"],"content":"算术运算符 运算符 说明 举例 + 加法 expr $a + $b 结果为 30。 - 减法 expr $a - $b 结果为 -10。 * 乘法 expr $a * $b 结果为 200。 / 除法 expr $b / $a 结果为 2。 % 取余 expr $b % $a 结果为 0。 = 赋值 a=$b 把变量 b 的值赋给 a。 == 相等。用于比较两个数字，相同则返回 true。 [ $a == $b ] 返回 false。 != 不相等。用于比较两个数字，不相同则返回 true。 [ $a != $b ] 返回 true。 注意：条件表达式要放在方括号之间，并且要有空格，例如: [$a==$b] 是错误的，必须写成 [ $a == $b ]。 乘号(*)前边必须加反斜杠(\\)才能实现乘法运算； 在 MAC 中 shell 的 expr 语法是：$((表达式))，此处表达式中的 “*” 不需要转义符号 “\\” 。 ","date":"2024-10-17","objectID":"/posts/shell/:9:0","tags":["shell"],"title":"Shell","uri":"/posts/shell/"},{"categories":["shell"],"content":"自增和自减操作符 使用 let 命令 let 命令允许对整数进行算术运算。 #!/bin/bash # 初始化变量 num=5 # 自增 let num++ # 自减 let num-- echo $num 使用 $(( )) 进行算术运算 $(( )) 语法也是进行算术运算的一种方式。 #!/bin/bash # 初始化变量 num=5 # 自增 num=$((num + 1)) # 自减 num=$((num - 1)) echo $num 使用 expr 命令 expr 命令可以用于算术运算，但在现代脚本中不如 let 和 $(( )) 常用。 #!/bin/bash # 初始化变量 num=5 # 自增 num=$(expr $num + 1) # 自减 num=$(expr $num - 1) echo $num 使用 (( )) 进行算术运算 与 $(( )) 类似，(( )) 语法也可以用于算术运算。 #!/bin/bash # 初始化变量 num=5 # 自增 ((num++)) # 自减 ((num--)) echo $num ","date":"2024-10-17","objectID":"/posts/shell/:10:0","tags":["shell"],"title":"Shell","uri":"/posts/shell/"},{"categories":["macos"],"content":"minikube minikube start --image-mirror-country='cn' --driver=hyperkit --registry-mirror=\"\u003chttps://xxx.mirror.aliyuncs.com\u003e\" ","date":"2024-10-17","objectID":"/posts/macos/:1:0","tags":["macos"],"title":"Macos","uri":"/posts/macos/"},{"categories":["macos"],"content":"macos工具集 xldr sourcetree aliyun-cli dash xnip miniconda visualvm maccy obsidian tabby ","date":"2024-10-17","objectID":"/posts/macos/:2:0","tags":["macos"],"title":"Macos","uri":"/posts/macos/"},{"categories":["https"],"content":"ssl # acme.sh # 默认是zerossl，存在认证问题：get authz objec with invalid status, please try again later. # https://github.com/acmesh-official/acme.sh/wiki/Server acme.sh --set-default-ca --server letsencrypt # 申明dns的aksk export DP_Id=\"xxx\";export DP_Key=\"xxx\" # 生成需要的泛域名证书 acme.sh --dnssleep --force --issue -k 2048 --dns dns_dp -d '*.exsample.com' -d exsample.com # 生成nginx 证书 acme.sh --force --install-cert -d *.xxx.net \\ --key-file /usr/local/openresty/nginx/conf/ssl/xxx.net.key \\ --fullchain-file /usr/local/openresty/nginx/conf/ssl/xxx.net.pem \\ --reloadcmd \"nginx -s reload\" # 删除证书 acme.sh --remove -d *.exsample.com # 查看证书信息 acme.sh --info -d *.exsample.com # 查看证书列表 acme.sh --list # 设置自动更新 acme.sh --upgrade --auto-upgrade ","date":"2024-10-17","objectID":"/posts/letsencrypt/:1:0","tags":["https"],"title":"letsencrypt","uri":"/posts/letsencrypt/"},{"categories":["https"],"content":"certbot certbot certonly --manual --preferred-challenges dns ","date":"2024-10-17","objectID":"/posts/letsencrypt/:2:0","tags":["https"],"title":"letsencrypt","uri":"/posts/letsencrypt/"},{"categories":["linux"],"content":"mem centos6.5 -/+ buffers/cache： -buffers/cache 的内存数：95 (等于第1行的 used - buffers - cached) +buffers/cache 的内存数: 32 (等于第1行的 free + buffers + cached) 1. -buffers/cache 反映的是被程序实实在在吃掉的内存， 2. +buffers/cache 反映的是可以挪用的内存总数。 ","date":"2024-10-17","objectID":"/posts/linux/:1:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["linux"],"content":"Linux Ctrl C无效 原因：rvm 版本bug 解决方法： 命令查看： 正常： [root@server002 ~]# trap trap -- '' SIGTSTP trap -- '' SIGTTIN trap -- '' SIGTTOU 异常： [root@server002 ~]# trap trap -- '' SIGTSTP trap -- '' SIGTTIN trap -- '' SIGTTOU trap -- '' SIGINT trap -- '' SIGQUIT 现象：终端Ctrl + C完全失效，当执行trap 信号命令时多处两个SIGINT和SIGQUIT两项 升级rvm 版本：rvm get stable（ 1.29.4 版本以上都可以解决） 卸载rvm工具：gem uninstall rvm ","date":"2024-10-17","objectID":"/posts/linux/:2:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["linux"],"content":"pip 国内源临时加速 pip install markdown -i \u003chttps://pypi.tuna.tsinghua.edu.cn/simple\u003e 永久配置 # 清华源 pip config set global.index-url \u003chttps://pypi.tuna.tsinghua.edu.cn/simple\u003e # 或： # 阿里源 pip config set global.index-url \u003chttps://mirrors.aliyun.com/pypi/simple/\u003e # 腾讯源 pip config set global.index-url \u003chttp://mirrors.cloud.tencent.com/pypi/simple\u003e ","date":"2024-10-17","objectID":"/posts/linux/:3:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["linux"],"content":"goaccess ","date":"2024-10-17","objectID":"/posts/linux/:4:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["linux"],"content":"conda • 安装uwsgi： conda install -c conda-forge uwsgi # 取消自动进入base环境 conda config --set auto_activate_base false ","date":"2024-10-17","objectID":"/posts/linux/:5:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["linux"],"content":"lvm lvm pvcreate /dev/vdc vgextend VolGroup /dev/vdc lvextend -l +100%FREE /dev/mapper/VolGroup-LogVol00 resize2fs /dev/mapper/VolGroup-LogVol00 ","date":"2024-10-17","objectID":"/posts/linux/:6:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["linux"],"content":"根据日期排序删除 ls -ltd FilePath | awk '{if(NR\u003e10){print $0}}' | xargs rm -rf; ","date":"2024-10-17","objectID":"/posts/linux/:7:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["linux"],"content":"磁盘在线扩容 安装工具包： yum -y install cloud-utils-growpart 给指定分区扩容： growpart /dev/vda 1 扩容支文件系统（如果无法resize，确保分区已扩容的情况下重启服务器离线扩容）： resize2fs /dev/vda1 ","date":"2024-10-17","objectID":"/posts/linux/:8:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["linux"],"content":"timewait查看 netstat -an | awk '{print $6}' | sort | uniq -c | sort -nr ","date":"2024-10-17","objectID":"/posts/linux/:9:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["linux"],"content":"路由新增删除 route add -net 106.15.100.0/24 gw 183.57.42.65 route del -net 106.15.100.0/24 gw 183.57.42.65 ","date":"2024-10-17","objectID":"/posts/linux/:10:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["linux"],"content":"maildrop删除 rsync --delete -rlptD /tmp/empty/ /var/spool/postfix/maildrop/ ","date":"2024-10-17","objectID":"/posts/linux/:11:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["linux"],"content":"ssh config ServerAliveInterval 60 ServerAliveCountMax 30 HostkeyAlgorithms +ssh-rsa PubkeyAcceptedAlgorithms +ssh-rsa UserKnownHostsFile=/dev/null StrictHostKeyChecking no UserKnownHostsFile=/dev/null Host * ServerAliveInterval 60 ServerAliveCountMax 30 HostkeyAlgorithms +ssh-rsa PubkeyAcceptedAlgorithms +ssh-rsa StrictHostKeyChecking no Host IPADDRESS HostName IPADDRESS User root IdentityFile ~/.ssh/id_rsa ","date":"2024-10-17","objectID":"/posts/linux/:12:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["linux"],"content":"crontab 使用vim编辑 1.对于一些系统，crontab的默认编译器使用起来不是很方便，想换成熟悉的vim，按下面操作即可：编辑.profile文件，增加EDITOR=vim;export EDITOR即可； 2.在命令行直接输入EDITOR=vim;export EDITOR ","date":"2024-10-17","objectID":"/posts/linux/:13:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["linux"],"content":"ossutil /opt/ossutil64 cp xxx.sql.gz oss://BUCKET/dir/ -u -c CONFIGFILE ","date":"2024-10-17","objectID":"/posts/linux/:14:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["linux"],"content":"多线程压缩 pigz # 压缩文件 pigz -k filename # -k 保留原文件 pigz -l filename.gz # -l 查看文件压缩内容 # 压缩目录 tar --use-compress-program=\"pigz -k\" -cvf dir1.tar.gz dir1 # 解压文件 pigz -k -d filename.gz # 解压目录 tar --use-compress-program=\"pigz -k \" -xvf dir1.tar.gz ","date":"2024-10-17","objectID":"/posts/linux/:15:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["linux"],"content":"requirements 依赖生成: pipreqs --encoding utf8 --force ","date":"2024-10-17","objectID":"/posts/linux/:16:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["linux"],"content":"openssl 证书测试 openssl s_client -connect domainName:443 ","date":"2024-10-17","objectID":"/posts/linux/:17:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["linux"],"content":"强密码生成 openssl rand -base64 15 系统使用规范(自有服务统一授权为普通用户权限) 统一数据目录：/data 统一日志目录：/var/log 应用统一管理工具：supervisor 三方应用目录：/opt 示例服务标记：应用目录：application 应用备份：appbak 公共脚本：scripts ","date":"2024-10-17","objectID":"/posts/linux/:18:0","tags":["system"],"title":"Linux","uri":"/posts/linux/"},{"categories":["supervisor"],"content":" /etc/supervisor.conf [unix_http_server] file=/tmp/supervisor.sock [supervisord] minfds=65535 # supervisord 加大应用的可用链接数 minprocs=65535 user=deploy [supervisorctl] serverurl=unix:///tmp/supervisor.sock supervisor exsample [program:SERVICENAME] ;脚本目录 directory= /data/%(program_name)s/ ;脚本执行命令 command=/usr/bin/uwsgi --ini %(program_name)s.ini --ignore-sigpipe ;supervisor启动的时候是否随着同时启动,默认True autostart=true ;当程序exit的时候，这个program不会自动重启. autorestart=true ;这个选项是子进程启动多少秒之后，此时状态如果是running，则我们认为启动成功了。默认值为1 startsecs=5 ;脚本运行的用户身份 user = USER ;日志输出 stdout_logfile= /var/log/supervisor/%(program_name)s.log ;把stderr重定向到stdout，默认 false redirect_stderr = true ;stdout日志文件大小，默认 50MB stdout_logfile_maxbytes = 20MB ;stdout日志文件备份数 stdout_logfile_backups = 20 ;environment= ","date":"2024-10-15","objectID":"/posts/supervisor/:0:0","tags":["supervisor"],"title":"Supervisor","uri":"/posts/supervisor/"},{"categories":["openvpn"],"content":" port 2305 proto udp dev tun ca ca.crt cert server.crt key server.key dh dh.pem auth SHA512 tls-crypt tc.key topology subnet server 10.8.0.0 255.255.255.0 ifconfig-pool-persist ipp.txt push \"dhcp-option DNS 100.100.2.136\" push \"dhcp-option DNS 100.100.2.138\" # 内网推送 push \"route 172.16.0.0 255.255.0.0\" # 阿里内网推送 push \"route 100.100.0.0 255.255.0.0\" push \"route 100.103.0.0 255.255.0.0\" push \"route 47.106.223.210 255.255.255.255\" keepalive 10 120 cipher AES-256-CBC user nobody group nobody persist-key persist-tun verb 3 crl-verify crl.pem explicit-exit-notify ","date":"2024-10-15","objectID":"/posts/openvpncommunity/:0:0","tags":["openvpn"],"title":"OpenvpnCommunity","uri":"/posts/openvpncommunity/"},{"categories":["nginx"],"content":"请求方法限制 if ($request_method !~ ^(GET|HEAD|POST)$ ) { return 501; } ","date":"2024-10-15","objectID":"/posts/nginx/:1:0","tags":["nginx"],"title":"Nginx","uri":"/posts/nginx/"},{"categories":["nginx"],"content":"try_files location / { try_files $uri $uri/ /index.html; } next.js location / { try_files $uri $uri.html $uri/ /index.html; } ","date":"2024-10-15","objectID":"/posts/nginx/:2:0","tags":["nginx"],"title":"Nginx","uri":"/posts/nginx/"},{"categories":["nginx"],"content":"443 force ssl if ($ssl_protocol = \"\") { return 302 https://$host$request_uri; } # 302 if ($server_port !~ 443) { rewrite ^(.*)$ https://$host$1 redirect; } # 301 if ($server_port !~ 443) { rewrite ^(.*)$ https://$host$1 permanent; } ","date":"2024-10-15","objectID":"/posts/nginx/:3:0","tags":["nginx"],"title":"Nginx","uri":"/posts/nginx/"},{"categories":["nginx"],"content":"499 proxy_ignore_client_abort on; # 确定在客户端关闭连接时是否应关闭与代理服务器的连接，而不在等待响应 proxy_read_timeout 600; proxy_send_timeout 600; # 如果超时(默认60s)，Nginx 会主动断开连接，记录504 ","date":"2024-10-15","objectID":"/posts/nginx/:4:0","tags":["nginx"],"title":"Nginx","uri":"/posts/nginx/"},{"categories":["nginx"],"content":"log format log_format main escape=json '{ \"time_local\": \"$time_local\", ' '\"remote_user\": \"$remote_user\", ' '\"remote_addr\": \"$remote_addr\", ' '\"http_referer\": \"$http_referer\", ' '\"request\": \"$request\", ' '\"method\": \"$request_method\", ' '\"url_path\": \"$request_uri\", ' '\"request_body\": \"$request_body\", ' '\"status\": $status, ' '\"level\": \"$level\",' '\"body_bytes_sent\": $body_bytes_sent, ' '\"http_user_agent\": \"$http_user_agent\", ' '\"http_host\": \"$http_host\", ' '\"http_requestid\": \"$http_requestid\", ' '\"http_authorization\": \"$http_authorization\", ' '\"business\": \"ngx_access-$host\", ' '\"http_x_forwarded_for\": \"$http_x_forwarded_for\", ' '\"upstream_addr\": \"$upstream_addr\",' '\"trace_id\": \"$trace_id\",' '\"upstream_response_time\": \"$upstream_response_timer\",' '\"ssl_protocol\": \"$ssl_protocol\",' '\"request_time\": $request_time' ' }'; ","date":"2024-10-15","objectID":"/posts/nginx/:5:0","tags":["nginx"],"title":"Nginx","uri":"/posts/nginx/"},{"categories":["nginx"],"content":"跨域 add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods *; add_header Access-Control-Allow-Credentials true; ","date":"2024-10-15","objectID":"/posts/nginx/:6:0","tags":["nginx"],"title":"Nginx","uri":"/posts/nginx/"},{"categories":["nginx"],"content":"上传文件 # nginx client_max_body_size 1024m; # php file_uploads on 是否允许通过HTTP上传文件的开关。 默认为ON即是开upload_tmp_dir – 文件上传至服务器上存储临时文件的地方，如果没指定就会用系统默认的临时文件夹 upload_max_filesize 8m 望文生意，即允许上传文件大小的最大值。默认为2M post_max_size 8m 指通过表单POST给PHP的所能接收的最大值，包括表单里的所有值。默认为8M # 针对网络不好配置 max_execution_time 600 每个PHP页面运行的最大时间值(秒)，默认30秒 max_input_time 600 每个PHP页面接收数据所需的最大时间，默认60秒 memory_limit 8m 每个PHP页面所吃掉的最大内存，默认8M ","date":"2024-10-15","objectID":"/posts/nginx/:7:0","tags":["nginx"],"title":"Nginx","uri":"/posts/nginx/"},{"categories":["nginx"],"content":"proxy location ~ .*\\.(js|css)?$ { expires 12h; proxy_pass http://xxx; } location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)?$ { expires 12h; proxy_pass http://xxx; } ","date":"2024-10-15","objectID":"/posts/nginx/:8:0","tags":["nginx"],"title":"Nginx","uri":"/posts/nginx/"},{"categories":["nginx"],"content":"exsample ","date":"2024-10-15","objectID":"/posts/nginx/:9:0","tags":["nginx"],"title":"Nginx","uri":"/posts/nginx/"},{"categories":["nginx"],"content":"http upstream xxx.cn { server 10.x:3000 weight=10 max_fails=3 fail_timeout=3s; server 10.x:3000 weight=10 max_fails=3 fail_timeout=3s; check interval=1000 rise=2 fall=3 timeout=5000 type=http default_down=false; check_http_send \"GET /ping HTTP/1.0\\\\r\\\\n\\\\r\\\\n\"; check_http_expect_alive http_2xx http_3xx; } server { listen 80; server_name xxx.cn; index index.html index.htm; access_log /var/log/nginx/xxx.cn.access.log main; error_log /var/log/nginx/xxx.cn.error.log warn; location ~ ^/NginxStatus/ { stub_status on; access_log on; } location / { proxy_redirect off ; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_connect_timeout 600; proxy_send_timeout 600; proxy_read_timeout 600; proxy_ignore_client_abort on; proxy_buffer_size 1600k; proxy_buffers 4 3200k; proxy_busy_buffers_size 6400k; proxy_temp_file_write_size 6400k; proxy_max_temp_file_size 128m; proxy_next_upstream error timeout invalid_header http_500 http_503 http_404; proxy_pass http://xxx.cn; } } ","date":"2024-10-15","objectID":"/posts/nginx/:9:1","tags":["nginx"],"title":"Nginx","uri":"/posts/nginx/"},{"categories":["nginx"],"content":"php listen 80; listen [::]:80; listen 443 ssl http2; listen [::]:443 ssl http2; ssl_certificate /usr/local/openresty/nginx/conf/ssl/xxx.com.pem; ssl_certificate_key /usr/local/openresty/nginx/conf/ssl/xxx.com.key; ssl_protocols TLSv1.2 TLSv1.3; ssl_ecdh_curve X25519:prime256v1:secp384r1:secp521r1; ssl_ciphers ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256; ssl_conf_command Ciphersuites TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256; ssl_conf_command Options PrioritizeChaCha; ssl_prefer_server_ciphers on; ssl_session_timeout 10m; ssl_session_cache shared:SSL:10m; ssl_buffer_size 2k; add_header Strict-Transport-Security max-age=15768000; ssl_stapling on; ssl_stapling_verify on; server_name xxx; access_log /var/log/xxx.log combined; index index.html index.htm index.php; root xxx_path; if ($ssl_protocol = \"\") { return 302 https://$host$request_uri; } location ~ [^/]\\\\.php(/|$) { #fastcgi_pass remote_php_ip:9000; fastcgi_pass unix:/dev/shm/php-cgi.sock; fastcgi_index index.php; include fastcgi.conf; } location ~ .*\\\\.(gif|jpg|jpeg|png|bmp|swf|flv|mp4|ico)$ { expires 30d; access_log off; } location ~ .*\\\\.(js|css)?$ { expires 7d; access_log off; } location ~ /(\\\\.user\\\\.ini|\\\\.ht|\\\\.git|\\\\.svn|\\\\.project|LICENSE|README\\\\.md|\\\\.env) { deny all; } location /.well-known { allow all; } ","date":"2024-10-15","objectID":"/posts/nginx/:9:2","tags":["nginx"],"title":"Nginx","uri":"/posts/nginx/"},{"categories":["nginx"],"content":"default_server # 手动生成本地ssl公私钥 openssl req -x509 -nodes -days 3650 -newkey rsa:2048 -keyout /etc/nginx/ssl/nginx.key -out /etc/nginx/ssl/nginx.crt # 增加default_server cat \u003c\u003c 'EOF' \u003e /etc/nginx/sites-available/000_default server { listen 80 default_server; listen 443 ssl default_server; ssl_certificate /etc/nginx/ssl/nginx.crt; ssl_certificate_key /etc/nginx/ssl/nginx.key; server_name _; return 444; access_log /var/log/nginx/000_default.access.log; error_log /var/log/nginx/000_default.error.log; } EOF # reload nginx nginx -t nginx -s reload # 查看日志，检查其他域名是否正常 tailf /var/log/nginx/000_default.access.log ","date":"2024-10-15","objectID":"/posts/nginx/:10:0","tags":["nginx"],"title":"Nginx","uri":"/posts/nginx/"},{"categories":["minio"],"content":"集群版条件 注意 单独无数据磁盘使用 minio节点的时间不能超过3s ","date":"2024-10-15","objectID":"/posts/minio/:0:0","tags":["minio"],"title":"Minio","uri":"/posts/minio/"},{"categories":["minio"],"content":"nginx 配置 upstream xxx.com { least_conn; server 127.0.0.1:9000; } upstream xxx.com-console { least_conn; server 127.0.0.1:9001; } server { listen 80; listen [::]:80; server_name xxx.com; access_log /var/log/nginx/xxx.com.access.log main; error_log /var/log/nginx/xxx.com.error.log warn; # Allow special characters in headers ignore_invalid_headers off; # Allow any size file to be uploaded. # Set to a value such as 1000m; to restrict file size to a specific value client_max_body_size 0; # Disable buffering proxy_buffering off; proxy_request_buffering off; location / { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_connect_timeout 300; # Default is HTTP/1, keepalive is only enabled in HTTP/1.1 proxy_http_version 1.1; proxy_set_header Connection \"\"; chunked_transfer_encoding off; proxy_pass \u003chttp://xxx.com\u003e; # This uses the upstream directive definition to load balance } location /minio { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-NginX-Proxy true; # This is necessary to pass the correct IP to be hashed # real_ip_header X-Real-IP; proxy_connect_timeout 300; # To support websockets in MinIO versions released after January 2023 proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; chunked_transfer_encoding off; proxy_pass \u003chttp://xxx.com-console\u003e; # This uses the upstream directive definition to load balance and assumes a static Console port of 9001 } } ","date":"2024-10-15","objectID":"/posts/minio/:1:0","tags":["minio"],"title":"Minio","uri":"/posts/minio/"},{"categories":["minio"],"content":"minio 配置 useradd minio -s /sbin/nologin /etc/default/minio MINIO_VOLUMES=\"\u003chttp://192.168.1.141/data/minio\u003e \u003chttp://192.168.1.140/data/minio\u003e\" MINIO_OPTS=\"--console-address :9001 --address :9000\" MINIO_ROOT_USER=admin MINIO_ROOT_PASSWORD=xxx # MINIO_SERVER_URL=\"\u003chttps://minio.example.net:9000\u003e\" /usr/lib/systemd/system/minio.service [Unit] Description=MinIO Documentation=https://min.io/docs/minio/linux/index.html Wants=network-online.target After=network-online.target AssertFileIsExecutable=/usr/local/bin/minio [Service] WorkingDirectory=/usr/local User=minio Group=minio ProtectProc=invisible EnvironmentFile=-/etc/default/minio ExecStartPre=/bin/bash -c \"if [ -z \\\\\"${MINIO_VOLUMES}\\\\\" ]; then echo \\\\\"Variable MINIO_VOLUMES not set in /etc/default/minio\\\\\"; exit 1; fi\" ExecStart=/usr/local/bin/minio server $MINIO_OPTS $MINIO_VOLUMES # MinIO RELEASE.2023-05-04T21-44-30Z adds support for Type=notify (\u003chttps://www.freedesktop.org/software/systemd/man/systemd.service.html#Type=\u003e) # This may improve systemctl setups where other services use `After=minio.server` # Uncomment the line to enable the functionality # Type=notify # Let systemd restart this service always Restart=always # Specifies the maximum file descriptor number that can be opened by this process LimitNOFILE=65536 # Specifies the maximum number of threads this process can create TasksMax=infinity # Disable timeout logic and wait until process is stopped TimeoutStopSec=infinity SendSIGKILL=no [Install] WantedBy=multi-user.target # Built for ${project.name}-${project.version} (${project.name}) 开启自启动 # 创建minio目录（一个盘对应一个目录即可） mkdir /data/minio chown -R minio.minio /data/minio systemctl enable minio systemctl start minio ","date":"2024-10-15","objectID":"/posts/minio/:2:0","tags":["minio"],"title":"Minio","uri":"/posts/minio/"},{"categories":["kernal"],"content":"备注: /proc/sys/：目录是Linux内核在启动后生成的伪目录，其目录下的net文件夹中存放了当前系统中开启的所有内核参数,目录树结构与参数的完整名称相关. 如: net.ipv4.tcp_tw_recycle，它对应的文件是/proc/sys/net/ipv4/tcp_tw_recycle文件，文件的内容就是参数值。 允许回收TCP连接，必须为1 Linux从4.12内核版本开始移除了 配置 net.ipv4.tcp_tw_recycle = 0 阿里云 - Linux系统常用内核网络参数介绍与常见问题处理: Sysctl 操作命令 查看当前生效的内核参数 sysctl -a 生效更改的内核参数 sysctl -p 禁用大内存页面 Transparent Huge Pages for Redis/MongoDB ，默认是 always echo \"never\" \u003e /sys/kernel/mm/transparent_hugepage/enabled ulimits 优化设置打开文件的最大数量（文件描述符），按需修改最大数值。 编辑 /etc/security/limits.conf ，添加或替换下面几行代码到文件结尾. root soft nofile 65535 root hard nofile 65535 # root hard nofile 65535 * soft nproc 65535 * hard nproc 65535 * soft nofile 65535 * hard nofile 65535 ","date":"2024-10-15","objectID":"/posts/sysctl/:1:0","tags":["system"],"title":"Sysctl","uri":"/posts/sysctl/"},{"categories":["kernal"],"content":"sysctl.conf 优化 # 脏数据的比例和处理，根据场景不同设置， # 参考 \u003chttps://lonesysadmin.net/2013/12/22/better-linux-disk-caching-performance-vm-dirty_ratio/\u003e # 如果是数据库服务器，希望数据能够尽快安全写入，可降低内存缓存比例 vm.dirty_background_ratio = 5 vm.dirty_ratio = 10 # 如果是业务服务器，对数据安全写入无要求，可加大内存缓存比例 vm.dirty_background_ratio = 50 vm.dirty_ratio = 80 # 设置为1，内核允许分配所有的物理内存,Redis常用 # 0， 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。 # 1， 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。 # 2， 表示内核允许分配超过所有物理内存和交换空间总和的内存 vm.overcommit_memory = 1 fs.file-max = 2097152 # 系统拥有的内存数，ElasticSearch启动必备 vm.max_map_count = 262144 # 数据包转发,0表示禁止 net.ipv4.ip_forward = 0 # 设置为1,tcp链接参数重新配置 net.ipv4.tcp_no_metrics_save = 1 # 处理无源路由 net.ipv4.conf.all.accept_source_route = 0 net.ipv4.conf.default.accept_source_route = 0 # 禁用 sysrq 功能 kernel.sysrq = 0 # 控制 core 文件的文件名中是否添加 pid 作为扩展 kernel.core_uses_pid = 1 # 服务端主动关闭后,客户端释放连接的超时,FIN-WAIT-2状态\u003c30 net.ipv4.tcp_fin_timeout = 10 # 设置为1，防止 SYNC FLOOD 攻击 net.ipv4.tcp_syncookies = 1 # TIME_WAIT socket的最大数目，不宜太大或者太小，nginx反向代理必备 net.ipv4.tcp_max_tw_buckets = 262144 # 允许重用TCP连接,0表示关闭 net.ipv4.tcp_tw_reuse = 1 # 允许TCP保持的空闲keepalive时长,不需要太长 net.ipv4.tcp_keepalive_time = 30 # 链接失效前发送探测包数量 net.ipv4.tcp_keepalive_probes = 3 # 链接无确认时重新发送的频度,default 75s net.ipv4.tcp_keepalive_intvl = 30 # 消息队列存放消息的总字节数 kernel.msgmnb = 65536 # 系统范围内最大多少个消息队列 kernel.msgmni = 2048 # 消息队列的最大消息大小，默认8k，建议64kb kernel.msgmax = 65536 # 每个消息的最大size. kernel.shmmax = 68719476736 # 内核参数定义单个共享内存段的最大值 kernel.shmall = 4294967296 # 交换内存使用 vm.swappiness = 0 # 系统作为TCP客户端连接自动使用的端口(start，end），可发起并发连接数为end-star net.ipv4.ip_local_port_range = 1024 65500 # socket缓冲区发送和接收的默认值 net.core.wmem_default = 8388608 net.core.rmem_default = 8388608 # tcp数据发送和接收值 net.core.wmem_max = 16777216 net.core.rmem_max = 16777216 # TCP 缓冲区内存，连接数达到非常高时候需要配置好 net.ipv4.tcp_rmem = 4096 87380 16777216 net.ipv4.tcp_wmem = 4096 65536 16777216 net.ipv4.tcp_mem = 786432 2097152 3145728 # 打开 SACK 选项,防止伪造sequence net.ipv4.tcp_sack = 1 # 禁用timestamp，重要，高并发下设置为0 net.ipv4.tcp_timestamps = 0 # 激活窗口扩充因子，支持64kb以上数据传输 (2^30)1GB net.ipv4.tcp_window_scaling = 1 # ACCEPT等待队列长度,当内核处理慢时多出的包放入网卡接受队列,反之为允许放入队列的最大数量 net.core.netdev_max_backlog = 262144 # 允许最大并发连接数，重要 net.core.somaxconn = 262144 # SYNC等待队列长度,太大了排队也没用 net.ipv4.tcp_max_syn_backlog = 262144 # 不属于任何进程的socket数目，不宜太大，防止攻击 net.ipv4.tcp_max_orphans = 262144 # 处于SYN_RECV状态时重传SYN+ACK包的次数,5以内 net.ipv4.tcp_synack_retries = 2 # 外向syn握手重试次数，5以内 net.ipv4.tcp_syn_retries = 2 # arp相邻层有效性周期 net.ipv4.neigh.default.gc_stale_time=120 # 数据包反向路由验证,0:关闭 1:严格 2:松散 net.ipv4.conf.default.rp_filter=0 net.ipv4.conf.all.rp_filter=0 net.ipv4.conf.default.arp_announce = 2 net.ipv4.conf.all.arp_announce=2 net.ipv4.conf.lo.arp_announce=2 net.ipv4.conf.all.arp_ignore=1 net.ipv4.conf.lo.arp_ignore=1 net.bridge.bridge-nf-call-ip6tables = 0 net.bridge.bridge-nf-call-iptables = 0 net.bridge.bridge-nf-call-arptables = 0 # 关闭tcp链接传输的慢启动 net.ipv4.tcp_slow_start_after_idle = 0 # Linux实例NAT哈希表满导致ECS实例丢包 # nf_conntrack_buckets * 4 = nf_conntrack_max # net.netfilter.nf_conntrack_buckets = 163837 net.netfilter.nf_conntrack_max = 655350 net.netfilter.nf_conntrack_tcp_timeout_established = 1200 ","date":"2024-10-15","objectID":"/posts/sysctl/:2:0","tags":["system"],"title":"Sysctl","uri":"/posts/sysctl/"},{"categories":["kernal"],"content":"阿里云系统（alibaba cloud linux 3）默认配置 • Alibaba cloud linux 3 default sysctl configure vm.swappiness = 0 kernel.sysrq = 1 net.ipv4.neigh.default.gc_stale_time = 120 # see details in \u003chttps://help.aliyun.com/knowledge_detail/39428.html\u003e net.ipv4.conf.all.rp_filter = 0 net.ipv4.conf.default.rp_filter = 0 net.ipv4.conf.default.arp_announce = 2 net.ipv4.conf.lo.arp_announce = 2 net.ipv4.conf.all.arp_announce = 2 # see details in \u003chttps://help.aliyun.com/knowledge_detail/41334.html\u003e net.ipv4.tcp_max_tw_buckets = 262144 net.ipv4.tcp_syncookies = 1 # tcp_max_syn_backlog will only take effect when net.ipv4.tcp_syncookies == 0 # net.ipv4.tcp_max_syn_backlog = 65536 net.ipv4.tcp_synack_retries = 2 net.ipv4.tcp_slow_start_after_idle = 0 ","date":"2024-10-15","objectID":"/posts/sysctl/:3:0","tags":["system"],"title":"Sysctl","uri":"/posts/sysctl/"},{"categories":["linux"],"content":"性能观测工具 ","date":"2024-10-15","objectID":"/posts/linux_analysis_tools/:1:0","tags":["linux"],"title":"linux_analysis_tools","uri":"/posts/linux_analysis_tools/"},{"categories":["linux"],"content":"性能压测工具 ","date":"2024-10-15","objectID":"/posts/linux_analysis_tools/:2:0","tags":["linux"],"title":"linux_analysis_tools","uri":"/posts/linux_analysis_tools/"},{"categories":["linux"],"content":"性能调优工具 ","date":"2024-10-15","objectID":"/posts/linux_analysis_tools/:3:0","tags":["linux"],"title":"linux_analysis_tools","uri":"/posts/linux_analysis_tools/"},{"categories":["alpine"],"content":" 替换源： # alpine sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories # ubuntu sed -i s@/archive.ubuntu.com/@/mirrors.aliyun.com/@g /etc/apt/sources.list # debian sed -i \"s@\u003chttp://deb.debian.org@http\u003e://mirrors.aliyun.com@g\" /etc/apt/sources.list sed -i \"s@\u003chttp://security.debian.org@http\u003e://mirrors.aliyun.com@g\" /etc/apt/sources.list python： apk add python3 apk add py-pip pip install -U pip \\\\ pip config set global.index-url \u003chttps://mirrors.aliyun.com/pypi/simple/\u003e \\\\ dockerfile COPY * target # 会解压第一层目录 COPY . target # 保留原始目录 ","date":"2024-10-15","objectID":"/posts/alpine/:0:0","tags":["alpine"],"title":"Alpine","uri":"/posts/alpine/"},{"categories":["linux"],"content":" 系统版本：Alibaba Cloud Linux 3.2104 LTS 64位 默认镜像操作 # 关闭默认启动服务 systemctl disable nfs-server systemctl disable rpc-statd systemctl disable systemd-resolved systemctl disable rpcbind systemctl disable nfsdcld systemctl stop nfs-server systemctl stop rpc-statd systemctl stop rpcbind systemctl stop systemd-resolved systemctl stop nfsdcld # 安装软件 dnf install supervisor dnf install nscd # 新增普通用户 useradd xxx 清除dns缓存 service nscd restart # 或者使用以下命令清楚 service nscd restart crontab 59 23 * * * /usr/sbin/logrotate /etc/logrotate.conf logrostate daily #指定转储周期为每天 weekly #指定转储周期为每周； monthly #指定转储周期为每月； rotate count #指定日志文件删除之前转储的次数，0指没有备份，5指保留5个备份； compress #通过gzip压缩转储以后的日志； nocompress #不需要压缩时，用这个参数； delaycompress #延迟压缩，和compress一起使用时，转储的日志文件到下一次转储时才压缩； nodelaycompress #覆盖delaycompress选项，转储同时压缩； copytruncate #用于还在打开中的日志文件，把当前日志备份并截断； nocopytruncate #备份日志文件但是不截断； create mode owner group #转储文件，使用指定的文件模式创建新的日志文件； nocreate #不建立新的日志文件； errors address #专储时的错误信息发送到指定的Email地址； ifempty #即使是空文件也转储，这个是logrotate的缺省选项； notifempty #如果是空文件的话，不转储； mail address #把转储的日志文件发送到指定的E-mail地； nomail #转储时不发送日志文件； olddir directory #转储后的日志文件放入指定的目录，必须和当前日志文件在同一个文件系统； noolddir #转储后的日志文件和当前日志文件放在同一个目录下； prerotate/endscript #在转储以前需要执行的命令可以放入这个对，这两个关键字必须单独成行； postrotate/endscript #在转储以后需要执行的命令可以放入这个对，这两个关键字必须单独成行； tabootext [+] list #让logrotate不转储指定扩展名的文件，缺省的扩展名是：.rpm-orig, .rpmsave,v,和~ ； size size #当日志文件到达指定的大小时才转储，Size可以指定bytes(缺省)以及KB(sizek)或者MB(sizem)； postrotate #日志轮换过后指定指定的脚本，endscript参数表示结束脚本； sharedscripts #共享脚本,下面的postrotate中的脚本只执行一次即可； # 手动执行：/usr/sbin/logrotate -f /etc/logrotate.conf # nginx /var/log/nginx/*.log { daily dateext missingok rotate 52 compress delaycompress notifempty create 640 nginx zabbix sharedscripts postrotate /usr/sbin/nginx -s reload endscript } # 示例：待验证 /var/log/nginx/*log { daily rotate 10 missingok notifempty compress sharedscripts su root postrotate /bin/kill -USR1 $(cat /var/run/nginx.pid 2\u003e/dev/null) 2\u003e/dev/null || : endscript } # httpd /var/log/httpd/*log { missingok notifempty sharedscripts delaycompress postrotate /sbin/service httpd reload \u003e /dev/null 2\u003e/dev/null || true endscript } sshd_config配置 # alibaba linux default configure UseDNS no AddressFamily inet SyslogFacility AUTHPRIV PermitRootLogin yes PasswordAuthentication yes https://help.aliyun.com/zh/ecs/how-to-enable-the-kdump-service-for-linux-instances?spm=a2c4g.750001.0.i42 ","date":"2024-10-15","objectID":"/posts/alibabalinux/:0:0","tags":["alibabalinux"],"title":"Alibabalinux","uri":"/posts/alibabalinux/"},{"categories":["kibana"],"content":" kibana无法新建索引模式，F12 “403”: 权限问题 PUT .kibana/_settings { \"index\": { \"blocks\": { \"read_only_allow_delete\": false } } } kibana磁盘满之后无法写入索引 PUT _settings { \"index\": { \"blocks\": { \"read_only_allow_delete\": \"false\" } } } ","date":"2024-10-15","objectID":"/posts/kibana/:0:0","tags":["kibana"],"title":"Kibana","uri":"/posts/kibana/"},{"categories":["kafka"],"content":" 查看topic bin/kafka-topics.sh --list --bootstrap-server 127.0.0.1:9092 查看某个topic信息 bin/kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --describe TOPICNAME 查看所有消费组 bin/kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group --all-groups 消费消息 bin/kafka-consumer-groups.sh --zookeeper 127.0.0.1:2181 --topic TOPICNAME 查看topic内容 bin/kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --from-beginning --topic TOPICNAME 创建topic bin/kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --partitions 1 --replication-factor 1 --topic TOPICNAME 删除topic bin/kafka-topics.sh --delete --bootstrap-server 127.0.0.1:9092 --topic TOPICNAME bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --list bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --describe --topic TOPICNAME bin/kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --list bin/kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group GROUPNAME bin/kafka-consumer-groups.sh --zookeeper 127.0.0.1:2181 --delete --group GROUPNAME bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic TOPICNAME ","date":"2024-10-15","objectID":"/posts/kafka/:0:0","tags":["kafka,efk"],"title":"Kafka","uri":"/posts/kafka/"},{"categories":["gitlab"],"content":"git lfs 问题 客户端配置：git config --system http.sslverify false 参考连接：https://blog.csdn.net/root_miss/article/details/81450687 ","date":"2024-10-14","objectID":"/posts/gitlab/:1:0","tags":["gitlab"],"title":"Gitlab","uri":"/posts/gitlab/"},{"categories":["gitlab"],"content":"gitlab邮箱配置 gitlab_rails['smtp_enable'] = true gitlab_rails['smtp_address'] = \"smtp.exmail.qq.com\" gitlab_rails['smtp_port'] = 25 gitlab_rails['smtp_user_name'] = \"gitlab@xxx.cn\" gitlab_rails['smtp_password'] = \"xxx\" gitlab_rails['smtp_domain'] = \"smtp.exmail.qq.com\" gitlab_rails['smtp_authentication'] = \"login\" gitlab_rails['smtp_ssl'] = false gitlab_rails['smtp_enable_starttls_auto'] = true gitlab_rails['gitlab_email_from'] = \"gitlab@xxx.cn\" user[\"git_user_email\"] = \"gitlab@xxx.cn\" ","date":"2024-10-14","objectID":"/posts/gitlab/:2:0","tags":["gitlab"],"title":"Gitlab","uri":"/posts/gitlab/"},{"categories":["gitlab"],"content":"gitlab迁移 gitlab备份 gitlab-rake gitlab:backup:create gitlab 定制相关数据服务 # 停止相关数据连接服务 gitlab-ctl stop unicorn gitlab-ctl stop sidekiq # 从1393513186编号备份中恢复 gitlab-rake gitlab:backup:restore BACKUP=1393513186 # 启动Gitlab gitlab-ctl start ","date":"2024-10-14","objectID":"/posts/gitlab/:3:0","tags":["gitlab"],"title":"Gitlab","uri":"/posts/gitlab/"},{"categories":["gitlab"],"content":"submodule add submodule to project git submodule add https://github.com/yyy/xxx.git DESTPATH list submodule git submodule delete submodule git submodule deinit pull submodule: when git clone add parms –recursive git clone https://github.com/xxx.git --recursive if you forget add –recursive git submodule update --init git submodule update --init --recursive update submodule git submodule update --remote change branch git config submodule.xxx.branch dev or git config -f .gitmodules submodule.xxx.branch dev ","date":"2024-10-14","objectID":"/posts/gitlab/:4:0","tags":["gitlab"],"title":"Gitlab","uri":"/posts/gitlab/"},{"categories":["gitlab"],"content":"gitconfig 常用配置 [alias] ch = checkou st = status staust = 'gitst' cf = config ck = checkout ft = fetch fh = fetch br = branch brv = branch --v geturl = config --get remote.origin.url bs = bisect lg = log --graph --decorate --oneline --all cfg = config --global cfga = config --global alias. pull = pl pl = pull --rebase cm = commit -c HEAD ps = push lsr = ls-remote --heads udc = reset HEAD~ ftg = fetch --tags am = commit -amend cmd = commit --amend rsh = reset HEAD~ cmi = commit --interactive -c HEAD --reset-author i = --interactive rss = reset --soft rmc = rm --cached cp = cherry-pick cpx = cherry-pick -x bl = blame gk = gitk ltn = ls-tree -r HEAD~ --name-only lt = ls-tree -r HEAD~ --name-only ltng = ls-tree -r HEAD~ --name-only |grep lgd = log -p --full-diff bcm = \"branch -a --contains \" brc = branch -a --contains tagc = tag --contains ","date":"2024-10-14","objectID":"/posts/gitlab/:5:0","tags":["gitlab"],"title":"Gitlab","uri":"/posts/gitlab/"},{"categories":["elasticsearch"],"content":"elasticsearch伸缩容 ","date":"2024-10-14","objectID":"/posts/elasticsearch/:1:0","tags":["elasticsearch"],"title":"Elasticsearch","uri":"/posts/elasticsearch/"},{"categories":["elasticsearch"],"content":"水平扩容 将现有集群中的一个节点镜像到一个新机器(主要是相关配置 插件都使用已有配置，避免再重新安装插件修改设置等) ","date":"2024-10-14","objectID":"/posts/elasticsearch/:2:0","tags":["elasticsearch"],"title":"Elasticsearch","uri":"/posts/elasticsearch/"},{"categories":["elasticsearch"],"content":"更改 elasticsearch.yml 配置 # new add config node.master: false node.data: true # modify config node.name: new_instance_name network.host: real_intranet_address ","date":"2024-10-14","objectID":"/posts/elasticsearch/:2:1","tags":["elasticsearch"],"title":"Elasticsearch","uri":"/posts/elasticsearch/"},{"categories":["elasticsearch"],"content":"清空数据目录 方案一：清空数据目录 # default path.data /var/lib/elasticsearch # exec shell rm -rf /var/lib/elasticsearch/*; 方案二：更改数据目录：path.data # new add config path.data: new_stroage_system_path # shell exec chown elasticsearch.elasticsearch /data/application/elasticsearch/ ","date":"2024-10-14","objectID":"/posts/elasticsearch/:2:2","tags":["elasticsearch"],"title":"Elasticsearch","uri":"/posts/elasticsearch/"},{"categories":["elasticsearch"],"content":"start services /etc/init.d/elasticsearch start 查看集群状态：http://ip:9200/_cat/health?v 查看分片迁移进度：http://ip:9200/#/overview?host=Pd_elasticsearch 查看恢复进度：http://ip:9200/_cat/recovery?v 待平衡完成后 修改索引对应的副本数 curl -XPUT \"\u003chttp://ip:9200/INDEXNAME/_settings\u003e\" -d '{ \"index\" : { \"number_of_replicas\" : 3 } }' http://ip:9200/INDEXNAME/list/_search?pretty\u0026from=0\u0026size=1 ","date":"2024-10-14","objectID":"/posts/elasticsearch/:2:3","tags":["elasticsearch"],"title":"Elasticsearch","uri":"/posts/elasticsearch/"},{"categories":["elasticsearch"],"content":"缩容操作 服务使用的es集群中应先剔除要下线的节点 恢复成之前的副本数量 curl -XPUT \"\u003chttp://ip:9200/INDEXNAME/_settings\u003e\" -d '{ \"index\" : { \"number_of_replicas\" : 2 } }' 排除es集群要下线的节点 curl -XPUT \"\u003chttp://ip:9200/_cluster/settings\u003e\" -d'{ \"transient\": { \"cluster.routing.allocation.exclude._ip\": \"要下线的ip\" } }' ","date":"2024-10-14","objectID":"/posts/elasticsearch/:3:0","tags":["elasticsearch"],"title":"Elasticsearch","uri":"/posts/elasticsearch/"},{"categories":["postgres"],"content":"导出 pg_dump -h IPADRESS -U USERNAME -t TABLENAME --column-inserts DATABASENAME \u003e BACKUPNAME.sql ","date":"2024-10-14","objectID":"/posts/postgres/:1:0","tags":["postgres"],"title":"Postgres","uri":"/posts/postgres/"},{"categories":["postgres"],"content":"表owner批量授权 REASSIGN OWNEDBY old_role [,...] TO new_role ","date":"2024-10-14","objectID":"/posts/postgres/:2:0","tags":["postgres"],"title":"Postgres","uri":"/posts/postgres/"},{"categories":["postgres"],"content":"主从配置 主节点配置 # 安装postgre # 切换postgres su - postgres # 登录 psql # 管理员用户配置密码 ALTER USER postgres WITH PASSWORD 'YourPassWord'; # 创建备份账号及权限 CREATE ROLE replica login replication encrypted password 'replica'; # 验证账号是否成功 SELECT usename from pg_user; # 验证权限 SELECT rolname from pg_roles; # 编辑pg_hba.conf,设置replica用户白名单 vim /var/lib/pgsql/9.6/data/pg_hba.conf host all all \u003c从节点的VPC IPv4网段\u003e md5 #允许VPC网段中md5密码认证连接 host replication replica \u003c从节点的VPC IPv4网段\u003e md5 #允许用户从replication数据库进行数据同步 # 编辑postgresql.conf vim /var/lib/pgsql/9.6/data/postgresql.conf # 分别找到以下参数 listen_addresses = '*' #监听的IP地址 wal_level = hot_standby #启用热备模式 synchronous_commit = on #开启同步复制 max_wal_senders = 32 #同步最大的进程数量 wal_sender_timeout = 60s #流复制主机发送数据的超时时间 max_connections = 100 #最大连接数，从库的max_connections必须要大于主库的 # 重启服务 systemctl restart postgresql-9.6.service 从节点配置 # 运行以下命令使用pg_basebackup基础备份工具指定备份目录。 pg_basebackup -D /var/lib/pgsql/9.6/data -h \u003c主节点IP\u003e -p 5432 -U replica -X stream -P # 依次运行以下命令新建并修改recovery.conf配置文件。 cp /usr/pgsql-9.6/share/recovery.conf.sample /var/lib/pgsql/9.6/data/recovery.conf vim /var/lib/pgsql/9.6/data/recovery.conf # 分别找到以下参数，并将参数修改为以下内容： standby_mode = on #声明此节点为从库 primary_conninfo = ‘host=\u003c主节点IP\u003e port=5432 user=replica password=replica’ #对应主库的连接信息 recovery_target_timeline = ‘latest’ #流复制同步到最新的数据 # 运行以下命令打开postgresql.conf文件。 vim /var/lib/pgsql/9.6/data/postgresql.conf max_connections = 1000 # 最大连接数，从节点需设置比主节点大 hot_standby = on # 开启热备 max_standby_streaming_delay = 30s # 数据流备份的最大延迟时间 wal_receiver_status_interval = 1s # 从节点向主节点报告自身状态的最长间隔时间 hot_standby_feedback = on # 如果有错误的数据复制向主进行反馈 # 运行以下命令修改数据目录的属组和属主 chown -R postgres.postgres /var/lib/pgsql/9.6/data 检测验证 # 检测验证需要主从节点之间存在数据交互，例如，从节点备份目录时，进行检测能够得到预期的结果。 pg_basebackup -D /var/lib/pgsql/96/data -h \u003c主节点IP\u003e -p 5432 -U replica -X stream -P # 在主节点中运行以下命令查看sender进程。 ps aux |grep sender # 在从节点中运行以下命令查看receiver进程。 ps aux |grep receiver # 在主节点中进入PostgreSQL交互终端，输入以下SQL语句，在主库中查看从库状态。 select * from pg_stat_replication; ","date":"2024-10-14","objectID":"/posts/postgres/:3:0","tags":["postgres"],"title":"Postgres","uri":"/posts/postgres/"},{"categories":["mysql"],"content":"常用命令 ","date":"2024-10-12","objectID":"/posts/mysql/:1:0","tags":["mysql"],"title":"Mysql","uri":"/posts/mysql/"},{"categories":["mysql"],"content":"mysql导出 –skip-extended-insert 跳过多行写入 –skip-quote-names 跳过 ` 表名 –complete-insert 带字段的insert ","date":"2024-10-12","objectID":"/posts/mysql/:2:0","tags":["mysql"],"title":"Mysql","uri":"/posts/mysql/"},{"categories":["mysql"],"content":"结构导出 mysqldump -uroot -pxxx \\ --default-character-set=utf8 \\ --set-gtid-purged=off \\ --compact \\ --no-data \\ --databases xxx \\ --tables xxx \u003e xxx.sql ","date":"2024-10-12","objectID":"/posts/mysql/:3:0","tags":["mysql"],"title":"Mysql","uri":"/posts/mysql/"},{"categories":["mysql"],"content":"数据导出 mysqldump -uroot -pxxx \\ --default-character-set=utf8 \\ --set-gtid-purged=off \\ --compact \\ --no-create-info \\ --skip-quote-names \\ --complete-insert \\ --databases xxx \\ --tables xxx \u003e xxx.sql ","date":"2024-10-12","objectID":"/posts/mysql/:4:0","tags":["mysql"],"title":"Mysql","uri":"/posts/mysql/"},{"categories":["mysql"],"content":"binlog日志查看 mysqlbinlog --base64-output=decode-rows -v -v mysql-bin.021530 \u003e021530.sql ","date":"2024-10-12","objectID":"/posts/mysql/:5:0","tags":["mysql"],"title":"Mysql","uri":"/posts/mysql/"},{"categories":["mysql"],"content":"慢进程查看 select id,user,host,db,command,time,state,info from information_schema.PROCESSLIST order by time desc; ","date":"2024-10-12","objectID":"/posts/mysql/:6:0","tags":["mysql"],"title":"Mysql","uri":"/posts/mysql/"},{"categories":["mysql"],"content":"Slave 链接 master 配置 CHANGE MASTER TO MASTER_HOST='IPADDRESS',MASTER_USER='UserName',MASTER_PASSWORD='PassWord',master_log_file='BinLogFile',master_log_pos=POSITION; ","date":"2024-10-12","objectID":"/posts/mysql/:7:0","tags":["mysql"],"title":"Mysql","uri":"/posts/mysql/"},{"categories":["mysql"],"content":"从库扩容备份操作 ","date":"2024-10-12","objectID":"/posts/mysql/:8:0","tags":["mysql"],"title":"Mysql","uri":"/posts/mysql/"},{"categories":["mysql"],"content":"1. 备份到目标机器: innobackupex --defaults-file=/etc/my.cnf --no-timestamp --user=root --password=\"PassWord\" --compress --parallel=4 --compress-threads=4 --stream=xbstream /tmp/backup | ssh root@IPADDRESS \"xbstream -x -C /DSTDIR\" ","date":"2024-10-12","objectID":"/posts/mysql/:8:1","tags":["mysql"],"title":"Mysql","uri":"/posts/mysql/"},{"categories":["mysql"],"content":"2. 从库扩容操作: 目标机器解压 innobackupex --parallel=8 --decompress ./ 目标机器初始化 innobackupex --use-memory=51200M --apply-log ./ 目标机器恢复 innobackupex --defaults-file=/etc/my.cnf --copy-back ./2017-08-23_21-23-46/ 清理备份文件 find /var/lib/mysql -name \"*.qp\" | xargs rm chown -R mysql.mysql /var/lib/mysql ","date":"2024-10-12","objectID":"/posts/mysql/:8:2","tags":["mysql"],"title":"Mysql","uri":"/posts/mysql/"},{"categories":["mysql"],"content":"mysql 从库繁忙配置： innodb_flush_log_at_trx_commit = 2 sync_binlog=1 set global innodb_flush_log_at_trx_commit=0; set global sync_binlog=0; ","date":"2024-10-12","objectID":"/posts/mysql/:9:0","tags":["mysql"],"title":"Mysql","uri":"/posts/mysql/"},{"categories":["mysql"],"content":"mysql8.0密码更改原生： set global validate_password.policy=0; set global validate_password.length=1; ALTER user 'root'@'localhost' IDENTIFIED BY 'PASSWORD'; ALTER USER 'UserName'@'%' IDENTIFIED WITH mysql_native_password BY 'PassWord'; ","date":"2024-10-12","objectID":"/posts/mysql/:10:0","tags":["mysql"],"title":"Mysql","uri":"/posts/mysql/"},{"categories":["mysql"],"content":"mysql slave 权限配置： CREATE USER 'rpl'@'172.16.1.%' IDENTIFIED BY 'xxx'; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'rpl'@'172.16.1.%'; ","date":"2024-10-12","objectID":"/posts/mysql/:11:0","tags":["mysql"],"title":"Mysql","uri":"/posts/mysql/"},{"categories":["mysql"],"content":"information_schema 表空间优化 碎片大小 = 数据总大小 - 实际表空间文件大小 数据总大小 = Data_length + Index_length = 101842944 实际表空间文件大小 = rows_Avg_row_length = 101177624 碎片大小 = (101842944 - 101177624) / 1024 /1024 = 0.63MB 整理碎片 alter table table_name engine = innodb pt-online-schema-change optimize table 命令整理: show table status from DBNAME like ‘%TABLENAME%’ \\G 查看; pt-online-schema-change-shell #!/bin/bash source /etc/profile pt-online-schema-change \\ --defaults-file=/etc/my.cnf \\ -uroot -h localhost --password=PASSWORD \\ --alter=\"ENGINE=InnoDB\" \\ D=DBNAME,t=TABLENAME \\ 1--no-check-replication-filters --alter-foreign-keys-method=auto \\ 1--recursion-method=none --print \\ 1--charset=utf8 --max-load=\"Threads_running=100\" \\ 1--critical-load=\"Threads_running=200\" --execute 查看所有数据库的容量 SELECT table_schema as '数据库', sum(table_rows) as '记录数', sum(truncate(data_length/1024/1024, 2)) as '数据容量(MB)', sum(truncate(index_length/1024/1024, 2)) as '索引容量(MB)', sum(truncate(DATA_FREE/1024/1024, 2)) as '碎片占用(MB)' from information_schema.tables group by table_schema order by sum(data_length) desc, sum(index_length) desc; 查看指定库的大小 SELECT table_schema as '数据库', sum(table_rows) as '记录数', sum(truncate(data_length/1024/1024, 2)) as '数据容量(MB)', sum(truncate(index_length/1024/1024, 2)) as '索引容量(MB)', sum(truncate(DATA_FREE/1024/1024, 2)) as '碎片占用(MB)' from information_schema.tables where table_schema='DBNAME' order by data_length desc, index_length desc; 查看指定库所有表的大小 SELECT table_schema as '数据库', table_name as '表名', table_rows as '记录数', truncate(data_length/1024/1024, 2) as '数据容量(MB)', truncate(index_length/1024/1024, 2) as '索引容量(MB)', truncate(DATA_FREE/1024/1024, 2) as '碎片占用(MB)' from information_schema.tables where table_schema='DBNAME' order by data_length desc, index_length desc; 查看数据库中容量排名前十的表 USE information_schema; SELECT TABLE_SCHEMA as '数据库', table_name as '表名', table_rows as '记录数', ENGINE as '存储引擎', truncate(data_length/1024/1024, 2) as '数据容量(MB)', truncate(index_length/1024/1024, 2) as '索引容量(MB)', truncate(DATA_FREE/1024/1024, 2) as '碎片占用(MB)' from tables order by table_rows desc limit 10; ","date":"2024-10-12","objectID":"/posts/mysql/:12:0","tags":["mysql"],"title":"Mysql","uri":"/posts/mysql/"},{"categories":["mysql"],"content":"分区 重组 ALTER TABLE tableName REORGANIZE PARTITION pmax INTO( PARTITION partitionName VALUES LESS THAN (890000000), PARTITION pmax VALUES LESS THAN MAXVALUE ); -- 语法分析: 重组对应分区表最大分区pmax,将结果放入新的分区 依次递增。 添加 -- 递增：1209600 ALTER TABLE history ADD PARTITION (PARTITION p20210820 VALUES LESS THAN (1637337600)); ","date":"2024-10-12","objectID":"/posts/mysql/:13:0","tags":["mysql"],"title":"Mysql","uri":"/posts/mysql/"},{"categories":["mysql"],"content":"mysql CSV入库 mysql -h IPADDRESS -uroot -pxxx DBNAME -e \"load data local infile 'CSVFILE' into table $tableName FIELDS TERMINATED BY '\\\\\\\\t';\" ","date":"2024-10-12","objectID":"/posts/mysql/:14:0","tags":["mysql"],"title":"Mysql","uri":"/posts/mysql/"},{"categories":["apisix"],"content":"Nginx proxy_pass + / 问题: location /api { proxy_pass http://api_proxy/; } # 访问: http://api.xxx.com/api/admin; # 转发效果：http://api_proxy/admin; 由于Apisix 使用的是radixtree 的写法, 导致只支持匹配规则(Full match,Prefix matching) , 并且不会去掉匹配的路径, 这个时候, 为了去掉上面的 /api , 需要使用到插件：proxy-rewrite Apisix-Router：https://apisix.apache.org/zh/docs/apisix/terminology/router Proxy-rewrite：https://apisix.apache.org/zh/docs/apisix/plugins/proxy-rewrite ngx_http_rewirte_module：https://nginx.org/en/docs/http/ngx_http_rewrite_module.html ngx_http_proxy_module：https://nginx.org/en/docs/http/ngx_http_proxy_module.html ngx_stream_proxy_module：http://nginx.org/en/docs/stream/ngx_stream_proxy_module.html { \"uri\": \"/api*\", \"name\": \"api\", \"id\": \"489259072256738721\", \"upstream\": { \"type\": \"roundrobin\", \"pass_host\": \"pass\", \"nodes\": { \"10.1.1.1:3030\": 10 }, \"timeout\": { \"send\": 6, \"connect\": 6, \"read\": 6 }, \"scheme\": \"http\", \"keepalive_pool\": { \"idle_timeout\": 60, \"requests\": 1000, \"size\": 320 } }, \"plugins\": { \"proxy-rewrite\": { \"regex_uri\": [ \"^/api(.*)$\", \"$1\" ] } }, \"status\": 1, \"host\": \"api.xxx.com\" } ","date":"2024-10-12","objectID":"/posts/apisix/:1:0","tags":["apisix"],"title":"Apisix","uri":"/posts/apisix/"},{"categories":["macos"],"content":"安装lrsz brew install lrzsz ","date":"2024-10-12","objectID":"/posts/lrzsz/:1:0","tags":["macos"],"title":"Lrzsz","uri":"/posts/lrzsz/"},{"categories":["macos"],"content":"iterm2-send-zmodem.sh #!/bin/bash osascript -e 'tell application \"iTerm2\" to version' \u003e /dev/null 2\u003e\u00261 \u0026\u0026 NAME=iTerm2 || NAME=iTerm if [[ $NAME = \"iTerm\" ]]; then FILE=$(osascript -e 'tell application \"iTerm\" to activate' -e 'tell application \"iTerm\" to set thefile to choose file with prompt \"Choose a file to send\"' -e \"do shell script (\\\"echo \\\"\u0026(quoted form of POSIX path of thefile as Unicode text)\u0026\\\"\\\")\") else FILE=$(osascript -e 'tell application \"iTerm2\" to activate' -e 'tell application \"iTerm2\" to set thefile to choose file with prompt \"Choose a file to send\"' -e \"do shell script (\\\"echo \\\"\u0026(quoted form of POSIX path of thefile as Unicode text)\u0026\\\"\\\")\") fi if [[ $FILE = \"\" ]]; then echo Cancelled. # Send ZModem cancel echo -e \\\\x18\\\\x18\\\\x18\\\\x18\\\\x18 sleep 1 echo echo \\# Cancelled transfer else /usr/local/bin/sz \"$FILE\" --escape --binary --bufsize 4096 sleep 1 echo echo \\# Received \"$FILE\" fi ","date":"2024-10-12","objectID":"/posts/lrzsz/:2:0","tags":["macos"],"title":"Lrzsz","uri":"/posts/lrzsz/"},{"categories":["macos"],"content":"iterm2-recv-zmodem.sh #!/bin/bash osascript -e 'tell application \"iTerm2\" to version' \u003e /dev/null 2\u003e\u00261 \u0026\u0026 NAME=iTerm2 || NAME=iTerm if [[ $NAME = \"iTerm\" ]]; then FILE=$(osascript -e 'tell application \"iTerm\" to activate' -e 'tell application \"iTerm\" to set thefile to choose folder with prompt \"Choose a folder to place received files in\"' -e \"do shell script (\\\"echo \\\"\u0026(quoted form of POSIX path of thefile as Unicode text)\u0026\\\"\\\")\") else FILE=$(osascript -e 'tell application \"iTerm2\" to activate' -e 'tell application \"iTerm2\" to set thefile to choose folder with prompt \"Choose a folder to place received files in\"' -e \"do shell script (\\\"echo \\\"\u0026(quoted form of POSIX path of thefile as Unicode text)\u0026\\\"\\\")\") fi if [[ $FILE = \"\" ]]; then echo Cancelled. # Send ZModem cancel echo -e \\\\x18\\\\x18\\\\x18\\\\x18\\\\x18 sleep 1 echo echo \\# Cancelled transfer else cd \"$FILE\" /usr/local/bin/rz --rename --escape --binary --bufsize 4096 sleep 1 echo echo echo \\# Sent \\-\\\u003e $FILE fi ","date":"2024-10-12","objectID":"/posts/lrzsz/:3:0","tags":["macos"],"title":"Lrzsz","uri":"/posts/lrzsz/"},{"categories":["macos"],"content":"iterm2 triggers配置 Regular expression: rz waiting to receive.\\*\\*B0100 Action: Run Silent Coprocess Parameters: /usr/local/bin/iterm2-send-zmodem.sh Instant: checked Regular expression: \\*\\*B00000000000000 Action: Run Silent Coprocess Parameters: /usr/local/bin/iterm2-recv-zmodem.sh Instant: checked ","date":"2024-10-12","objectID":"/posts/lrzsz/:4:0","tags":["macos"],"title":"Lrzsz","uri":"/posts/lrzsz/"},{"categories":["tomcat"],"content":"版本号隐藏 进入到tomcat 目录 mv webapps/ROOT webapps/ROOT mkdir webapps/ROOT$(date +%Y%m%d) 编辑conf/server.xml配置文件中的配置项中添加如下配置： \u003cValve className=\"org.apache.catalina.valves.ErrorReportValve\" showReport=\"false\" showServerInfo=\"false\" /\u003e 修改后再次访问，返回404 ","date":"2024-10-12","objectID":"/posts/tomcat/:1:0","tags":["tomcat"],"title":"Tomcat","uri":"/posts/tomcat/"},{"categories":["java"],"content":"java home 配置 vim /etc/profile export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.312.b07-10.p01.ky10.aarch64/jre/ export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar ","date":"2024-10-12","objectID":"/posts/java/:1:0","tags":["java"],"title":"Java","uri":"/posts/java/"},{"categories":["java"],"content":"Java • Jcmd 开启java 进程remote 端口 jcmd 20364 ManagementAgent.start jmxremote.port=9999 jmxremote.ssl=false jmxremote.authenticate=false -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9999 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=10.1.219.21 • Java dump堆栈信息 jmap -dump:format=b,file=VipQuickRoutePlatAsyn.dat 29473 ","date":"2024-10-12","objectID":"/posts/java/:2:0","tags":["java"],"title":"Java","uri":"/posts/java/"},{"categories":["golang"],"content":"build_packages ","date":"2024-10-12","objectID":"/posts/golang/:1:0","tags":["golang"],"title":"Golang","uri":"/posts/golang/"},{"categories":["golang"],"content":"go打包命令 # 常规打包方法 go build # 使用 “-dflags” 缩小大小 go build -ldflags '-w -s' # 使用upx打包为最小程序 upx ...二进制文件 ","date":"2024-10-12","objectID":"/posts/golang/:2:0","tags":["golang"],"title":"Golang","uri":"/posts/golang/"},{"categories":["golang"],"content":"示例 CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o target/NAME_`date +%Y_%m_%d` ${MAINSRCPATH} CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -ldflags '-w -s' -o pkg/PACKAGENAME ","date":"2024-10-12","objectID":"/posts/golang/:2:1","tags":["golang"],"title":"Golang","uri":"/posts/golang/"},{"categories":["golang"],"content":"multi_platfrom_build ● Mac 打包Linux windows $ CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build test.go $ CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build test.go ● Linux打包Mac windows $ CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build test.go $ CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build test.go ● windows编译Linux Mac $ SET CGO_ENABLED=0SET GOOS=darwin3 SET GOARCH=amd64 go build test.go $ SET CGO_ENABLED=0 SET GOOS=linux SET GOARCH=amd64 go build test.go 参数说明 GOOS：目标可执行程序运行操作系统，支持 darwin，freebsd，linux，windows GOARCH：目标可执行程序操作系统构架，包括 386，amd64，arm ","date":"2024-10-12","objectID":"/posts/golang/:2:2","tags":["golang"],"title":"Golang","uri":"/posts/golang/"},{"categories":["golang"],"content":"go 代理配置 go env -w GOPROXY=https://goproxy.cn,direct ","date":"2024-10-12","objectID":"/posts/golang/:3:0","tags":["golang"],"title":"Golang","uri":"/posts/golang/"},{"categories":["golang"],"content":"fmt 使用 ","date":"2024-10-12","objectID":"/posts/golang/:4:0","tags":["golang"],"title":"Golang","uri":"/posts/golang/"},{"categories":["golang"],"content":"General %v // 以默认的方式打印变量的值 %T // 打印变量的类型 ","date":"2024-10-12","objectID":"/posts/golang/:4:1","tags":["golang"],"title":"Golang","uri":"/posts/golang/"},{"categories":["golang"],"content":"Integer %+d // 带符号的整型，fmt.Printf(\"%+d\", 255)输出+255 %q // 打印单引号 %o // 不带零的八进制 %#o // 带零的八进制 %x // 小写的十六进制 %X // 大写的十六进制 %#x // 带0x的十六进制 %U // 打印Unicode字符 %#U // 打印带字符的Unicode %b // 打印整型的二进制 ","date":"2024-10-12","objectID":"/posts/golang/:4:2","tags":["golang"],"title":"Golang","uri":"/posts/golang/"},{"categories":["golang"],"content":"Integer width %5d // 表示该整型最大长度是5，下面这段代码 %-5d // 则相反，打印结果会自动左对齐 %05d // 会在数字前面补零。 ","date":"2024-10-12","objectID":"/posts/golang/:4:3","tags":["golang"],"title":"Golang","uri":"/posts/golang/"},{"categories":["golang"],"content":"Float %f(=%.6f) // 6位小数点 %e(=%.6e) // 6位小数点（科学计数法） %g // 用最少的数字来表示 %.3g // 最多3位数字来表示 %.3f // 最多3位小数来表示 ","date":"2024-10-12","objectID":"/posts/golang/:4:4","tags":["golang"],"title":"Golang","uri":"/posts/golang/"},{"categories":["golang"],"content":"String %s //正常输出字符串 %q //字符串带双引号，字符串中的引号带转义符 %#q //字符串带反引号，如果字符串内有反引号，就用双引号代替 %x //将字符串转换为小写的16进制格式 %X //将字符串转换为大写的16进制格式 %x //带空格的16进制格式 ","date":"2024-10-12","objectID":"/posts/golang/:4:5","tags":["golang"],"title":"Golang","uri":"/posts/golang/"},{"categories":["golang"],"content":"String Width (以5做例子） %5s // 最小宽度为5 %-5s // 最小宽度为5（左对齐） %.5s // 最大宽度为5 %5.7s // 最小宽度为5，最大宽度为7 %-5.7s // 最小宽度为5，最大宽度为7（左对齐） %5.3s // 如果宽度大于3，则截断 %05s // 如果宽度小于5，就会在字符串前面补零 ","date":"2024-10-12","objectID":"/posts/golang/:4:6","tags":["golang"],"title":"Golang","uri":"/posts/golang/"},{"categories":["golang"],"content":"Struct %v // 正常打印。比如：{sam {12345 67890}} %+v // 带字段名称。比如：{name:sam phone:{mobile:12345 office:67890} %#v // 用Go的语法打印。 // 比如main.People{name:\"sam\", phone:main.Phone{mobile:\"12345\", office:\"67890\"}} ","date":"2024-10-12","objectID":"/posts/golang/:4:7","tags":["golang"],"title":"Golang","uri":"/posts/golang/"},{"categories":["golang"],"content":"Boolean %t // 打印true或false ","date":"2024-10-12","objectID":"/posts/golang/:4:8","tags":["golang"],"title":"Golang","uri":"/posts/golang/"},{"categories":["golang"],"content":"Pointer %p // 带0x的指针 %#p // 不带0x的指针 ","date":"2024-10-12","objectID":"/posts/golang/:4:9","tags":["golang"],"title":"Golang","uri":"/posts/golang/"}]